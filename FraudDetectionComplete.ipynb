{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tqdm\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "import PMLE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import datetime\n",
    "from statsmodels.discrete.discrete_model import Logit\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import log_loss\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import random\n",
    "from keras import regularizers\n",
    "from keras import models,layers,optimizers\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks.callbacks import ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')\n",
    "\n",
    "time_df = pd.DataFrame(df.Time)\n",
    "time_df['hour_dummy']=(time_df.Time/(60*60)).round().astype(str)\n",
    "time_df['day_dummy']=(time_df.Time/(60*60*24)).round().astype(str)\n",
    "time_df = pd.get_dummies(time_df,drop_first=True).drop('Time',axis=1)\n",
    "df.drop('Time',axis=1,inplace=True)\n",
    "\n",
    "df['cents'] = df.Amount.apply(lambda x: int(str(x).split('.')[1]))\n",
    "df.Amount[df.Amount!=0] = np.log(df.Amount[df.Amount!=0])\n",
    "\n",
    "X = df.drop('Class',axis=1)\n",
    "y = df.Class\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "time_train, time_val = train_test_split(time_df,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain bagged logistic regression with penalized MLE results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bagged_PMLE_results(X_train,y_train,functions,function_labels,iterations=20):\n",
    "    train = dict.fromkeys(function_labels,np.zeros(X_train.shape[0]))\n",
    "    val = dict.fromkeys(function_labels,np.zeros(X_val.shape[0]))\n",
    "    for i in range(iterations):\n",
    "        print('Epoch', i+1)\n",
    "        X = X_train[y_train==1].sample(frac=0.05).append(X_train[y_train==0].sample(frac=0.05))\n",
    "        y = y_train.loc[X.index]\n",
    "        for j in range(len(functions)):\n",
    "            functions[j].fit(X,y)\n",
    "            train[function_labels[j]] = ((i)*train[function_labels[j]] + functions[j].predict_proba(X_train))/(i+1)\n",
    "            val[function_labels[j]] =  ((i)*val[function_labels[j]] + functions[j].predict_proba(X_val))/(i+1)\n",
    "    return train, val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firth = PMLE.PMLE.Firth_Logit(num_iters=125,lr=0.05, metric='recall_score', readout_rate=10)\n",
    "FLIC = PMLE.PMLE.Firth_Logit(num_iters=125,lr=0.05,FLIC=True, metric='recall_score', readout_rate=10)\n",
    "t_firth = PMLE.PMLE.Firth_Logit(num_iters=125,lr=0.05,lmbda=0.01, metric='recall_score', readout_rate=10)\n",
    "\n",
    "functions = [firth, FLIC, t_firth]\n",
    "function_labels = ['firth','FLIC','t_firth']\n",
    "\n",
    "train_results, val_results = get_bagged_PMLE_results(X_train,y_train,functions,function_labels,iterations=1)\n",
    "\n",
    "train_results = pd.DataFrame.from_dict(train_results)\n",
    "train_results.index = X_train.index\n",
    "val_results = pd.DataFrame.from_dict(val_results)\n",
    "val_results.index = X_val.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder Anomaly Detection\n",
    "### With undercomplete, regularized and denoising autoencoders using pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify non-fraud rows\n",
    "normal_inds = y_train[y_train==0].reset_index().index\n",
    "\n",
    "#Standardize dfs\n",
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_val_sc = sc.fit_transform(X_val)\n",
    "n_features = X_train_sc.shape[1]\n",
    "\n",
    "#Convert non-fraud rows to pytorch tensor\n",
    "normal_train = X_train_sc[normal_inds,:]\n",
    "normal_torch = torch.from_numpy(normal_train,).type(torch.FloatTensor)\n",
    "\n",
    "#Convert train and val sets to pytorch tensor\n",
    "train_torch = torch.from_numpy(X_train_sc).type(torch.FloatTensor)\n",
    "val_torch = torch.from_numpy(X_val_sc).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create autoencoder class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self,n_features,hidden_nodes,dropout=None,VAE=False):\n",
    "        \n",
    "        '''PARAMATERS\n",
    "           n_features: number of X variables in dataset\n",
    "           hidden_nodes: number of nodes in hidden layer\n",
    "           dropout: fraction of nodes to dropout (0 < dropout <1)'''\n",
    "        \n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.n_features=n_features\n",
    "        self.n_hidden = hidden_nodes\n",
    "        self.encoder = nn.Linear(n_features,hidden_nodes)\n",
    "        self.decoder = nn.Linear(hidden_nodes,n_features)\n",
    "        self.output_layer = nn.Linear(n_features,n_features)\n",
    "        self.dropout = dropout\n",
    "        self.best_recon = None\n",
    "        \n",
    "        \n",
    "    def forward (self,x):\n",
    "        if self.dropout!=None:\n",
    "            x = F.relu(F.dropout(self.encoder(x)))\n",
    "        else:\n",
    "            x = F.relu(self.encoder(x))\n",
    "        self.hidden_layer=x\n",
    "        x = F.relu(self.decoder(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_autoencoder(model, dataset, loss_func, optimizer, epochs=100, batch_size=1024,  \n",
    "                      validation_tensor=None,y_val=None, lr_rate_scheduler = None, noise_factor=None, \n",
    "                      random_seed=None, MSE_stopping_threshold=0):\n",
    "        '''Parameters\n",
    "           model: instantiated autoencoder\n",
    "           dataset: torch tensor of X variables\n",
    "           loss_func: instantiated loss function\n",
    "           optimizer: instantiated optimizer\n",
    "           validation_tensor: torch tensor of validation X variables\n",
    "           y_val: numpy array of y values\n",
    "           epochs: number of epochs\n",
    "           lr_rate_scheduler: Instantiated PyTorch learning rate scheduler\n",
    "           batch_size: batch_size\n",
    "           noise_factor: magnitude of noise added to data\n",
    "             for a denoising autoencoder (0 < noise_factor <=1)\n",
    "           random_seed: random_seed\n",
    "           stopping_MSE_threshold: MSE value after which autoencoder stops training'''\n",
    "\n",
    "        \n",
    "        #Set up\n",
    "        if random_seed!=None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        train_loader = torch.utils.data.DataLoader(dataset, \n",
    "                                                   batch_size=batch_size, \n",
    "                                                   shuffle=True)\n",
    "\n",
    "        if type(validation_tensor)==torch.Tensor:\n",
    "            val = True\n",
    "            val_numpy = validation_tensor.detach().numpy()\n",
    "        else:\n",
    "            val = False\n",
    "\n",
    "        readout_batch_interval = 0.25*(dataset.shape[0]/batch_size)//1\n",
    "        \n",
    "        #Training\n",
    "        for epoch in range(epochs):\n",
    "            counter = 0\n",
    "            print('\\n\\033[1mEpoch {}\\033[0m\\n'.format(epoch+1))\n",
    "            for batch in train_loader:\n",
    "\n",
    "                if noise_factor!=None:\n",
    "                    batch = batch + noise_factor * torch.randn(*batch.shape)\n",
    "                batch = torch.autograd.Variable(batch)\n",
    "                optimizer.zero_grad()\n",
    "                recon = model(batch)\n",
    "                loss = loss_func(recon, batch)\n",
    "                if (counter%readout_batch_interval==0):\n",
    "                    print('Batch {} Loss: {:.4f}'.format(counter, float(loss)))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                counter+=1\n",
    "            \n",
    "            #Readout for each epoch\n",
    "            if epoch==0:\n",
    "                epoch_loss = loss_func(model(dataset), dataset)\n",
    "                print('\\nEPOCH {} LOSS: {:.4f}'.format(epoch+1, float(epoch_loss)))\n",
    "            else:\n",
    "                old_epoch_loss = epoch_loss\n",
    "                epoch_loss = loss_func(model(dataset), dataset)\n",
    "                print('\\nEPOCH {} LOSS: {:.4f}'.format(epoch+1, float(epoch_loss)))\n",
    "                \n",
    "            if val == True:\n",
    "                val_output = model(validation_tensor).detach().numpy()\n",
    "                reconstruction_error = np.sqrt(np.power(val_output - val_numpy, 2)).sum(axis=1)\n",
    "                reconstruction_error = sc.fit_transform(reconstruction_error.reshape(-1, 1))\n",
    "                sklogit = LogisticRegression()\n",
    "                if epoch==0:\n",
    "                    sklogit.fit(reconstruction_error,y_val)\n",
    "                    preds = sklogit.predict(reconstruction_error)\n",
    "                    score = recall_score(y_val,preds)\n",
    "                    model.best_recon=model.parameters()\n",
    "                    model.best_pr = score\n",
    "                    print('\\nReconstruction error recall: {:.4f}'.format(score))\n",
    "                else:\n",
    "                    old_score = score\n",
    "                    sklogit.fit(reconstruction_error,y_val)\n",
    "                    preds = sklogit.predict(reconstruction_error)\n",
    "                    score = recall_score(y_val,preds)\n",
    "                    if score<old_score:\n",
    "                        model.best_recon=model.parameters()\n",
    "                        model.best_recall = score\n",
    "                    print('\\nReconstruction error recall {:.4f}'.format(score))\n",
    "                    print('Change: {:.4f}%'.format(float((score-old_score)/old_score)))\n",
    "            if type(scheduler)==torch.optim.lr_scheduler.ReduceLROnPlateau:\n",
    "                scheduler.step(score) \n",
    "            if epoch_loss<=MSE_stopping_threshold:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder I: Undercomplete with Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate encoder and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae1 = AutoEncoder(n_features,int(n_features*1.5//1),dropout=0.3)\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mEpoch 1\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.4900\n",
      "Batch 222 Loss: 0.8589\n",
      "Batch 444 Loss: 0.9410\n",
      "Batch 666 Loss: 0.8289\n",
      "Batch 888 Loss: 0.7099\n",
      "\n",
      "EPOCH 1 LOSS: 0.8892\n",
      "\n",
      "Reconstruction error recall: 0.1485\n",
      "\n",
      "\u001b[1mEpoch 2\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7737\n",
      "Batch 222 Loss: 0.9750\n",
      "Batch 444 Loss: 1.0887\n",
      "Batch 666 Loss: 0.7332\n",
      "Batch 888 Loss: 0.8008\n",
      "\n",
      "EPOCH 2 LOSS: 0.8883\n",
      "\n",
      "Reconstruction error recall 0.1386\n",
      "Change: -0.0667%\n",
      "\n",
      "\u001b[1mEpoch 3\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7950\n",
      "Batch 222 Loss: 0.8598\n",
      "Batch 444 Loss: 0.8896\n",
      "Batch 666 Loss: 0.8075\n",
      "Batch 888 Loss: 0.7872\n",
      "\n",
      "EPOCH 3 LOSS: 0.8880\n",
      "\n",
      "Reconstruction error recall 0.1188\n",
      "Change: -0.1429%\n",
      "\n",
      "\u001b[1mEpoch 4\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.0196\n",
      "Batch 222 Loss: 0.8915\n",
      "Batch 444 Loss: 0.7577\n",
      "Batch 666 Loss: 0.8030\n",
      "Batch 888 Loss: 0.9440\n",
      "\n",
      "EPOCH 4 LOSS: 0.8878\n",
      "\n",
      "Reconstruction error recall 0.1683\n",
      "Change: 0.4167%\n",
      "\n",
      "\u001b[1mEpoch 5\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8061\n",
      "Batch 222 Loss: 0.7351\n",
      "Batch 444 Loss: 0.8013\n",
      "Batch 666 Loss: 0.8537\n",
      "Batch 888 Loss: 0.9079\n",
      "\n",
      "EPOCH 5 LOSS: 0.8881\n",
      "\n",
      "Reconstruction error recall 0.1089\n",
      "Change: -0.3529%\n",
      "\n",
      "\u001b[1mEpoch 6\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7109\n",
      "Batch 222 Loss: 0.9564\n",
      "Batch 444 Loss: 0.7431\n",
      "Batch 666 Loss: 1.0233\n",
      "Batch 888 Loss: 0.7770\n",
      "\n",
      "EPOCH 6 LOSS: 0.8880\n",
      "\n",
      "Reconstruction error recall 0.0990\n",
      "Change: -0.0909%\n",
      "\n",
      "\u001b[1mEpoch 7\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8641\n",
      "Batch 222 Loss: 0.8107\n",
      "Batch 444 Loss: 0.7203\n",
      "Batch 666 Loss: 1.1095\n",
      "Batch 888 Loss: 0.8240\n",
      "\n",
      "EPOCH 7 LOSS: 0.8880\n",
      "\n",
      "Reconstruction error recall 0.1089\n",
      "Change: 0.1000%\n",
      "\n",
      "\u001b[1mEpoch 8\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8482\n",
      "Batch 222 Loss: 0.9127\n",
      "Batch 444 Loss: 0.7797\n",
      "Batch 666 Loss: 0.7641\n",
      "Batch 888 Loss: 0.7402\n",
      "\n",
      "EPOCH 8 LOSS: 0.8877\n",
      "\n",
      "Reconstruction error recall 0.1683\n",
      "Change: 0.5455%\n",
      "\n",
      "\u001b[1mEpoch 9\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7327\n",
      "Batch 222 Loss: 1.1228\n",
      "Batch 444 Loss: 1.5994\n",
      "Batch 666 Loss: 1.1955\n",
      "Batch 888 Loss: 0.8515\n",
      "\n",
      "EPOCH 9 LOSS: 0.8692\n",
      "\n",
      "Reconstruction error recall 0.0198\n",
      "Change: -0.8824%\n",
      "Epoch     9: reducing learning rate of group 0 to 1.8000e-02.\n",
      "\n",
      "\u001b[1mEpoch 10\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.1054\n",
      "Batch 222 Loss: 0.6417\n",
      "Batch 444 Loss: 0.7254\n",
      "Batch 666 Loss: 0.9228\n",
      "Batch 888 Loss: 1.0243\n",
      "\n",
      "EPOCH 10 LOSS: 0.8519\n",
      "\n",
      "Reconstruction error recall 0.0000\n",
      "Change: -1.0000%\n",
      "\n",
      "\u001b[1mEpoch 11\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7824\n",
      "Batch 222 Loss: 0.7646\n",
      "Batch 444 Loss: 0.8645\n",
      "Batch 666 Loss: 0.7598\n",
      "Batch 888 Loss: 0.8834\n",
      "\n",
      "EPOCH 11 LOSS: 0.8430\n",
      "\n",
      "Reconstruction error recall 0.0000\n",
      "Change: nan%\n",
      "\n",
      "\u001b[1mEpoch 12\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7729\n",
      "Batch 222 Loss: 0.8615\n",
      "Batch 444 Loss: 0.7317\n",
      "Batch 666 Loss: 0.7520\n",
      "Batch 888 Loss: 0.7076\n",
      "\n",
      "EPOCH 12 LOSS: 0.8064\n",
      "\n",
      "Reconstruction error recall 0.0000\n",
      "Change: nan%\n",
      "\n",
      "\u001b[1mEpoch 13\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.0401\n",
      "Batch 222 Loss: 0.6518\n",
      "Batch 444 Loss: 0.7215\n",
      "Batch 666 Loss: 0.8645\n",
      "Batch 888 Loss: 0.8147\n",
      "\n",
      "EPOCH 13 LOSS: 0.7893\n",
      "\n",
      "Reconstruction error recall 0.0000\n",
      "Change: nan%\n",
      "\n",
      "\u001b[1mEpoch 14\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.4138\n",
      "Batch 222 Loss: 0.7595\n",
      "Batch 444 Loss: 0.7413\n",
      "Batch 666 Loss: 0.7094\n",
      "Batch 888 Loss: 0.6820\n",
      "\n",
      "EPOCH 14 LOSS: 0.7673\n",
      "\n",
      "Reconstruction error recall 0.0000\n",
      "Change: nan%\n",
      "Epoch    14: reducing learning rate of group 0 to 1.6200e-02.\n",
      "\n",
      "\u001b[1mEpoch 15\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.0456\n",
      "Batch 222 Loss: 0.6429\n",
      "Batch 444 Loss: 0.7016\n",
      "Batch 666 Loss: 0.8255\n",
      "Batch 888 Loss: 0.6571\n",
      "\n",
      "EPOCH 15 LOSS: 0.7462\n",
      "\n",
      "Reconstruction error recall 0.0000\n",
      "Change: nan%\n",
      "\n",
      "\u001b[1mEpoch 16\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6354\n",
      "Batch 222 Loss: 1.0289\n",
      "Batch 444 Loss: 0.6525\n",
      "Batch 666 Loss: 0.8779\n",
      "Batch 888 Loss: 0.9238\n",
      "\n",
      "EPOCH 16 LOSS: 0.7234\n",
      "\n",
      "Reconstruction error recall 0.0000\n",
      "Change: nan%\n",
      "\n",
      "\u001b[1mEpoch 17\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5969\n",
      "Batch 222 Loss: 0.6679\n",
      "Batch 444 Loss: 0.6911\n",
      "Batch 666 Loss: 0.6420\n",
      "Batch 888 Loss: 0.6142\n",
      "\n",
      "EPOCH 17 LOSS: 0.6847\n",
      "\n",
      "Reconstruction error recall 0.0000\n",
      "Change: nan%\n",
      "\n",
      "\u001b[1mEpoch 18\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7309\n",
      "Batch 222 Loss: 0.8843\n",
      "Batch 444 Loss: 0.5571\n",
      "Batch 666 Loss: 0.6046\n",
      "Batch 888 Loss: 0.5735\n",
      "\n",
      "EPOCH 18 LOSS: 0.6533\n",
      "\n",
      "Reconstruction error recall 0.0000\n",
      "Change: nan%\n",
      "\n",
      "\u001b[1mEpoch 19\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6006\n",
      "Batch 222 Loss: 0.8561\n",
      "Batch 444 Loss: 0.8285\n",
      "Batch 666 Loss: 0.6134\n",
      "Batch 888 Loss: 0.5420\n",
      "\n",
      "EPOCH 19 LOSS: 0.6251\n",
      "\n",
      "Reconstruction error recall 0.0000\n",
      "Change: nan%\n",
      "Epoch    19: reducing learning rate of group 0 to 1.4580e-02.\n",
      "\n",
      "\u001b[1mEpoch 20\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7341\n",
      "Batch 222 Loss: 0.6244\n",
      "Batch 444 Loss: 0.6324\n",
      "Batch 666 Loss: 0.5544\n",
      "Batch 888 Loss: 0.5573\n",
      "\n",
      "EPOCH 20 LOSS: 0.5880\n",
      "\n",
      "Reconstruction error recall 0.0099\n",
      "Change: inf%\n",
      "\n",
      "\u001b[1mEpoch 21\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5228\n",
      "Batch 222 Loss: 0.5431\n",
      "Batch 444 Loss: 0.5939\n",
      "Batch 666 Loss: 0.4709\n",
      "Batch 888 Loss: 0.5070\n",
      "\n",
      "EPOCH 21 LOSS: 0.5555\n",
      "\n",
      "Reconstruction error recall 0.0099\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 22\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4947\n",
      "Batch 222 Loss: 0.5128\n",
      "Batch 444 Loss: 0.5444\n",
      "Batch 666 Loss: 0.5085\n",
      "Batch 888 Loss: 0.5502\n",
      "\n",
      "EPOCH 22 LOSS: 0.5387\n",
      "\n",
      "Reconstruction error recall 0.0198\n",
      "Change: 1.0000%\n",
      "\n",
      "\u001b[1mEpoch 23\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6494\n",
      "Batch 222 Loss: 0.4562\n",
      "Batch 444 Loss: 0.6784\n",
      "Batch 666 Loss: 0.4432\n",
      "Batch 888 Loss: 0.4293\n",
      "\n",
      "EPOCH 23 LOSS: 0.5062\n",
      "\n",
      "Reconstruction error recall 0.0297\n",
      "Change: 0.5000%\n",
      "\n",
      "\u001b[1mEpoch 24\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4559\n",
      "Batch 222 Loss: 0.4427\n",
      "Batch 444 Loss: 0.4486\n",
      "Batch 666 Loss: 0.4609\n",
      "Batch 888 Loss: 0.6085\n",
      "\n",
      "EPOCH 24 LOSS: 0.4890\n",
      "\n",
      "Reconstruction error recall 0.0099\n",
      "Change: -0.6667%\n",
      "Epoch    24: reducing learning rate of group 0 to 1.3122e-02.\n",
      "\n",
      "\u001b[1mEpoch 25\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4374\n",
      "Batch 222 Loss: 0.5903\n",
      "Batch 444 Loss: 0.5608\n",
      "Batch 666 Loss: 0.4278\n",
      "Batch 888 Loss: 0.4095\n",
      "\n",
      "EPOCH 25 LOSS: 0.4787\n",
      "\n",
      "Reconstruction error recall 0.0594\n",
      "Change: 5.0000%\n",
      "\n",
      "\u001b[1mEpoch 26\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4299\n",
      "Batch 222 Loss: 0.4476\n",
      "Batch 444 Loss: 0.4292\n",
      "Batch 666 Loss: 0.5209\n",
      "Batch 888 Loss: 0.4679\n",
      "\n",
      "EPOCH 26 LOSS: 0.4672\n",
      "\n",
      "Reconstruction error recall 0.0198\n",
      "Change: -0.6667%\n",
      "\n",
      "\u001b[1mEpoch 27\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4457\n",
      "Batch 222 Loss: 0.3932\n",
      "Batch 444 Loss: 0.4261\n",
      "Batch 666 Loss: 0.5470\n",
      "Batch 888 Loss: 0.3701\n",
      "\n",
      "EPOCH 27 LOSS: 0.4495\n",
      "\n",
      "Reconstruction error recall 0.0396\n",
      "Change: 1.0000%\n",
      "\n",
      "\u001b[1mEpoch 28\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4227\n",
      "Batch 222 Loss: 0.3861\n",
      "Batch 444 Loss: 0.4116\n",
      "Batch 666 Loss: 0.7607\n",
      "Batch 888 Loss: 0.4292\n",
      "\n",
      "EPOCH 28 LOSS: 0.4364\n",
      "\n",
      "Reconstruction error recall 0.0495\n",
      "Change: 0.2500%\n",
      "\n",
      "\u001b[1mEpoch 29\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4180\n",
      "Batch 222 Loss: 0.6260\n",
      "Batch 444 Loss: 0.3929\n",
      "Batch 666 Loss: 0.3994\n",
      "Batch 888 Loss: 0.4341\n",
      "\n",
      "EPOCH 29 LOSS: 0.4258\n",
      "\n",
      "Reconstruction error recall 0.0297\n",
      "Change: -0.4000%\n",
      "Epoch    29: reducing learning rate of group 0 to 1.1810e-02.\n",
      "\n",
      "\u001b[1mEpoch 30\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3974\n",
      "Batch 222 Loss: 0.4446\n",
      "Batch 444 Loss: 0.3875\n",
      "Batch 666 Loss: 0.3759\n",
      "Batch 888 Loss: 0.4657\n",
      "\n",
      "EPOCH 30 LOSS: 0.4172\n",
      "\n",
      "Reconstruction error recall 0.0198\n",
      "Change: -0.3333%\n",
      "\n",
      "\u001b[1mEpoch 31\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3935\n",
      "Batch 222 Loss: 0.3739\n",
      "Batch 444 Loss: 0.4053\n",
      "Batch 666 Loss: 0.4180\n",
      "Batch 888 Loss: 0.3521\n",
      "\n",
      "EPOCH 31 LOSS: 0.4090\n",
      "\n",
      "Reconstruction error recall 0.0891\n",
      "Change: 3.5000%\n",
      "\n",
      "\u001b[1mEpoch 32\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3855\n",
      "Batch 222 Loss: 0.3775\n",
      "Batch 444 Loss: 0.4444\n",
      "Batch 666 Loss: 0.3867\n",
      "Batch 888 Loss: 0.3260\n",
      "\n",
      "EPOCH 32 LOSS: 0.3994\n",
      "\n",
      "Reconstruction error recall 0.0495\n",
      "Change: -0.4444%\n",
      "\n",
      "\u001b[1mEpoch 33\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3552\n",
      "Batch 222 Loss: 0.3390\n",
      "Batch 444 Loss: 0.3473\n",
      "Batch 666 Loss: 0.3373\n",
      "Batch 888 Loss: 0.3434\n",
      "\n",
      "EPOCH 33 LOSS: 0.3884\n",
      "\n",
      "Reconstruction error recall 0.0891\n",
      "Change: 0.8000%\n",
      "\n",
      "\u001b[1mEpoch 34\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3334\n",
      "Batch 222 Loss: 0.3498\n",
      "Batch 444 Loss: 0.3406\n",
      "Batch 666 Loss: 0.3520\n",
      "Batch 888 Loss: 0.2970\n",
      "\n",
      "EPOCH 34 LOSS: 0.3836\n",
      "\n",
      "Reconstruction error recall 0.0891\n",
      "Change: 0.0000%\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0629e-02.\n",
      "\n",
      "\u001b[1mEpoch 35\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3863\n",
      "Batch 222 Loss: 0.3441\n",
      "Batch 444 Loss: 0.3243\n",
      "Batch 666 Loss: 0.3475\n",
      "Batch 888 Loss: 0.3794\n",
      "\n",
      "EPOCH 35 LOSS: 0.3797\n",
      "\n",
      "Reconstruction error recall 0.0594\n",
      "Change: -0.3333%\n",
      "\n",
      "\u001b[1mEpoch 36\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3599\n",
      "Batch 222 Loss: 0.4970\n",
      "Batch 444 Loss: 0.3526\n",
      "Batch 666 Loss: 0.3957\n",
      "Batch 888 Loss: 0.3405\n",
      "\n",
      "EPOCH 36 LOSS: 0.3758\n",
      "\n",
      "Reconstruction error recall 0.0495\n",
      "Change: -0.1667%\n",
      "\n",
      "\u001b[1mEpoch 37\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3639\n",
      "Batch 222 Loss: 0.3563\n",
      "Batch 444 Loss: 0.3495\n",
      "Batch 666 Loss: 0.4215\n",
      "Batch 888 Loss: 0.3955\n",
      "\n",
      "EPOCH 37 LOSS: 0.3697\n",
      "\n",
      "Reconstruction error recall 0.0396\n",
      "Change: -0.2000%\n",
      "\n",
      "\u001b[1mEpoch 38\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3667\n",
      "Batch 222 Loss: 0.3279\n",
      "Batch 444 Loss: 0.3246\n",
      "Batch 666 Loss: 0.3451\n",
      "Batch 888 Loss: 0.3953\n",
      "\n",
      "EPOCH 38 LOSS: 0.3698\n",
      "\n",
      "Reconstruction error recall 0.0693\n",
      "Change: 0.7500%\n",
      "\n",
      "\u001b[1mEpoch 39\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 Loss: 0.3832\n",
      "Batch 222 Loss: 0.3299\n",
      "Batch 444 Loss: 0.3109\n",
      "Batch 666 Loss: 0.4096\n",
      "Batch 888 Loss: 0.3200\n",
      "\n",
      "EPOCH 39 LOSS: 0.3660\n",
      "\n",
      "Reconstruction error recall 0.0594\n",
      "Change: -0.1429%\n",
      "Epoch    39: reducing learning rate of group 0 to 9.5659e-03.\n",
      "\n",
      "\u001b[1mEpoch 40\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3145\n",
      "Batch 222 Loss: 0.3759\n",
      "Batch 444 Loss: 0.3606\n",
      "Batch 666 Loss: 0.4134\n",
      "Batch 888 Loss: 0.2971\n",
      "\n",
      "EPOCH 40 LOSS: 0.3626\n",
      "\n",
      "Reconstruction error recall 0.0594\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 41\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3436\n",
      "Batch 222 Loss: 0.3546\n",
      "Batch 444 Loss: 0.3113\n",
      "Batch 666 Loss: 0.3416\n",
      "Batch 888 Loss: 0.3593\n",
      "\n",
      "EPOCH 41 LOSS: 0.3620\n",
      "\n",
      "Reconstruction error recall 0.0495\n",
      "Change: -0.1667%\n",
      "\n",
      "\u001b[1mEpoch 42\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3401\n",
      "Batch 222 Loss: 0.3136\n",
      "Batch 444 Loss: 0.3059\n",
      "Batch 666 Loss: 0.4467\n",
      "Batch 888 Loss: 0.3053\n",
      "\n",
      "EPOCH 42 LOSS: 0.3599\n",
      "\n",
      "Reconstruction error recall 0.0396\n",
      "Change: -0.2000%\n",
      "\n",
      "\u001b[1mEpoch 43\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4845\n",
      "Batch 222 Loss: 0.3181\n",
      "Batch 444 Loss: 0.3436\n",
      "Batch 666 Loss: 0.3325\n",
      "Batch 888 Loss: 0.2859\n",
      "\n",
      "EPOCH 43 LOSS: 0.3576\n",
      "\n",
      "Reconstruction error recall 0.1089\n",
      "Change: 1.7500%\n",
      "\n",
      "\u001b[1mEpoch 44\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5788\n",
      "Batch 222 Loss: 0.3273\n",
      "Batch 444 Loss: 0.3242\n",
      "Batch 666 Loss: 0.3130\n",
      "Batch 888 Loss: 0.2826\n",
      "\n",
      "EPOCH 44 LOSS: 0.3540\n",
      "\n",
      "Reconstruction error recall 0.0594\n",
      "Change: -0.4545%\n",
      "Epoch    44: reducing learning rate of group 0 to 8.6093e-03.\n",
      "\n",
      "\u001b[1mEpoch 45\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3357\n",
      "Batch 222 Loss: 0.4875\n",
      "Batch 444 Loss: 0.4833\n",
      "Batch 666 Loss: 0.3461\n",
      "Batch 888 Loss: 0.3225\n",
      "\n",
      "EPOCH 45 LOSS: 0.3531\n",
      "\n",
      "Reconstruction error recall 0.0495\n",
      "Change: -0.1667%\n",
      "\n",
      "\u001b[1mEpoch 46\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3417\n",
      "Batch 222 Loss: 0.3310\n",
      "Batch 444 Loss: 0.3331\n",
      "Batch 666 Loss: 0.4176\n",
      "Batch 888 Loss: 0.3052\n",
      "\n",
      "EPOCH 46 LOSS: 0.3509\n",
      "\n",
      "Reconstruction error recall 0.0495\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 47\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3732\n",
      "Batch 222 Loss: 0.3142\n",
      "Batch 444 Loss: 0.3553\n",
      "Batch 666 Loss: 0.4793\n",
      "Batch 888 Loss: 0.3698\n",
      "\n",
      "EPOCH 47 LOSS: 0.3516\n",
      "\n",
      "Reconstruction error recall 0.0693\n",
      "Change: 0.4000%\n",
      "\n",
      "\u001b[1mEpoch 48\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2933\n",
      "Batch 222 Loss: 0.3054\n",
      "Batch 444 Loss: 0.4882\n",
      "Batch 666 Loss: 0.3392\n",
      "Batch 888 Loss: 0.3662\n",
      "\n",
      "EPOCH 48 LOSS: 0.3492\n",
      "\n",
      "Reconstruction error recall 0.0198\n",
      "Change: -0.7143%\n",
      "\n",
      "\u001b[1mEpoch 49\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3200\n",
      "Batch 222 Loss: 0.3098\n",
      "Batch 444 Loss: 0.3090\n",
      "Batch 666 Loss: 0.4117\n",
      "Batch 888 Loss: 0.2867\n",
      "\n",
      "EPOCH 49 LOSS: 0.3472\n",
      "\n",
      "Reconstruction error recall 0.0297\n",
      "Change: 0.5000%\n",
      "Epoch    49: reducing learning rate of group 0 to 7.7484e-03.\n",
      "\n",
      "\u001b[1mEpoch 50\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3394\n",
      "Batch 222 Loss: 0.3075\n",
      "Batch 444 Loss: 0.3761\n",
      "Batch 666 Loss: 0.3044\n",
      "Batch 888 Loss: 0.3393\n",
      "\n",
      "EPOCH 50 LOSS: 0.3462\n",
      "\n",
      "Reconstruction error recall 0.0495\n",
      "Change: 0.6667%\n",
      "\n",
      "\u001b[1mEpoch 51\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4587\n",
      "Batch 222 Loss: 0.3140\n",
      "Batch 444 Loss: 0.4898\n",
      "Batch 666 Loss: 0.4041\n",
      "Batch 888 Loss: 0.3172\n",
      "\n",
      "EPOCH 51 LOSS: 0.3477\n",
      "\n",
      "Reconstruction error recall 0.0693\n",
      "Change: 0.4000%\n",
      "\n",
      "\u001b[1mEpoch 52\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2872\n",
      "Batch 222 Loss: 0.3653\n",
      "Batch 444 Loss: 0.3746\n",
      "Batch 666 Loss: 0.3841\n",
      "Batch 888 Loss: 0.3664\n",
      "\n",
      "EPOCH 52 LOSS: 0.3455\n",
      "\n",
      "Reconstruction error recall 0.0594\n",
      "Change: -0.1429%\n",
      "\n",
      "\u001b[1mEpoch 53\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3337\n",
      "Batch 222 Loss: 0.3561\n",
      "Batch 444 Loss: 0.2936\n",
      "Batch 666 Loss: 0.4619\n",
      "Batch 888 Loss: 0.3131\n",
      "\n",
      "EPOCH 53 LOSS: 0.3452\n",
      "\n",
      "Reconstruction error recall 0.0990\n",
      "Change: 0.6667%\n",
      "\n",
      "\u001b[1mEpoch 54\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3355\n",
      "Batch 222 Loss: 0.3195\n",
      "Batch 444 Loss: 0.4956\n",
      "Batch 666 Loss: 0.3400\n",
      "Batch 888 Loss: 0.3518\n",
      "\n",
      "EPOCH 54 LOSS: 0.3442\n",
      "\n",
      "Reconstruction error recall 0.0693\n",
      "Change: -0.3000%\n",
      "Epoch    54: reducing learning rate of group 0 to 6.9736e-03.\n",
      "\n",
      "\u001b[1mEpoch 55\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3082\n",
      "Batch 222 Loss: 0.3120\n",
      "Batch 444 Loss: 0.3331\n",
      "Batch 666 Loss: 0.3176\n",
      "Batch 888 Loss: 0.4151\n",
      "\n",
      "EPOCH 55 LOSS: 0.3448\n",
      "\n",
      "Reconstruction error recall 0.0495\n",
      "Change: -0.2857%\n",
      "\n",
      "\u001b[1mEpoch 56\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3592\n",
      "Batch 222 Loss: 0.4180\n",
      "Batch 444 Loss: 0.3700\n",
      "Batch 666 Loss: 0.3426\n",
      "Batch 888 Loss: 0.3243\n",
      "\n",
      "EPOCH 56 LOSS: 0.3425\n",
      "\n",
      "Reconstruction error recall 0.0990\n",
      "Change: 1.0000%\n",
      "\n",
      "\u001b[1mEpoch 57\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3414\n",
      "Batch 222 Loss: 0.4029\n",
      "Batch 444 Loss: 0.2799\n",
      "Batch 666 Loss: 0.3358\n",
      "Batch 888 Loss: 0.2941\n",
      "\n",
      "EPOCH 57 LOSS: 0.3432\n",
      "\n",
      "Reconstruction error recall 0.0792\n",
      "Change: -0.2000%\n",
      "\n",
      "\u001b[1mEpoch 58\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3246\n",
      "Batch 222 Loss: 0.3472\n",
      "Batch 444 Loss: 0.3480\n",
      "Batch 666 Loss: 0.3208\n",
      "Batch 888 Loss: 0.2467\n",
      "\n",
      "EPOCH 58 LOSS: 0.3406\n",
      "\n",
      "Reconstruction error recall 0.0297\n",
      "Change: -0.6250%\n",
      "\n",
      "\u001b[1mEpoch 59\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3068\n",
      "Batch 222 Loss: 0.2934\n",
      "Batch 444 Loss: 0.3051\n",
      "Batch 666 Loss: 0.3103\n",
      "Batch 888 Loss: 0.3556\n",
      "\n",
      "EPOCH 59 LOSS: 0.3414\n",
      "\n",
      "Reconstruction error recall 0.0495\n",
      "Change: 0.6667%\n",
      "Epoch    59: reducing learning rate of group 0 to 6.2762e-03.\n",
      "\n",
      "\u001b[1mEpoch 60\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2978\n",
      "Batch 222 Loss: 0.3676\n",
      "Batch 444 Loss: 0.3050\n",
      "Batch 666 Loss: 0.3345\n",
      "Batch 888 Loss: 0.3433\n",
      "\n",
      "EPOCH 60 LOSS: 0.3408\n",
      "\n",
      "Reconstruction error recall 0.0297\n",
      "Change: -0.4000%\n",
      "\n",
      "\u001b[1mEpoch 61\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3126\n",
      "Batch 222 Loss: 0.3317\n",
      "Batch 444 Loss: 0.3404\n",
      "Batch 666 Loss: 0.3213\n",
      "Batch 888 Loss: 0.3012\n",
      "\n",
      "EPOCH 61 LOSS: 0.3405\n",
      "\n",
      "Reconstruction error recall 0.0693\n",
      "Change: 1.3333%\n",
      "\n",
      "\u001b[1mEpoch 62\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2867\n",
      "Batch 222 Loss: 0.4430\n",
      "Batch 444 Loss: 0.2935\n",
      "Batch 666 Loss: 0.3182\n",
      "Batch 888 Loss: 0.2696\n",
      "\n",
      "EPOCH 62 LOSS: 0.3407\n",
      "\n",
      "Reconstruction error recall 0.0990\n",
      "Change: 0.4286%\n",
      "\n",
      "\u001b[1mEpoch 63\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3214\n",
      "Batch 222 Loss: 0.2950\n",
      "Batch 444 Loss: 0.3183\n",
      "Batch 666 Loss: 0.3640\n",
      "Batch 888 Loss: 0.2740\n",
      "\n",
      "EPOCH 63 LOSS: 0.3404\n",
      "\n",
      "Reconstruction error recall 0.0099\n",
      "Change: -0.9000%\n",
      "\n",
      "\u001b[1mEpoch 64\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3442\n",
      "Batch 222 Loss: 0.3152\n",
      "Batch 444 Loss: 0.3902\n",
      "Batch 666 Loss: 0.3865\n",
      "Batch 888 Loss: 0.3137\n",
      "\n",
      "EPOCH 64 LOSS: 0.3402\n",
      "\n",
      "Reconstruction error recall 0.0594\n",
      "Change: 5.0000%\n",
      "Epoch    64: reducing learning rate of group 0 to 5.6486e-03.\n",
      "\n",
      "\u001b[1mEpoch 65\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3703\n",
      "Batch 222 Loss: 0.3184\n",
      "Batch 444 Loss: 0.2965\n",
      "Batch 666 Loss: 0.2911\n",
      "Batch 888 Loss: 0.2902\n",
      "\n",
      "EPOCH 65 LOSS: 0.3402\n",
      "\n",
      "Reconstruction error recall 0.0297\n",
      "Change: -0.5000%\n",
      "\n",
      "\u001b[1mEpoch 66\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3878\n",
      "Batch 222 Loss: 0.2877\n",
      "Batch 444 Loss: 0.4073\n",
      "Batch 666 Loss: 0.3685\n",
      "Batch 888 Loss: 0.2929\n",
      "\n",
      "EPOCH 66 LOSS: 0.3363\n",
      "\n",
      "Reconstruction error recall 0.0693\n",
      "Change: 1.3333%\n",
      "\n",
      "\u001b[1mEpoch 67\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3102\n",
      "Batch 222 Loss: 0.5217\n",
      "Batch 444 Loss: 0.3206\n",
      "Batch 666 Loss: 0.3260\n",
      "Batch 888 Loss: 0.3609\n",
      "\n",
      "EPOCH 67 LOSS: 0.3392\n",
      "\n",
      "Reconstruction error recall 0.0198\n",
      "Change: -0.7143%\n",
      "\n",
      "\u001b[1mEpoch 68\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3606\n",
      "Batch 222 Loss: 0.3133\n",
      "Batch 444 Loss: 0.3894\n",
      "Batch 666 Loss: 0.3398\n",
      "Batch 888 Loss: 0.3106\n",
      "\n",
      "EPOCH 68 LOSS: 0.3378\n",
      "\n",
      "Reconstruction error recall 0.0396\n",
      "Change: 1.0000%\n",
      "\n",
      "\u001b[1mEpoch 69\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2979\n",
      "Batch 222 Loss: 0.3114\n",
      "Batch 444 Loss: 0.2988\n",
      "Batch 666 Loss: 0.3126\n",
      "Batch 888 Loss: 0.3167\n",
      "\n",
      "EPOCH 69 LOSS: 0.3376\n",
      "\n",
      "Reconstruction error recall 0.0396\n",
      "Change: 0.0000%\n",
      "Epoch    69: reducing learning rate of group 0 to 5.0837e-03.\n",
      "\n",
      "\u001b[1mEpoch 70\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2974\n",
      "Batch 222 Loss: 0.3802\n",
      "Batch 444 Loss: 0.3702\n",
      "Batch 666 Loss: 0.3278\n",
      "Batch 888 Loss: 0.4194\n",
      "\n",
      "EPOCH 70 LOSS: 0.3359\n",
      "\n",
      "Reconstruction error recall 0.0297\n",
      "Change: -0.2500%\n",
      "\n",
      "\u001b[1mEpoch 71\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2896\n",
      "Batch 222 Loss: 0.3124\n",
      "Batch 444 Loss: 0.2921\n",
      "Batch 666 Loss: 0.3095\n",
      "Batch 888 Loss: 0.3084\n",
      "\n",
      "EPOCH 71 LOSS: 0.3350\n",
      "\n",
      "Reconstruction error recall 0.0693\n",
      "Change: 1.3333%\n",
      "\n",
      "\u001b[1mEpoch 72\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3795\n",
      "Batch 222 Loss: 0.3181\n",
      "Batch 444 Loss: 0.3008\n",
      "Batch 666 Loss: 0.4231\n",
      "Batch 888 Loss: 0.2903\n",
      "\n",
      "EPOCH 72 LOSS: 0.3367\n",
      "\n",
      "Reconstruction error recall 0.0594\n",
      "Change: -0.1429%\n",
      "\n",
      "\u001b[1mEpoch 73\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3026\n",
      "Batch 222 Loss: 0.3436\n",
      "Batch 444 Loss: 0.2821\n",
      "Batch 666 Loss: 0.3650\n",
      "Batch 888 Loss: 0.4764\n",
      "\n",
      "EPOCH 73 LOSS: 0.3344\n",
      "\n",
      "Reconstruction error recall 0.0891\n",
      "Change: 0.5000%\n",
      "\n",
      "\u001b[1mEpoch 74\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3432\n",
      "Batch 222 Loss: 0.3768\n",
      "Batch 444 Loss: 0.3479\n",
      "Batch 666 Loss: 0.6752\n",
      "Batch 888 Loss: 0.3219\n",
      "\n",
      "EPOCH 74 LOSS: 0.3340\n",
      "\n",
      "Reconstruction error recall 0.0693\n",
      "Change: -0.2222%\n",
      "Epoch    74: reducing learning rate of group 0 to 4.5754e-03.\n",
      "\n",
      "\u001b[1mEpoch 75\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3085\n",
      "Batch 222 Loss: 0.3902\n",
      "Batch 444 Loss: 0.2630\n",
      "Batch 666 Loss: 0.3538\n",
      "Batch 888 Loss: 0.2679\n",
      "\n",
      "EPOCH 75 LOSS: 0.3319\n",
      "\n",
      "Reconstruction error recall 0.0495\n",
      "Change: -0.2857%\n",
      "\n",
      "\u001b[1mEpoch 76\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 222 Loss: 0.5397\n",
      "Batch 444 Loss: 0.3343\n",
      "Batch 666 Loss: 0.3153\n",
      "Batch 888 Loss: 0.3083\n",
      "\n",
      "EPOCH 76 LOSS: 0.3320\n",
      "\n",
      "Reconstruction error recall 0.0495\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 77\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3109\n",
      "Batch 222 Loss: 0.3106\n",
      "Batch 444 Loss: 0.3967\n",
      "Batch 666 Loss: 0.3246\n",
      "Batch 888 Loss: 0.3530\n",
      "\n",
      "EPOCH 77 LOSS: 0.3317\n",
      "\n",
      "Reconstruction error recall 0.0396\n",
      "Change: -0.2000%\n",
      "\n",
      "\u001b[1mEpoch 78\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3665\n",
      "Batch 222 Loss: 0.3123\n",
      "Batch 444 Loss: 0.3017\n",
      "Batch 666 Loss: 0.3230\n",
      "Batch 888 Loss: 0.2849\n",
      "\n",
      "EPOCH 78 LOSS: 0.3306\n",
      "\n",
      "Reconstruction error recall 0.0297\n",
      "Change: -0.2500%\n",
      "\n",
      "\u001b[1mEpoch 79\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3707\n",
      "Batch 222 Loss: 0.4081\n",
      "Batch 444 Loss: 0.2870\n",
      "Batch 666 Loss: 0.3588\n",
      "Batch 888 Loss: 0.3440\n",
      "\n",
      "EPOCH 79 LOSS: 0.3309\n",
      "\n",
      "Reconstruction error recall 0.0594\n",
      "Change: 1.0000%\n",
      "Epoch    79: reducing learning rate of group 0 to 4.1178e-03.\n",
      "\n",
      "\u001b[1mEpoch 80\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3151\n",
      "Batch 222 Loss: 0.3304\n",
      "Batch 444 Loss: 0.2774\n",
      "Batch 666 Loss: 0.3049\n",
      "Batch 888 Loss: 0.3757\n",
      "\n",
      "EPOCH 80 LOSS: 0.3287\n",
      "\n",
      "Reconstruction error recall 0.0495\n",
      "Change: -0.1667%\n",
      "\n",
      "\u001b[1mEpoch 81\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2869\n",
      "Batch 222 Loss: 0.3160\n",
      "Batch 444 Loss: 0.3143\n",
      "Batch 666 Loss: 0.3761\n",
      "Batch 888 Loss: 0.2911\n",
      "\n",
      "EPOCH 81 LOSS: 0.3286\n",
      "\n",
      "Reconstruction error recall 0.0792\n",
      "Change: 0.6000%\n",
      "\n",
      "\u001b[1mEpoch 82\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2876\n",
      "Batch 222 Loss: 0.2825\n",
      "Batch 444 Loss: 0.2840\n",
      "Batch 666 Loss: 0.3216\n",
      "Batch 888 Loss: 0.2686\n",
      "\n",
      "EPOCH 82 LOSS: 0.3287\n",
      "\n",
      "Reconstruction error recall 0.0693\n",
      "Change: -0.1250%\n",
      "\n",
      "\u001b[1mEpoch 83\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3407\n",
      "Batch 222 Loss: 0.3076\n",
      "Batch 444 Loss: 0.3364\n",
      "Batch 666 Loss: 0.3765\n",
      "Batch 888 Loss: 0.3315\n",
      "\n",
      "EPOCH 83 LOSS: 0.3273\n",
      "\n",
      "Reconstruction error recall 0.0594\n",
      "Change: -0.1429%\n",
      "\n",
      "\u001b[1mEpoch 84\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2441\n",
      "Batch 222 Loss: 0.2992\n",
      "Batch 444 Loss: 0.3089\n",
      "Batch 666 Loss: 0.3070\n",
      "Batch 888 Loss: 0.3026\n",
      "\n",
      "EPOCH 84 LOSS: 0.3255\n",
      "\n",
      "Reconstruction error recall 0.0297\n",
      "Change: -0.5000%\n",
      "Epoch    84: reducing learning rate of group 0 to 3.7060e-03.\n",
      "\n",
      "\u001b[1mEpoch 85\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3405\n",
      "Batch 222 Loss: 0.2729\n",
      "Batch 444 Loss: 0.3546\n",
      "Batch 666 Loss: 0.3907\n",
      "Batch 888 Loss: 0.3043\n",
      "\n",
      "EPOCH 85 LOSS: 0.3248\n",
      "\n",
      "Reconstruction error recall 0.0495\n",
      "Change: 0.6667%\n",
      "\n",
      "\u001b[1mEpoch 86\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4029\n",
      "Batch 222 Loss: 0.2979\n",
      "Batch 444 Loss: 0.3544\n",
      "Batch 666 Loss: 0.2973\n",
      "Batch 888 Loss: 0.3124\n",
      "\n",
      "EPOCH 86 LOSS: 0.3264\n",
      "\n",
      "Reconstruction error recall 0.0594\n",
      "Change: 0.2000%\n",
      "\n",
      "\u001b[1mEpoch 87\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3157\n",
      "Batch 222 Loss: 0.3023\n",
      "Batch 444 Loss: 0.2987\n",
      "Batch 666 Loss: 0.3075\n",
      "Batch 888 Loss: 0.2610\n",
      "\n",
      "EPOCH 87 LOSS: 0.3266\n",
      "\n",
      "Reconstruction error recall 0.0594\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 88\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3109\n",
      "Batch 222 Loss: 0.3157\n",
      "Batch 444 Loss: 0.4113\n",
      "Batch 666 Loss: 0.2828\n",
      "Batch 888 Loss: 0.4278\n",
      "\n",
      "EPOCH 88 LOSS: 0.3257\n",
      "\n",
      "Reconstruction error recall 0.0297\n",
      "Change: -0.5000%\n",
      "\n",
      "\u001b[1mEpoch 89\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2969\n",
      "Batch 222 Loss: 0.3620\n",
      "Batch 444 Loss: 0.3451\n",
      "Batch 666 Loss: 0.2766\n",
      "Batch 888 Loss: 0.2963\n",
      "\n",
      "EPOCH 89 LOSS: 0.3246\n",
      "\n",
      "Reconstruction error recall 0.0693\n",
      "Change: 1.3333%\n",
      "Epoch    89: reducing learning rate of group 0 to 3.3354e-03.\n",
      "\n",
      "\u001b[1mEpoch 90\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3011\n",
      "Batch 222 Loss: 0.2621\n",
      "Batch 444 Loss: 0.3032\n",
      "Batch 666 Loss: 0.4578\n",
      "Batch 888 Loss: 0.3947\n",
      "\n",
      "EPOCH 90 LOSS: 0.3234\n",
      "\n",
      "Reconstruction error recall 0.0891\n",
      "Change: 0.2857%\n",
      "\n",
      "\u001b[1mEpoch 91\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2950\n",
      "Batch 222 Loss: 0.4993\n",
      "Batch 444 Loss: 0.2725\n",
      "Batch 666 Loss: 0.4187\n",
      "Batch 888 Loss: 0.4702\n",
      "\n",
      "EPOCH 91 LOSS: 0.3243\n",
      "\n",
      "Reconstruction error recall 0.0495\n",
      "Change: -0.4444%\n",
      "\n",
      "\u001b[1mEpoch 92\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3844\n",
      "Batch 222 Loss: 0.3648\n",
      "Batch 444 Loss: 0.4457\n",
      "Batch 666 Loss: 0.3344\n",
      "Batch 888 Loss: 0.3090\n",
      "\n",
      "EPOCH 92 LOSS: 0.3239\n",
      "\n",
      "Reconstruction error recall 0.0792\n",
      "Change: 0.6000%\n",
      "\n",
      "\u001b[1mEpoch 93\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2869\n",
      "Batch 222 Loss: 0.2638\n",
      "Batch 444 Loss: 0.2924\n",
      "Batch 666 Loss: 0.2907\n",
      "Batch 888 Loss: 0.3616\n",
      "\n",
      "EPOCH 93 LOSS: 0.3232\n",
      "\n",
      "Reconstruction error recall 0.0396\n",
      "Change: -0.5000%\n",
      "\n",
      "\u001b[1mEpoch 94\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3305\n",
      "Batch 222 Loss: 0.2664\n",
      "Batch 444 Loss: 0.3881\n",
      "Batch 666 Loss: 0.3164\n",
      "Batch 888 Loss: 0.3031\n",
      "\n",
      "EPOCH 94 LOSS: 0.3223\n",
      "\n",
      "Reconstruction error recall 0.0495\n",
      "Change: 0.2500%\n",
      "Epoch    94: reducing learning rate of group 0 to 3.0019e-03.\n",
      "\n",
      "\u001b[1mEpoch 95\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2870\n",
      "Batch 222 Loss: 0.3097\n",
      "Batch 444 Loss: 0.3637\n",
      "Batch 666 Loss: 0.3093\n",
      "Batch 888 Loss: 0.3628\n",
      "\n",
      "EPOCH 95 LOSS: 0.3235\n",
      "\n",
      "Reconstruction error recall 0.0693\n",
      "Change: 0.4000%\n",
      "\n",
      "\u001b[1mEpoch 96\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3317\n",
      "Batch 222 Loss: 0.4797\n",
      "Batch 444 Loss: 0.3216\n",
      "Batch 666 Loss: 0.2872\n",
      "Batch 888 Loss: 0.3354\n",
      "\n",
      "EPOCH 96 LOSS: 0.3217\n",
      "\n",
      "Reconstruction error recall 0.0396\n",
      "Change: -0.4286%\n",
      "\n",
      "\u001b[1mEpoch 97\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3123\n",
      "Batch 222 Loss: 0.2635\n",
      "Batch 444 Loss: 0.3016\n",
      "Batch 666 Loss: 0.3062\n",
      "Batch 888 Loss: 0.2762\n",
      "\n",
      "EPOCH 97 LOSS: 0.3216\n",
      "\n",
      "Reconstruction error recall 0.0495\n",
      "Change: 0.2500%\n",
      "\n",
      "\u001b[1mEpoch 98\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3318\n",
      "Batch 222 Loss: 0.3254\n",
      "Batch 444 Loss: 0.3554\n",
      "Batch 666 Loss: 0.3300\n",
      "Batch 888 Loss: 0.3272\n",
      "\n",
      "EPOCH 98 LOSS: 0.3231\n",
      "\n",
      "Reconstruction error recall 0.0891\n",
      "Change: 0.8000%\n",
      "\n",
      "\u001b[1mEpoch 99\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3525\n",
      "Batch 222 Loss: 0.3199\n",
      "Batch 444 Loss: 0.3133\n",
      "Batch 666 Loss: 0.2836\n",
      "Batch 888 Loss: 0.3390\n",
      "\n",
      "EPOCH 99 LOSS: 0.3212\n",
      "\n",
      "Reconstruction error recall 0.0792\n",
      "Change: -0.1111%\n",
      "Epoch    99: reducing learning rate of group 0 to 2.7017e-03.\n",
      "\n",
      "\u001b[1mEpoch 100\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3173\n",
      "Batch 222 Loss: 0.3610\n",
      "Batch 444 Loss: 0.6807\n",
      "Batch 666 Loss: 0.3419\n",
      "Batch 888 Loss: 0.2412\n",
      "\n",
      "EPOCH 100 LOSS: 0.3217\n",
      "\n",
      "Reconstruction error recall 0.0099\n",
      "Change: -0.8750%\n"
     ]
    }
   ],
   "source": [
    "#Start with high learning rate\n",
    "optimizer = torch.optim.SGD(ae1.parameters(), lr=0.02, momentum=0.9,nesterov=True)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.9, patience=4, verbose=True)\n",
    "train_autoencoder(model=ae1,\n",
    "                   dataset=normal_torch,\n",
    "                   loss_func=loss_func,\n",
    "                   optimizer=optimizer,\n",
    "                   batch_size=256,\n",
    "                   epochs=100,\n",
    "                   lr_rate_scheduler=scheduler,\n",
    "                   validation_tensor=val_torch,\n",
    "                   y_val = y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "output1 = ae1(normal_torch)\n",
    "train_output1 = ae1(train_torch)\n",
    "val_output1 = ae1(val_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder II: L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae2 = AutoEncoder(n_features,n_features)\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mEpoch 1\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5115\n",
      "Batch 222 Loss: 0.8374\n",
      "Batch 444 Loss: 0.4493\n",
      "Batch 666 Loss: 0.5553\n",
      "Batch 888 Loss: 0.5016\n",
      "\n",
      "EPOCH 1 LOSS: 0.6490\n",
      "\n",
      "Reconstruction error recall: 0.2079\n",
      "\n",
      "\u001b[1mEpoch 2\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7040\n",
      "Batch 222 Loss: 0.5675\n",
      "Batch 444 Loss: 0.5542\n",
      "Batch 666 Loss: 0.5440\n",
      "Batch 888 Loss: 1.6456\n",
      "\n",
      "EPOCH 2 LOSS: 0.6498\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 3\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5355\n",
      "Batch 222 Loss: 0.5429\n",
      "Batch 444 Loss: 0.5103\n",
      "Batch 666 Loss: 0.6005\n",
      "Batch 888 Loss: 0.7870\n",
      "\n",
      "EPOCH 3 LOSS: 0.6548\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 4\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7061\n",
      "Batch 222 Loss: 0.5226\n",
      "Batch 444 Loss: 0.7563\n",
      "Batch 666 Loss: 0.6665\n",
      "Batch 888 Loss: 0.7538\n",
      "\n",
      "EPOCH 4 LOSS: 0.6543\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch     4: reducing learning rate of group 0 to 1.8000e-01.\n",
      "\n",
      "\u001b[1mEpoch 5\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5517\n",
      "Batch 222 Loss: 0.6649\n",
      "Batch 444 Loss: 0.9220\n",
      "Batch 666 Loss: 0.8240\n",
      "Batch 888 Loss: 0.4064\n",
      "\n",
      "EPOCH 5 LOSS: 0.6492\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 6\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5108\n",
      "Batch 222 Loss: 0.5743\n",
      "Batch 444 Loss: 0.5363\n",
      "Batch 666 Loss: 0.5019\n",
      "Batch 888 Loss: 0.6461\n",
      "\n",
      "EPOCH 6 LOSS: 0.6507\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 7\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5796\n",
      "Batch 222 Loss: 0.8089\n",
      "Batch 444 Loss: 0.5779\n",
      "Batch 666 Loss: 0.7183\n",
      "Batch 888 Loss: 0.4842\n",
      "\n",
      "EPOCH 7 LOSS: 0.6514\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch     7: reducing learning rate of group 0 to 1.6200e-01.\n",
      "\n",
      "\u001b[1mEpoch 8\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5346\n",
      "Batch 222 Loss: 0.7570\n",
      "Batch 444 Loss: 0.6202\n",
      "Batch 666 Loss: 0.6058\n",
      "Batch 888 Loss: 0.9533\n",
      "\n",
      "EPOCH 8 LOSS: 0.6507\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 9\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7127\n",
      "Batch 222 Loss: 0.8789\n",
      "Batch 444 Loss: 0.5417\n",
      "Batch 666 Loss: 0.7736\n",
      "Batch 888 Loss: 0.7883\n",
      "\n",
      "EPOCH 9 LOSS: 0.6480\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 10\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7080\n",
      "Batch 222 Loss: 0.6106\n",
      "Batch 444 Loss: 1.2404\n",
      "Batch 666 Loss: 0.6225\n",
      "Batch 888 Loss: 0.4802\n",
      "\n",
      "EPOCH 10 LOSS: 0.6493\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    10: reducing learning rate of group 0 to 1.4580e-01.\n",
      "\n",
      "\u001b[1mEpoch 11\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5832\n",
      "Batch 222 Loss: 0.6411\n",
      "Batch 444 Loss: 0.6573\n",
      "Batch 666 Loss: 0.5677\n",
      "Batch 888 Loss: 0.5495\n",
      "\n",
      "EPOCH 11 LOSS: 0.6481\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 12\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5478\n",
      "Batch 222 Loss: 0.5176\n",
      "Batch 444 Loss: 0.8317\n",
      "Batch 666 Loss: 1.0495\n",
      "Batch 888 Loss: 0.6129\n",
      "\n",
      "EPOCH 12 LOSS: 0.6493\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 13\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7218\n",
      "Batch 222 Loss: 0.8943\n",
      "Batch 444 Loss: 0.4890\n",
      "Batch 666 Loss: 0.6141\n",
      "Batch 888 Loss: 0.6111\n",
      "\n",
      "EPOCH 13 LOSS: 0.6461\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    13: reducing learning rate of group 0 to 1.3122e-01.\n",
      "\n",
      "\u001b[1mEpoch 14\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4951\n",
      "Batch 222 Loss: 1.4269\n",
      "Batch 444 Loss: 0.7768\n",
      "Batch 666 Loss: 0.5398\n",
      "Batch 888 Loss: 0.6984\n",
      "\n",
      "EPOCH 14 LOSS: 0.6480\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 15\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6281\n",
      "Batch 222 Loss: 0.4520\n",
      "Batch 444 Loss: 0.5096\n",
      "Batch 666 Loss: 0.5316\n",
      "Batch 888 Loss: 0.5401\n",
      "\n",
      "EPOCH 15 LOSS: 0.6479\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 16\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5396\n",
      "Batch 222 Loss: 0.5510\n",
      "Batch 444 Loss: 0.5605\n",
      "Batch 666 Loss: 0.7311\n",
      "Batch 888 Loss: 0.4728\n",
      "\n",
      "EPOCH 16 LOSS: 0.6475\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    16: reducing learning rate of group 0 to 1.1810e-01.\n",
      "\n",
      "\u001b[1mEpoch 17\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4824\n",
      "Batch 222 Loss: 0.6190\n",
      "Batch 444 Loss: 0.7792\n",
      "Batch 666 Loss: 0.5987\n",
      "Batch 888 Loss: 0.4828\n",
      "\n",
      "EPOCH 17 LOSS: 0.6470\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 18\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5956\n",
      "Batch 222 Loss: 0.4869\n",
      "Batch 444 Loss: 0.5844\n",
      "Batch 666 Loss: 0.5003\n",
      "Batch 888 Loss: 1.2759\n",
      "\n",
      "EPOCH 18 LOSS: 0.6490\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 19\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8200\n",
      "Batch 222 Loss: 0.5955\n",
      "Batch 444 Loss: 0.6079\n",
      "Batch 666 Loss: 0.6762\n",
      "Batch 888 Loss: 1.1132\n",
      "\n",
      "EPOCH 19 LOSS: 0.6485\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0629e-01.\n",
      "\n",
      "\u001b[1mEpoch 20\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6815\n",
      "Batch 222 Loss: 0.4810\n",
      "Batch 444 Loss: 0.4810\n",
      "Batch 666 Loss: 0.6911\n",
      "Batch 888 Loss: 0.5520\n",
      "\n",
      "EPOCH 20 LOSS: 0.6463\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 21\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8801\n",
      "Batch 222 Loss: 1.0395\n",
      "Batch 444 Loss: 0.5309\n",
      "Batch 666 Loss: 0.4865\n",
      "Batch 888 Loss: 0.5377\n",
      "\n",
      "EPOCH 21 LOSS: 0.6462\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 22\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6400\n",
      "Batch 222 Loss: 0.4950\n",
      "Batch 444 Loss: 0.7542\n",
      "Batch 666 Loss: 0.5133\n",
      "Batch 888 Loss: 1.1523\n",
      "\n",
      "EPOCH 22 LOSS: 0.6462\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    22: reducing learning rate of group 0 to 9.5659e-02.\n",
      "\n",
      "\u001b[1mEpoch 23\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5560\n",
      "Batch 222 Loss: 0.5774\n",
      "Batch 444 Loss: 0.7552\n",
      "Batch 666 Loss: 0.6731\n",
      "Batch 888 Loss: 0.4880\n",
      "\n",
      "EPOCH 23 LOSS: 0.6464\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 24\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5860\n",
      "Batch 222 Loss: 0.5224\n",
      "Batch 444 Loss: 0.5858\n",
      "Batch 666 Loss: 0.4777\n",
      "Batch 888 Loss: 0.4752\n",
      "\n",
      "EPOCH 24 LOSS: 0.6456\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 25\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5092\n",
      "Batch 222 Loss: 0.5805\n",
      "Batch 444 Loss: 0.5436\n",
      "Batch 666 Loss: 0.8925\n",
      "Batch 888 Loss: 0.4986\n",
      "\n",
      "EPOCH 25 LOSS: 0.6453\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    25: reducing learning rate of group 0 to 8.6093e-02.\n",
      "\n",
      "\u001b[1mEpoch 26\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6717\n",
      "Batch 222 Loss: 0.5362\n",
      "Batch 444 Loss: 0.5641\n",
      "Batch 666 Loss: 0.5530\n",
      "Batch 888 Loss: 0.5554\n",
      "\n",
      "EPOCH 26 LOSS: 0.6446\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 27\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5660\n",
      "Batch 222 Loss: 0.8504\n",
      "Batch 444 Loss: 0.5536\n",
      "Batch 666 Loss: 0.5231\n",
      "Batch 888 Loss: 0.6430\n",
      "\n",
      "EPOCH 27 LOSS: 0.6452\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 28\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.9542\n",
      "Batch 222 Loss: 0.7168\n",
      "Batch 444 Loss: 0.5601\n",
      "Batch 666 Loss: 0.5254\n",
      "Batch 888 Loss: 0.9464\n",
      "\n",
      "EPOCH 28 LOSS: 0.6446\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    28: reducing learning rate of group 0 to 7.7484e-02.\n",
      "\n",
      "\u001b[1mEpoch 29\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4852\n",
      "Batch 222 Loss: 0.5496\n",
      "Batch 444 Loss: 0.9127\n",
      "Batch 666 Loss: 0.5589\n",
      "Batch 888 Loss: 0.5321\n",
      "\n",
      "EPOCH 29 LOSS: 0.6436\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 30\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7498\n",
      "Batch 222 Loss: 0.5322\n",
      "Batch 444 Loss: 0.5687\n",
      "Batch 666 Loss: 0.5757\n",
      "Batch 888 Loss: 0.6547\n",
      "\n",
      "EPOCH 30 LOSS: 0.6454\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 31\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5406\n",
      "Batch 222 Loss: 0.6632\n",
      "Batch 444 Loss: 0.6828\n",
      "Batch 666 Loss: 0.5440\n",
      "Batch 888 Loss: 0.4784\n",
      "\n",
      "EPOCH 31 LOSS: 0.6457\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    31: reducing learning rate of group 0 to 6.9736e-02.\n",
      "\n",
      "\u001b[1mEpoch 32\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5412\n",
      "Batch 222 Loss: 0.5635\n",
      "Batch 444 Loss: 0.5113\n",
      "Batch 666 Loss: 0.6415\n",
      "Batch 888 Loss: 1.4982\n",
      "\n",
      "EPOCH 32 LOSS: 0.6446\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 33\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5170\n",
      "Batch 222 Loss: 0.4780\n",
      "Batch 444 Loss: 0.5676\n",
      "Batch 666 Loss: 0.5944\n",
      "Batch 888 Loss: 0.6204\n",
      "\n",
      "EPOCH 33 LOSS: 0.6444\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 34\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5110\n",
      "Batch 222 Loss: 0.5189\n",
      "Batch 444 Loss: 0.7185\n",
      "Batch 666 Loss: 0.5958\n",
      "Batch 888 Loss: 0.5239\n",
      "\n",
      "EPOCH 34 LOSS: 0.6439\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    34: reducing learning rate of group 0 to 6.2762e-02.\n",
      "\n",
      "\u001b[1mEpoch 35\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6279\n",
      "Batch 222 Loss: 0.4387\n",
      "Batch 444 Loss: 0.4935\n",
      "Batch 666 Loss: 0.4412\n",
      "Batch 888 Loss: 0.6469\n",
      "\n",
      "EPOCH 35 LOSS: 0.6439\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 36\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4820\n",
      "Batch 222 Loss: 0.6249\n",
      "Batch 444 Loss: 0.6883\n",
      "Batch 666 Loss: 0.6981\n",
      "Batch 888 Loss: 0.5355\n",
      "\n",
      "EPOCH 36 LOSS: 0.6444\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 37\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5064\n",
      "Batch 222 Loss: 0.7146\n",
      "Batch 444 Loss: 1.1677\n",
      "Batch 666 Loss: 0.7792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 888 Loss: 0.4321\n",
      "\n",
      "EPOCH 37 LOSS: 0.6436\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    37: reducing learning rate of group 0 to 5.6486e-02.\n",
      "\n",
      "\u001b[1mEpoch 38\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5327\n",
      "Batch 222 Loss: 0.9532\n",
      "Batch 444 Loss: 0.6344\n",
      "Batch 666 Loss: 0.5251\n",
      "Batch 888 Loss: 1.0807\n",
      "\n",
      "EPOCH 38 LOSS: 0.6444\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 39\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5375\n",
      "Batch 222 Loss: 0.5572\n",
      "Batch 444 Loss: 0.5385\n",
      "Batch 666 Loss: 0.4820\n",
      "Batch 888 Loss: 1.1792\n",
      "\n",
      "EPOCH 39 LOSS: 0.6441\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 40\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7576\n",
      "Batch 222 Loss: 0.5244\n",
      "Batch 444 Loss: 0.5185\n",
      "Batch 666 Loss: 0.5095\n",
      "Batch 888 Loss: 0.5638\n",
      "\n",
      "EPOCH 40 LOSS: 0.6440\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    40: reducing learning rate of group 0 to 5.0837e-02.\n",
      "\n",
      "\u001b[1mEpoch 41\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4971\n",
      "Batch 222 Loss: 0.7727\n",
      "Batch 444 Loss: 0.7027\n",
      "Batch 666 Loss: 0.5498\n",
      "Batch 888 Loss: 0.4948\n",
      "\n",
      "EPOCH 41 LOSS: 0.6438\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 42\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5896\n",
      "Batch 222 Loss: 0.7177\n",
      "Batch 444 Loss: 0.5309\n",
      "Batch 666 Loss: 0.7560\n",
      "Batch 888 Loss: 0.5921\n",
      "\n",
      "EPOCH 42 LOSS: 0.6434\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 43\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5563\n",
      "Batch 222 Loss: 0.5690\n",
      "Batch 444 Loss: 0.5246\n",
      "Batch 666 Loss: 0.5979\n",
      "Batch 888 Loss: 0.4680\n",
      "\n",
      "EPOCH 43 LOSS: 0.6447\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    43: reducing learning rate of group 0 to 4.5754e-02.\n",
      "\n",
      "\u001b[1mEpoch 44\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5282\n",
      "Batch 222 Loss: 0.6657\n",
      "Batch 444 Loss: 0.8866\n",
      "Batch 666 Loss: 0.5234\n",
      "Batch 888 Loss: 0.4157\n",
      "\n",
      "EPOCH 44 LOSS: 0.6434\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 45\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4719\n",
      "Batch 222 Loss: 0.9430\n",
      "Batch 444 Loss: 0.6815\n",
      "Batch 666 Loss: 0.5629\n",
      "Batch 888 Loss: 0.5068\n",
      "\n",
      "EPOCH 45 LOSS: 0.6434\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 46\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6143\n",
      "Batch 222 Loss: 0.4765\n",
      "Batch 444 Loss: 0.7439\n",
      "Batch 666 Loss: 0.4955\n",
      "Batch 888 Loss: 0.8696\n",
      "\n",
      "EPOCH 46 LOSS: 0.6435\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    46: reducing learning rate of group 0 to 4.1178e-02.\n",
      "\n",
      "\u001b[1mEpoch 47\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7020\n",
      "Batch 222 Loss: 0.6799\n",
      "Batch 444 Loss: 0.5065\n",
      "Batch 666 Loss: 0.5789\n",
      "Batch 888 Loss: 0.5580\n",
      "\n",
      "EPOCH 47 LOSS: 0.6432\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 48\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7738\n",
      "Batch 222 Loss: 0.6784\n",
      "Batch 444 Loss: 1.5102\n",
      "Batch 666 Loss: 0.6998\n",
      "Batch 888 Loss: 0.4709\n",
      "\n",
      "EPOCH 48 LOSS: 0.6431\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 49\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7813\n",
      "Batch 222 Loss: 0.6471\n",
      "Batch 444 Loss: 0.4846\n",
      "Batch 666 Loss: 0.5396\n",
      "Batch 888 Loss: 0.8811\n",
      "\n",
      "EPOCH 49 LOSS: 0.6436\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    49: reducing learning rate of group 0 to 3.7060e-02.\n",
      "\n",
      "\u001b[1mEpoch 50\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5979\n",
      "Batch 222 Loss: 0.6281\n",
      "Batch 444 Loss: 0.6111\n",
      "Batch 666 Loss: 0.7282\n",
      "Batch 888 Loss: 0.4818\n",
      "\n",
      "EPOCH 50 LOSS: 0.6433\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 51\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5156\n",
      "Batch 222 Loss: 0.4369\n",
      "Batch 444 Loss: 0.5937\n",
      "Batch 666 Loss: 0.5576\n",
      "Batch 888 Loss: 0.7668\n",
      "\n",
      "EPOCH 51 LOSS: 0.6434\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 52\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.0408\n",
      "Batch 222 Loss: 0.5707\n",
      "Batch 444 Loss: 0.7985\n",
      "Batch 666 Loss: 0.5031\n",
      "Batch 888 Loss: 0.5861\n",
      "\n",
      "EPOCH 52 LOSS: 0.6433\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    52: reducing learning rate of group 0 to 3.3354e-02.\n",
      "\n",
      "\u001b[1mEpoch 53\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5357\n",
      "Batch 222 Loss: 0.4935\n",
      "Batch 444 Loss: 0.5327\n",
      "Batch 666 Loss: 0.4894\n",
      "Batch 888 Loss: 0.5266\n",
      "\n",
      "EPOCH 53 LOSS: 0.6432\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 54\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8282\n",
      "Batch 222 Loss: 0.8017\n",
      "Batch 444 Loss: 0.4704\n",
      "Batch 666 Loss: 0.6440\n",
      "Batch 888 Loss: 0.5593\n",
      "\n",
      "EPOCH 54 LOSS: 0.6432\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 55\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6488\n",
      "Batch 222 Loss: 0.5513\n",
      "Batch 444 Loss: 0.7834\n",
      "Batch 666 Loss: 0.7802\n",
      "Batch 888 Loss: 0.5114\n",
      "\n",
      "EPOCH 55 LOSS: 0.6433\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    55: reducing learning rate of group 0 to 3.0019e-02.\n",
      "\n",
      "\u001b[1mEpoch 56\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5128\n",
      "Batch 222 Loss: 1.0427\n",
      "Batch 444 Loss: 0.5313\n",
      "Batch 666 Loss: 0.6992\n",
      "Batch 888 Loss: 1.0165\n",
      "\n",
      "EPOCH 56 LOSS: 0.6432\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 57\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6503\n",
      "Batch 222 Loss: 1.3337\n",
      "Batch 444 Loss: 0.6356\n",
      "Batch 666 Loss: 0.6205\n",
      "Batch 888 Loss: 1.0010\n",
      "\n",
      "EPOCH 57 LOSS: 0.6436\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 58\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7954\n",
      "Batch 222 Loss: 0.6478\n",
      "Batch 444 Loss: 0.5411\n",
      "Batch 666 Loss: 0.6987\n",
      "Batch 888 Loss: 0.5306\n",
      "\n",
      "EPOCH 58 LOSS: 0.6432\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    58: reducing learning rate of group 0 to 2.7017e-02.\n",
      "\n",
      "\u001b[1mEpoch 59\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5314\n",
      "Batch 222 Loss: 0.8176\n",
      "Batch 444 Loss: 0.8144\n",
      "Batch 666 Loss: 0.6208\n",
      "Batch 888 Loss: 0.4385\n",
      "\n",
      "EPOCH 59 LOSS: 0.6431\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 60\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.9906\n",
      "Batch 222 Loss: 0.6380\n",
      "Batch 444 Loss: 0.8402\n",
      "Batch 666 Loss: 0.5128\n",
      "Batch 888 Loss: 0.5585\n",
      "\n",
      "EPOCH 60 LOSS: 0.6429\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 61\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5620\n",
      "Batch 222 Loss: 0.5288\n",
      "Batch 444 Loss: 0.6708\n",
      "Batch 666 Loss: 0.4686\n",
      "Batch 888 Loss: 0.5816\n",
      "\n",
      "EPOCH 61 LOSS: 0.6433\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    61: reducing learning rate of group 0 to 2.4315e-02.\n",
      "\n",
      "\u001b[1mEpoch 62\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5293\n",
      "Batch 222 Loss: 0.6228\n",
      "Batch 444 Loss: 0.5616\n",
      "Batch 666 Loss: 0.5625\n",
      "Batch 888 Loss: 0.5462\n",
      "\n",
      "EPOCH 62 LOSS: 0.6429\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 63\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.9929\n",
      "Batch 222 Loss: 0.5577\n",
      "Batch 444 Loss: 0.6407\n",
      "Batch 666 Loss: 0.6422\n",
      "Batch 888 Loss: 0.5515\n",
      "\n",
      "EPOCH 63 LOSS: 0.6430\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 64\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6334\n",
      "Batch 222 Loss: 0.4892\n",
      "Batch 444 Loss: 0.5201\n",
      "Batch 666 Loss: 0.8332\n",
      "Batch 888 Loss: 0.6467\n",
      "\n",
      "EPOCH 64 LOSS: 0.6430\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    64: reducing learning rate of group 0 to 2.1884e-02.\n",
      "\n",
      "\u001b[1mEpoch 65\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8506\n",
      "Batch 222 Loss: 0.7158\n",
      "Batch 444 Loss: 0.5342\n",
      "Batch 666 Loss: 0.5263\n",
      "Batch 888 Loss: 0.5715\n",
      "\n",
      "EPOCH 65 LOSS: 0.6429\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 66\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5441\n",
      "Batch 222 Loss: 0.5811\n",
      "Batch 444 Loss: 0.5957\n",
      "Batch 666 Loss: 0.8245\n",
      "Batch 888 Loss: 0.5360\n",
      "\n",
      "EPOCH 66 LOSS: 0.6429\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 67\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5473\n",
      "Batch 222 Loss: 0.5314\n",
      "Batch 444 Loss: 0.6616\n",
      "Batch 666 Loss: 0.8057\n",
      "Batch 888 Loss: 0.4770\n",
      "\n",
      "EPOCH 67 LOSS: 0.6428\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    67: reducing learning rate of group 0 to 1.9695e-02.\n",
      "\n",
      "\u001b[1mEpoch 68\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6090\n",
      "Batch 222 Loss: 1.0588\n",
      "Batch 444 Loss: 0.5618\n",
      "Batch 666 Loss: 0.5707\n",
      "Batch 888 Loss: 0.6309\n",
      "\n",
      "EPOCH 68 LOSS: 0.6429\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 69\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4979\n",
      "Batch 222 Loss: 1.0542\n",
      "Batch 444 Loss: 0.5232\n",
      "Batch 666 Loss: 0.7987\n",
      "Batch 888 Loss: 0.6523\n",
      "\n",
      "EPOCH 69 LOSS: 0.6431\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 70\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7316\n",
      "Batch 222 Loss: 0.4820\n",
      "Batch 444 Loss: 0.5013\n",
      "Batch 666 Loss: 0.8368\n",
      "Batch 888 Loss: 0.5925\n",
      "\n",
      "EPOCH 70 LOSS: 0.6429\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    70: reducing learning rate of group 0 to 1.7726e-02.\n",
      "\n",
      "\u001b[1mEpoch 71\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.0229\n",
      "Batch 222 Loss: 0.5163\n",
      "Batch 444 Loss: 0.4565\n",
      "Batch 666 Loss: 0.5723\n",
      "Batch 888 Loss: 0.5168\n",
      "\n",
      "EPOCH 71 LOSS: 0.6429\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 72\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6828\n",
      "Batch 222 Loss: 0.4588\n",
      "Batch 444 Loss: 0.8272\n",
      "Batch 666 Loss: 0.7323\n",
      "Batch 888 Loss: 0.4557\n",
      "\n",
      "EPOCH 72 LOSS: 0.6429\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 73\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5463\n",
      "Batch 222 Loss: 0.6678\n",
      "Batch 444 Loss: 0.8306\n",
      "Batch 666 Loss: 0.7788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 888 Loss: 0.5774\n",
      "\n",
      "EPOCH 73 LOSS: 0.6429\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    73: reducing learning rate of group 0 to 1.5953e-02.\n",
      "\n",
      "\u001b[1mEpoch 74\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7559\n",
      "Batch 222 Loss: 0.5803\n",
      "Batch 444 Loss: 0.5087\n",
      "Batch 666 Loss: 0.5226\n",
      "Batch 888 Loss: 0.5133\n",
      "\n",
      "EPOCH 74 LOSS: 0.6429\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 75\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6443\n",
      "Batch 222 Loss: 0.4779\n",
      "Batch 444 Loss: 0.7026\n",
      "Batch 666 Loss: 0.5251\n",
      "Batch 888 Loss: 1.1018\n",
      "\n",
      "EPOCH 75 LOSS: 0.6431\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 76\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5662\n",
      "Batch 222 Loss: 0.8769\n",
      "Batch 444 Loss: 0.8016\n",
      "Batch 666 Loss: 0.6007\n",
      "Batch 888 Loss: 0.6057\n",
      "\n",
      "EPOCH 76 LOSS: 0.6429\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    76: reducing learning rate of group 0 to 1.4358e-02.\n",
      "\n",
      "\u001b[1mEpoch 77\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6362\n",
      "Batch 222 Loss: 0.6411\n",
      "Batch 444 Loss: 0.6095\n",
      "Batch 666 Loss: 0.5535\n",
      "Batch 888 Loss: 0.7551\n",
      "\n",
      "EPOCH 77 LOSS: 0.6429\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 78\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5168\n",
      "Batch 222 Loss: 0.5422\n",
      "Batch 444 Loss: 0.6749\n",
      "Batch 666 Loss: 0.4780\n",
      "Batch 888 Loss: 0.9112\n",
      "\n",
      "EPOCH 78 LOSS: 0.6431\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 79\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8203\n",
      "Batch 222 Loss: 0.7854\n",
      "Batch 444 Loss: 0.5582\n",
      "Batch 666 Loss: 0.5537\n",
      "Batch 888 Loss: 0.4849\n",
      "\n",
      "EPOCH 79 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    79: reducing learning rate of group 0 to 1.2922e-02.\n",
      "\n",
      "\u001b[1mEpoch 80\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.1910\n",
      "Batch 222 Loss: 0.5963\n",
      "Batch 444 Loss: 0.5658\n",
      "Batch 666 Loss: 0.7357\n",
      "Batch 888 Loss: 0.5504\n",
      "\n",
      "EPOCH 80 LOSS: 0.6428\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 81\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6198\n",
      "Batch 222 Loss: 0.7188\n",
      "Batch 444 Loss: 0.6823\n",
      "Batch 666 Loss: 0.8036\n",
      "Batch 888 Loss: 0.6819\n",
      "\n",
      "EPOCH 81 LOSS: 0.6428\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 82\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7474\n",
      "Batch 222 Loss: 0.6231\n",
      "Batch 444 Loss: 0.5537\n",
      "Batch 666 Loss: 0.6054\n",
      "Batch 888 Loss: 0.7160\n",
      "\n",
      "EPOCH 82 LOSS: 0.6429\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    82: reducing learning rate of group 0 to 1.1630e-02.\n",
      "\n",
      "\u001b[1mEpoch 83\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6743\n",
      "Batch 222 Loss: 0.6100\n",
      "Batch 444 Loss: 0.8063\n",
      "Batch 666 Loss: 0.5221\n",
      "Batch 888 Loss: 0.7201\n",
      "\n",
      "EPOCH 83 LOSS: 0.6428\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 84\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4902\n",
      "Batch 222 Loss: 0.5712\n",
      "Batch 444 Loss: 0.5652\n",
      "Batch 666 Loss: 0.6442\n",
      "Batch 888 Loss: 0.5134\n",
      "\n",
      "EPOCH 84 LOSS: 0.6428\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 85\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6196\n",
      "Batch 222 Loss: 0.4502\n",
      "Batch 444 Loss: 0.7003\n",
      "Batch 666 Loss: 0.5283\n",
      "Batch 888 Loss: 0.5405\n",
      "\n",
      "EPOCH 85 LOSS: 0.6428\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0467e-02.\n",
      "\n",
      "\u001b[1mEpoch 86\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6076\n",
      "Batch 222 Loss: 0.6070\n",
      "Batch 444 Loss: 0.7379\n",
      "Batch 666 Loss: 0.6125\n",
      "Batch 888 Loss: 0.7053\n",
      "\n",
      "EPOCH 86 LOSS: 0.6429\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 87\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5515\n",
      "Batch 222 Loss: 0.6589\n",
      "Batch 444 Loss: 0.5104\n",
      "Batch 666 Loss: 0.7440\n",
      "Batch 888 Loss: 0.4712\n",
      "\n",
      "EPOCH 87 LOSS: 0.6428\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 88\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5097\n",
      "Batch 222 Loss: 0.6251\n",
      "Batch 444 Loss: 0.4766\n",
      "Batch 666 Loss: 0.6593\n",
      "Batch 888 Loss: 0.6423\n",
      "\n",
      "EPOCH 88 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    88: reducing learning rate of group 0 to 9.4203e-03.\n",
      "\n",
      "\u001b[1mEpoch 89\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6339\n",
      "Batch 222 Loss: 0.7425\n",
      "Batch 444 Loss: 0.9812\n",
      "Batch 666 Loss: 0.4937\n",
      "Batch 888 Loss: 0.6536\n",
      "\n",
      "EPOCH 89 LOSS: 0.6428\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 90\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5075\n",
      "Batch 222 Loss: 0.5065\n",
      "Batch 444 Loss: 0.6221\n",
      "Batch 666 Loss: 0.6640\n",
      "Batch 888 Loss: 0.6406\n",
      "\n",
      "EPOCH 90 LOSS: 0.6428\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 91\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5462\n",
      "Batch 222 Loss: 0.9473\n",
      "Batch 444 Loss: 0.4995\n",
      "Batch 666 Loss: 0.7695\n",
      "Batch 888 Loss: 0.5812\n",
      "\n",
      "EPOCH 91 LOSS: 0.6428\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    91: reducing learning rate of group 0 to 8.4782e-03.\n",
      "\n",
      "\u001b[1mEpoch 92\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6729\n",
      "Batch 222 Loss: 0.5668\n",
      "Batch 444 Loss: 0.5452\n",
      "Batch 666 Loss: 0.4891\n",
      "Batch 888 Loss: 0.4803\n",
      "\n",
      "EPOCH 92 LOSS: 0.6428\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 93\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6728\n",
      "Batch 222 Loss: 0.4879\n",
      "Batch 444 Loss: 0.4867\n",
      "Batch 666 Loss: 0.5307\n",
      "Batch 888 Loss: 0.6983\n",
      "\n",
      "EPOCH 93 LOSS: 0.6428\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 94\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5239\n",
      "Batch 222 Loss: 0.5218\n",
      "Batch 444 Loss: 0.5260\n",
      "Batch 666 Loss: 0.6197\n",
      "Batch 888 Loss: 1.3713\n",
      "\n",
      "EPOCH 94 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    94: reducing learning rate of group 0 to 7.6304e-03.\n",
      "\n",
      "\u001b[1mEpoch 95\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6227\n",
      "Batch 222 Loss: 0.6593\n",
      "Batch 444 Loss: 0.6331\n",
      "Batch 666 Loss: 0.4888\n",
      "Batch 888 Loss: 0.6362\n",
      "\n",
      "EPOCH 95 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 96\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8073\n",
      "Batch 222 Loss: 0.5471\n",
      "Batch 444 Loss: 0.9132\n",
      "Batch 666 Loss: 0.5884\n",
      "Batch 888 Loss: 1.6526\n",
      "\n",
      "EPOCH 96 LOSS: 0.6428\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 97\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5299\n",
      "Batch 222 Loss: 0.5587\n",
      "Batch 444 Loss: 0.4587\n",
      "Batch 666 Loss: 0.5512\n",
      "Batch 888 Loss: 0.5069\n",
      "\n",
      "EPOCH 97 LOSS: 0.6428\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    97: reducing learning rate of group 0 to 6.8674e-03.\n",
      "\n",
      "\u001b[1mEpoch 98\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.9401\n",
      "Batch 222 Loss: 0.4668\n",
      "Batch 444 Loss: 0.4450\n",
      "Batch 666 Loss: 0.5544\n",
      "Batch 888 Loss: 0.5387\n",
      "\n",
      "EPOCH 98 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 99\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7282\n",
      "Batch 222 Loss: 0.6910\n",
      "Batch 444 Loss: 0.7034\n",
      "Batch 666 Loss: 0.5347\n",
      "Batch 888 Loss: 0.4535\n",
      "\n",
      "EPOCH 99 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 100\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.1022\n",
      "Batch 222 Loss: 0.6557\n",
      "Batch 444 Loss: 0.6947\n",
      "Batch 666 Loss: 0.5545\n",
      "Batch 888 Loss: 0.7853\n",
      "\n",
      "EPOCH 100 LOSS: 0.6428\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   100: reducing learning rate of group 0 to 6.1806e-03.\n",
      "\n",
      "\u001b[1mEpoch 101\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.1615\n",
      "Batch 222 Loss: 0.4898\n",
      "Batch 444 Loss: 0.5063\n",
      "Batch 666 Loss: 0.7096\n",
      "Batch 888 Loss: 1.0060\n",
      "\n",
      "EPOCH 101 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 102\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5159\n",
      "Batch 222 Loss: 0.7189\n",
      "Batch 444 Loss: 0.4771\n",
      "Batch 666 Loss: 0.6383\n",
      "Batch 888 Loss: 0.4095\n",
      "\n",
      "EPOCH 102 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 103\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7105\n",
      "Batch 222 Loss: 0.7639\n",
      "Batch 444 Loss: 0.6116\n",
      "Batch 666 Loss: 0.6676\n",
      "Batch 888 Loss: 0.5395\n",
      "\n",
      "EPOCH 103 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   103: reducing learning rate of group 0 to 5.5626e-03.\n",
      "\n",
      "\u001b[1mEpoch 104\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6382\n",
      "Batch 222 Loss: 0.5574\n",
      "Batch 444 Loss: 0.6850\n",
      "Batch 666 Loss: 0.5780\n",
      "Batch 888 Loss: 0.5854\n",
      "\n",
      "EPOCH 104 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 105\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7211\n",
      "Batch 222 Loss: 0.5301\n",
      "Batch 444 Loss: 0.5982\n",
      "Batch 666 Loss: 0.5945\n",
      "Batch 888 Loss: 0.4763\n",
      "\n",
      "EPOCH 105 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 106\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.1929\n",
      "Batch 222 Loss: 0.6036\n",
      "Batch 444 Loss: 0.4864\n",
      "Batch 666 Loss: 1.0750\n",
      "Batch 888 Loss: 0.5339\n",
      "\n",
      "EPOCH 106 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   106: reducing learning rate of group 0 to 5.0063e-03.\n",
      "\n",
      "\u001b[1mEpoch 107\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5107\n",
      "Batch 222 Loss: 0.6150\n",
      "Batch 444 Loss: 0.9068\n",
      "Batch 666 Loss: 0.5377\n",
      "Batch 888 Loss: 1.3366\n",
      "\n",
      "EPOCH 107 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 108\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5556\n",
      "Batch 222 Loss: 0.5353\n",
      "Batch 444 Loss: 0.5160\n",
      "Batch 666 Loss: 0.6360\n",
      "Batch 888 Loss: 0.4882\n",
      "\n",
      "EPOCH 108 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 109\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4469\n",
      "Batch 222 Loss: 0.5280\n",
      "Batch 444 Loss: 0.7778\n",
      "Batch 666 Loss: 1.8594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 888 Loss: 0.7435\n",
      "\n",
      "EPOCH 109 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   109: reducing learning rate of group 0 to 4.5057e-03.\n",
      "\n",
      "\u001b[1mEpoch 110\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.9641\n",
      "Batch 222 Loss: 0.7151\n",
      "Batch 444 Loss: 0.5050\n",
      "Batch 666 Loss: 0.7241\n",
      "Batch 888 Loss: 0.4268\n",
      "\n",
      "EPOCH 110 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 111\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7105\n",
      "Batch 222 Loss: 0.5884\n",
      "Batch 444 Loss: 0.4775\n",
      "Batch 666 Loss: 0.7176\n",
      "Batch 888 Loss: 0.5570\n",
      "\n",
      "EPOCH 111 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 112\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6266\n",
      "Batch 222 Loss: 0.6988\n",
      "Batch 444 Loss: 0.6759\n",
      "Batch 666 Loss: 0.5051\n",
      "Batch 888 Loss: 0.4682\n",
      "\n",
      "EPOCH 112 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   112: reducing learning rate of group 0 to 4.0551e-03.\n",
      "\n",
      "\u001b[1mEpoch 113\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5975\n",
      "Batch 222 Loss: 0.4967\n",
      "Batch 444 Loss: 0.5474\n",
      "Batch 666 Loss: 0.5409\n",
      "Batch 888 Loss: 0.4442\n",
      "\n",
      "EPOCH 113 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 114\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4816\n",
      "Batch 222 Loss: 0.6529\n",
      "Batch 444 Loss: 0.4649\n",
      "Batch 666 Loss: 0.4975\n",
      "Batch 888 Loss: 0.6278\n",
      "\n",
      "EPOCH 114 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 115\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4872\n",
      "Batch 222 Loss: 0.5724\n",
      "Batch 444 Loss: 0.5136\n",
      "Batch 666 Loss: 0.9783\n",
      "Batch 888 Loss: 0.8697\n",
      "\n",
      "EPOCH 115 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   115: reducing learning rate of group 0 to 3.6496e-03.\n",
      "\n",
      "\u001b[1mEpoch 116\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6648\n",
      "Batch 222 Loss: 0.5616\n",
      "Batch 444 Loss: 0.7047\n",
      "Batch 666 Loss: 1.0021\n",
      "Batch 888 Loss: 0.4686\n",
      "\n",
      "EPOCH 116 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 117\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5295\n",
      "Batch 222 Loss: 0.6644\n",
      "Batch 444 Loss: 0.8348\n",
      "Batch 666 Loss: 0.5127\n",
      "Batch 888 Loss: 0.8392\n",
      "\n",
      "EPOCH 117 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 118\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5092\n",
      "Batch 222 Loss: 0.6499\n",
      "Batch 444 Loss: 0.5316\n",
      "Batch 666 Loss: 0.5464\n",
      "Batch 888 Loss: 0.4297\n",
      "\n",
      "EPOCH 118 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   118: reducing learning rate of group 0 to 3.2846e-03.\n",
      "\n",
      "\u001b[1mEpoch 119\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5417\n",
      "Batch 222 Loss: 0.5702\n",
      "Batch 444 Loss: 0.6754\n",
      "Batch 666 Loss: 0.6807\n",
      "Batch 888 Loss: 0.5090\n",
      "\n",
      "EPOCH 119 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 120\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5942\n",
      "Batch 222 Loss: 0.7533\n",
      "Batch 444 Loss: 0.6227\n",
      "Batch 666 Loss: 0.5677\n",
      "Batch 888 Loss: 0.6708\n",
      "\n",
      "EPOCH 120 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 121\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.9397\n",
      "Batch 222 Loss: 0.4896\n",
      "Batch 444 Loss: 0.4812\n",
      "Batch 666 Loss: 0.9494\n",
      "Batch 888 Loss: 0.5826\n",
      "\n",
      "EPOCH 121 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   121: reducing learning rate of group 0 to 2.9562e-03.\n",
      "\n",
      "\u001b[1mEpoch 122\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5280\n",
      "Batch 222 Loss: 0.6856\n",
      "Batch 444 Loss: 0.9258\n",
      "Batch 666 Loss: 0.7104\n",
      "Batch 888 Loss: 0.6148\n",
      "\n",
      "EPOCH 122 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 123\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6498\n",
      "Batch 222 Loss: 0.6443\n",
      "Batch 444 Loss: 0.6184\n",
      "Batch 666 Loss: 0.5666\n",
      "Batch 888 Loss: 0.6143\n",
      "\n",
      "EPOCH 123 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 124\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4972\n",
      "Batch 222 Loss: 1.8148\n",
      "Batch 444 Loss: 0.5513\n",
      "Batch 666 Loss: 0.5132\n",
      "Batch 888 Loss: 0.8756\n",
      "\n",
      "EPOCH 124 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   124: reducing learning rate of group 0 to 2.6606e-03.\n",
      "\n",
      "\u001b[1mEpoch 125\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7759\n",
      "Batch 222 Loss: 0.5839\n",
      "Batch 444 Loss: 0.5465\n",
      "Batch 666 Loss: 0.8111\n",
      "Batch 888 Loss: 0.5290\n",
      "\n",
      "EPOCH 125 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 126\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5081\n",
      "Batch 222 Loss: 0.5697\n",
      "Batch 444 Loss: 0.5950\n",
      "Batch 666 Loss: 0.6086\n",
      "Batch 888 Loss: 0.5601\n",
      "\n",
      "EPOCH 126 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 127\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7001\n",
      "Batch 222 Loss: 0.5450\n",
      "Batch 444 Loss: 0.5366\n",
      "Batch 666 Loss: 0.9897\n",
      "Batch 888 Loss: 0.4967\n",
      "\n",
      "EPOCH 127 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   127: reducing learning rate of group 0 to 2.3945e-03.\n",
      "\n",
      "\u001b[1mEpoch 128\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6323\n",
      "Batch 222 Loss: 0.7730\n",
      "Batch 444 Loss: 0.6077\n",
      "Batch 666 Loss: 0.5296\n",
      "Batch 888 Loss: 0.9655\n",
      "\n",
      "EPOCH 128 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 129\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5624\n",
      "Batch 222 Loss: 0.5328\n",
      "Batch 444 Loss: 0.6366\n",
      "Batch 666 Loss: 0.5792\n",
      "Batch 888 Loss: 0.5066\n",
      "\n",
      "EPOCH 129 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 130\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5195\n",
      "Batch 222 Loss: 0.6617\n",
      "Batch 444 Loss: 0.6534\n",
      "Batch 666 Loss: 0.4649\n",
      "Batch 888 Loss: 0.5151\n",
      "\n",
      "EPOCH 130 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   130: reducing learning rate of group 0 to 2.1551e-03.\n",
      "\n",
      "\u001b[1mEpoch 131\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5631\n",
      "Batch 222 Loss: 1.2999\n",
      "Batch 444 Loss: 0.5409\n",
      "Batch 666 Loss: 0.5910\n",
      "Batch 888 Loss: 0.9694\n",
      "\n",
      "EPOCH 131 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 132\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.2553\n",
      "Batch 222 Loss: 1.2472\n",
      "Batch 444 Loss: 0.5073\n",
      "Batch 666 Loss: 0.6302\n",
      "Batch 888 Loss: 0.6559\n",
      "\n",
      "EPOCH 132 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 133\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5331\n",
      "Batch 222 Loss: 0.8965\n",
      "Batch 444 Loss: 0.5422\n",
      "Batch 666 Loss: 0.5642\n",
      "Batch 888 Loss: 0.4698\n",
      "\n",
      "EPOCH 133 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   133: reducing learning rate of group 0 to 1.9395e-03.\n",
      "\n",
      "\u001b[1mEpoch 134\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7059\n",
      "Batch 222 Loss: 0.5107\n",
      "Batch 444 Loss: 0.5971\n",
      "Batch 666 Loss: 0.4516\n",
      "Batch 888 Loss: 0.4718\n",
      "\n",
      "EPOCH 134 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 135\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6186\n",
      "Batch 222 Loss: 0.5412\n",
      "Batch 444 Loss: 0.4984\n",
      "Batch 666 Loss: 0.5028\n",
      "Batch 888 Loss: 0.4687\n",
      "\n",
      "EPOCH 135 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 136\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8202\n",
      "Batch 222 Loss: 0.6078\n",
      "Batch 444 Loss: 0.8897\n",
      "Batch 666 Loss: 0.6387\n",
      "Batch 888 Loss: 0.5673\n",
      "\n",
      "EPOCH 136 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   136: reducing learning rate of group 0 to 1.7456e-03.\n",
      "\n",
      "\u001b[1mEpoch 137\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5101\n",
      "Batch 222 Loss: 0.7217\n",
      "Batch 444 Loss: 0.4438\n",
      "Batch 666 Loss: 0.6488\n",
      "Batch 888 Loss: 0.5157\n",
      "\n",
      "EPOCH 137 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 138\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5948\n",
      "Batch 222 Loss: 0.5591\n",
      "Batch 444 Loss: 0.4596\n",
      "Batch 666 Loss: 0.5330\n",
      "Batch 888 Loss: 0.4970\n",
      "\n",
      "EPOCH 138 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 139\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8358\n",
      "Batch 222 Loss: 0.5147\n",
      "Batch 444 Loss: 0.5169\n",
      "Batch 666 Loss: 0.6515\n",
      "Batch 888 Loss: 0.6242\n",
      "\n",
      "EPOCH 139 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   139: reducing learning rate of group 0 to 1.5710e-03.\n",
      "\n",
      "\u001b[1mEpoch 140\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6974\n",
      "Batch 222 Loss: 0.5762\n",
      "Batch 444 Loss: 0.5891\n",
      "Batch 666 Loss: 0.8040\n",
      "Batch 888 Loss: 0.3952\n",
      "\n",
      "EPOCH 140 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 141\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5601\n",
      "Batch 222 Loss: 0.5484\n",
      "Batch 444 Loss: 0.7250\n",
      "Batch 666 Loss: 0.4440\n",
      "Batch 888 Loss: 0.7188\n",
      "\n",
      "EPOCH 141 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 142\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.9796\n",
      "Batch 222 Loss: 0.6909\n",
      "Batch 444 Loss: 0.5709\n",
      "Batch 666 Loss: 0.5604\n",
      "Batch 888 Loss: 0.9404\n",
      "\n",
      "EPOCH 142 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   142: reducing learning rate of group 0 to 1.4139e-03.\n",
      "\n",
      "\u001b[1mEpoch 143\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5326\n",
      "Batch 222 Loss: 0.8015\n",
      "Batch 444 Loss: 0.5679\n",
      "Batch 666 Loss: 0.5246\n",
      "Batch 888 Loss: 0.5537\n",
      "\n",
      "EPOCH 143 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 144\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6528\n",
      "Batch 222 Loss: 0.9043\n",
      "Batch 444 Loss: 1.2756\n",
      "Batch 666 Loss: 0.8875\n",
      "Batch 888 Loss: 0.4331\n",
      "\n",
      "EPOCH 144 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 145\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 222 Loss: 0.5621\n",
      "Batch 444 Loss: 0.5781\n",
      "Batch 666 Loss: 0.4696\n",
      "Batch 888 Loss: 0.5828\n",
      "\n",
      "EPOCH 145 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   145: reducing learning rate of group 0 to 1.2725e-03.\n",
      "\n",
      "\u001b[1mEpoch 146\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5743\n",
      "Batch 222 Loss: 1.1410\n",
      "Batch 444 Loss: 0.5185\n",
      "Batch 666 Loss: 0.5530\n",
      "Batch 888 Loss: 0.5931\n",
      "\n",
      "EPOCH 146 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 147\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6542\n",
      "Batch 222 Loss: 0.4474\n",
      "Batch 444 Loss: 0.5660\n",
      "Batch 666 Loss: 0.5288\n",
      "Batch 888 Loss: 1.0083\n",
      "\n",
      "EPOCH 147 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 148\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6147\n",
      "Batch 222 Loss: 0.5847\n",
      "Batch 444 Loss: 0.7350\n",
      "Batch 666 Loss: 0.7062\n",
      "Batch 888 Loss: 0.5060\n",
      "\n",
      "EPOCH 148 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   148: reducing learning rate of group 0 to 1.1453e-03.\n",
      "\n",
      "\u001b[1mEpoch 149\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6205\n",
      "Batch 222 Loss: 0.6583\n",
      "Batch 444 Loss: 0.5220\n",
      "Batch 666 Loss: 0.8312\n",
      "Batch 888 Loss: 0.7415\n",
      "\n",
      "EPOCH 149 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 150\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5921\n",
      "Batch 222 Loss: 0.5766\n",
      "Batch 444 Loss: 0.5367\n",
      "Batch 666 Loss: 0.5082\n",
      "Batch 888 Loss: 0.5562\n",
      "\n",
      "EPOCH 150 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 151\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6456\n",
      "Batch 222 Loss: 0.4591\n",
      "Batch 444 Loss: 0.5610\n",
      "Batch 666 Loss: 0.7011\n",
      "Batch 888 Loss: 0.5746\n",
      "\n",
      "EPOCH 151 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0308e-03.\n",
      "\n",
      "\u001b[1mEpoch 152\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4778\n",
      "Batch 222 Loss: 0.5663\n",
      "Batch 444 Loss: 0.5427\n",
      "Batch 666 Loss: 0.5702\n",
      "Batch 888 Loss: 0.5185\n",
      "\n",
      "EPOCH 152 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 153\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5262\n",
      "Batch 222 Loss: 0.6930\n",
      "Batch 444 Loss: 0.7726\n",
      "Batch 666 Loss: 0.7931\n",
      "Batch 888 Loss: 0.6096\n",
      "\n",
      "EPOCH 153 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 154\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6195\n",
      "Batch 222 Loss: 0.5798\n",
      "Batch 444 Loss: 0.5938\n",
      "Batch 666 Loss: 1.5486\n",
      "Batch 888 Loss: 0.5317\n",
      "\n",
      "EPOCH 154 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   154: reducing learning rate of group 0 to 9.2768e-04.\n",
      "\n",
      "\u001b[1mEpoch 155\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5571\n",
      "Batch 222 Loss: 1.1168\n",
      "Batch 444 Loss: 0.5956\n",
      "Batch 666 Loss: 0.5989\n",
      "Batch 888 Loss: 1.0699\n",
      "\n",
      "EPOCH 155 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 156\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7270\n",
      "Batch 222 Loss: 0.6332\n",
      "Batch 444 Loss: 0.4763\n",
      "Batch 666 Loss: 0.5132\n",
      "Batch 888 Loss: 0.5049\n",
      "\n",
      "EPOCH 156 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 157\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6553\n",
      "Batch 222 Loss: 0.6179\n",
      "Batch 444 Loss: 0.5607\n",
      "Batch 666 Loss: 0.5075\n",
      "Batch 888 Loss: 0.6619\n",
      "\n",
      "EPOCH 157 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   157: reducing learning rate of group 0 to 8.3491e-04.\n",
      "\n",
      "\u001b[1mEpoch 158\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6024\n",
      "Batch 222 Loss: 0.4963\n",
      "Batch 444 Loss: 0.5517\n",
      "Batch 666 Loss: 0.5698\n",
      "Batch 888 Loss: 1.0115\n",
      "\n",
      "EPOCH 158 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 159\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5885\n",
      "Batch 222 Loss: 0.5661\n",
      "Batch 444 Loss: 0.5495\n",
      "Batch 666 Loss: 0.6275\n",
      "Batch 888 Loss: 0.5429\n",
      "\n",
      "EPOCH 159 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 160\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6046\n",
      "Batch 222 Loss: 0.5064\n",
      "Batch 444 Loss: 0.6841\n",
      "Batch 666 Loss: 0.4652\n",
      "Batch 888 Loss: 0.6277\n",
      "\n",
      "EPOCH 160 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   160: reducing learning rate of group 0 to 7.5142e-04.\n",
      "\n",
      "\u001b[1mEpoch 161\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.2528\n",
      "Batch 222 Loss: 0.5910\n",
      "Batch 444 Loss: 0.6793\n",
      "Batch 666 Loss: 0.4958\n",
      "Batch 888 Loss: 1.5350\n",
      "\n",
      "EPOCH 161 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 162\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7050\n",
      "Batch 222 Loss: 0.6793\n",
      "Batch 444 Loss: 0.5801\n",
      "Batch 666 Loss: 0.4955\n",
      "Batch 888 Loss: 0.5975\n",
      "\n",
      "EPOCH 162 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 163\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5474\n",
      "Batch 222 Loss: 0.5566\n",
      "Batch 444 Loss: 0.5395\n",
      "Batch 666 Loss: 0.6093\n",
      "Batch 888 Loss: 0.9591\n",
      "\n",
      "EPOCH 163 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   163: reducing learning rate of group 0 to 6.7628e-04.\n",
      "\n",
      "\u001b[1mEpoch 164\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5601\n",
      "Batch 222 Loss: 0.5301\n",
      "Batch 444 Loss: 0.5049\n",
      "Batch 666 Loss: 0.7930\n",
      "Batch 888 Loss: 0.5434\n",
      "\n",
      "EPOCH 164 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 165\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8166\n",
      "Batch 222 Loss: 0.9300\n",
      "Batch 444 Loss: 1.5729\n",
      "Batch 666 Loss: 0.5428\n",
      "Batch 888 Loss: 0.6068\n",
      "\n",
      "EPOCH 165 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 166\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5830\n",
      "Batch 222 Loss: 0.6785\n",
      "Batch 444 Loss: 0.4780\n",
      "Batch 666 Loss: 0.7127\n",
      "Batch 888 Loss: 0.6470\n",
      "\n",
      "EPOCH 166 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   166: reducing learning rate of group 0 to 6.0865e-04.\n",
      "\n",
      "\u001b[1mEpoch 167\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5103\n",
      "Batch 222 Loss: 0.5718\n",
      "Batch 444 Loss: 0.5328\n",
      "Batch 666 Loss: 0.5818\n",
      "Batch 888 Loss: 0.4928\n",
      "\n",
      "EPOCH 167 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 168\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7651\n",
      "Batch 222 Loss: 0.5527\n",
      "Batch 444 Loss: 0.5823\n",
      "Batch 666 Loss: 0.5031\n",
      "Batch 888 Loss: 0.5428\n",
      "\n",
      "EPOCH 168 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 169\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5885\n",
      "Batch 222 Loss: 0.8665\n",
      "Batch 444 Loss: 0.5905\n",
      "Batch 666 Loss: 0.6071\n",
      "Batch 888 Loss: 1.5174\n",
      "\n",
      "EPOCH 169 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   169: reducing learning rate of group 0 to 5.4779e-04.\n",
      "\n",
      "\u001b[1mEpoch 170\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5184\n",
      "Batch 222 Loss: 0.5394\n",
      "Batch 444 Loss: 0.6295\n",
      "Batch 666 Loss: 0.5723\n",
      "Batch 888 Loss: 0.8623\n",
      "\n",
      "EPOCH 170 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 171\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5896\n",
      "Batch 222 Loss: 0.5897\n",
      "Batch 444 Loss: 0.6156\n",
      "Batch 666 Loss: 0.6132\n",
      "Batch 888 Loss: 0.4954\n",
      "\n",
      "EPOCH 171 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 172\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6247\n",
      "Batch 222 Loss: 0.5349\n",
      "Batch 444 Loss: 0.5589\n",
      "Batch 666 Loss: 0.5168\n",
      "Batch 888 Loss: 0.7014\n",
      "\n",
      "EPOCH 172 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   172: reducing learning rate of group 0 to 4.9301e-04.\n",
      "\n",
      "\u001b[1mEpoch 173\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4576\n",
      "Batch 222 Loss: 1.2020\n",
      "Batch 444 Loss: 0.6201\n",
      "Batch 666 Loss: 0.5855\n",
      "Batch 888 Loss: 0.4518\n",
      "\n",
      "EPOCH 173 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 174\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6272\n",
      "Batch 222 Loss: 0.4878\n",
      "Batch 444 Loss: 0.6713\n",
      "Batch 666 Loss: 0.5249\n",
      "Batch 888 Loss: 0.6104\n",
      "\n",
      "EPOCH 174 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 175\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4876\n",
      "Batch 222 Loss: 0.5431\n",
      "Batch 444 Loss: 0.5754\n",
      "Batch 666 Loss: 0.9005\n",
      "Batch 888 Loss: 0.4878\n",
      "\n",
      "EPOCH 175 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   175: reducing learning rate of group 0 to 4.4371e-04.\n",
      "\n",
      "\u001b[1mEpoch 176\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5679\n",
      "Batch 222 Loss: 0.4887\n",
      "Batch 444 Loss: 0.7904\n",
      "Batch 666 Loss: 0.6507\n",
      "Batch 888 Loss: 0.5352\n",
      "\n",
      "EPOCH 176 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 177\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7426\n",
      "Batch 222 Loss: 0.7450\n",
      "Batch 444 Loss: 0.6384\n",
      "Batch 666 Loss: 0.6299\n",
      "Batch 888 Loss: 0.5633\n",
      "\n",
      "EPOCH 177 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 178\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5330\n",
      "Batch 222 Loss: 0.5773\n",
      "Batch 444 Loss: 0.6561\n",
      "Batch 666 Loss: 1.2800\n",
      "Batch 888 Loss: 0.7643\n",
      "\n",
      "EPOCH 178 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   178: reducing learning rate of group 0 to 3.9934e-04.\n",
      "\n",
      "\u001b[1mEpoch 179\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5511\n",
      "Batch 222 Loss: 0.7377\n",
      "Batch 444 Loss: 0.5067\n",
      "Batch 666 Loss: 0.5187\n",
      "Batch 888 Loss: 0.4688\n",
      "\n",
      "EPOCH 179 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 180\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4953\n",
      "Batch 222 Loss: 0.9082\n",
      "Batch 444 Loss: 0.4607\n",
      "Batch 666 Loss: 0.5056\n",
      "Batch 888 Loss: 0.5644\n",
      "\n",
      "EPOCH 180 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 181\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 222 Loss: 0.6731\n",
      "Batch 444 Loss: 0.6053\n",
      "Batch 666 Loss: 0.5548\n",
      "Batch 888 Loss: 0.4276\n",
      "\n",
      "EPOCH 181 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   181: reducing learning rate of group 0 to 3.5940e-04.\n",
      "\n",
      "\u001b[1mEpoch 182\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5821\n",
      "Batch 222 Loss: 0.6065\n",
      "Batch 444 Loss: 1.4900\n",
      "Batch 666 Loss: 0.5691\n",
      "Batch 888 Loss: 0.9073\n",
      "\n",
      "EPOCH 182 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 183\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6144\n",
      "Batch 222 Loss: 0.5540\n",
      "Batch 444 Loss: 0.6311\n",
      "Batch 666 Loss: 0.5759\n",
      "Batch 888 Loss: 0.6574\n",
      "\n",
      "EPOCH 183 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 184\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.9939\n",
      "Batch 222 Loss: 0.5264\n",
      "Batch 444 Loss: 0.6228\n",
      "Batch 666 Loss: 0.7631\n",
      "Batch 888 Loss: 0.4634\n",
      "\n",
      "EPOCH 184 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   184: reducing learning rate of group 0 to 3.2346e-04.\n",
      "\n",
      "\u001b[1mEpoch 185\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6686\n",
      "Batch 222 Loss: 0.5573\n",
      "Batch 444 Loss: 0.5228\n",
      "Batch 666 Loss: 0.5562\n",
      "Batch 888 Loss: 0.4953\n",
      "\n",
      "EPOCH 185 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 186\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5514\n",
      "Batch 222 Loss: 0.6777\n",
      "Batch 444 Loss: 0.7996\n",
      "Batch 666 Loss: 0.5153\n",
      "Batch 888 Loss: 0.5547\n",
      "\n",
      "EPOCH 186 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 187\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8889\n",
      "Batch 222 Loss: 0.5287\n",
      "Batch 444 Loss: 0.4696\n",
      "Batch 666 Loss: 0.5148\n",
      "Batch 888 Loss: 0.5249\n",
      "\n",
      "EPOCH 187 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   187: reducing learning rate of group 0 to 2.9112e-04.\n",
      "\n",
      "\u001b[1mEpoch 188\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5161\n",
      "Batch 222 Loss: 0.5346\n",
      "Batch 444 Loss: 0.4920\n",
      "Batch 666 Loss: 0.6429\n",
      "Batch 888 Loss: 0.4672\n",
      "\n",
      "EPOCH 188 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 189\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6205\n",
      "Batch 222 Loss: 0.6765\n",
      "Batch 444 Loss: 0.4766\n",
      "Batch 666 Loss: 0.6064\n",
      "Batch 888 Loss: 0.6317\n",
      "\n",
      "EPOCH 189 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 190\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5911\n",
      "Batch 222 Loss: 0.8218\n",
      "Batch 444 Loss: 0.5216\n",
      "Batch 666 Loss: 0.4995\n",
      "Batch 888 Loss: 0.7189\n",
      "\n",
      "EPOCH 190 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   190: reducing learning rate of group 0 to 2.6200e-04.\n",
      "\n",
      "\u001b[1mEpoch 191\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7491\n",
      "Batch 222 Loss: 0.5277\n",
      "Batch 444 Loss: 0.6201\n",
      "Batch 666 Loss: 0.5128\n",
      "Batch 888 Loss: 0.5317\n",
      "\n",
      "EPOCH 191 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 192\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5930\n",
      "Batch 222 Loss: 0.5502\n",
      "Batch 444 Loss: 0.8811\n",
      "Batch 666 Loss: 0.6809\n",
      "Batch 888 Loss: 0.5101\n",
      "\n",
      "EPOCH 192 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 193\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4908\n",
      "Batch 222 Loss: 0.6229\n",
      "Batch 444 Loss: 0.6808\n",
      "Batch 666 Loss: 0.5443\n",
      "Batch 888 Loss: 0.7813\n",
      "\n",
      "EPOCH 193 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   193: reducing learning rate of group 0 to 2.3580e-04.\n",
      "\n",
      "\u001b[1mEpoch 194\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5246\n",
      "Batch 222 Loss: 0.6924\n",
      "Batch 444 Loss: 0.8456\n",
      "Batch 666 Loss: 0.5781\n",
      "Batch 888 Loss: 0.5867\n",
      "\n",
      "EPOCH 194 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 195\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6712\n",
      "Batch 222 Loss: 0.8615\n",
      "Batch 444 Loss: 0.4401\n",
      "Batch 666 Loss: 0.4769\n",
      "Batch 888 Loss: 0.4607\n",
      "\n",
      "EPOCH 195 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 196\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5506\n",
      "Batch 222 Loss: 0.6524\n",
      "Batch 444 Loss: 0.8334\n",
      "Batch 666 Loss: 0.6529\n",
      "Batch 888 Loss: 0.4951\n",
      "\n",
      "EPOCH 196 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   196: reducing learning rate of group 0 to 2.1222e-04.\n",
      "\n",
      "\u001b[1mEpoch 197\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6892\n",
      "Batch 222 Loss: 0.5759\n",
      "Batch 444 Loss: 0.9991\n",
      "Batch 666 Loss: 0.5195\n",
      "Batch 888 Loss: 0.5019\n",
      "\n",
      "EPOCH 197 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 198\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5658\n",
      "Batch 222 Loss: 0.5084\n",
      "Batch 444 Loss: 0.4789\n",
      "Batch 666 Loss: 0.5075\n",
      "Batch 888 Loss: 0.5755\n",
      "\n",
      "EPOCH 198 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 199\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6281\n",
      "Batch 222 Loss: 0.7745\n",
      "Batch 444 Loss: 0.6013\n",
      "Batch 666 Loss: 0.9385\n",
      "Batch 888 Loss: 0.5955\n",
      "\n",
      "EPOCH 199 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   199: reducing learning rate of group 0 to 1.9100e-04.\n",
      "\n",
      "\u001b[1mEpoch 200\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5151\n",
      "Batch 222 Loss: 0.5608\n",
      "Batch 444 Loss: 0.4833\n",
      "Batch 666 Loss: 0.4964\n",
      "Batch 888 Loss: 0.7850\n",
      "\n",
      "EPOCH 200 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 201\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5696\n",
      "Batch 222 Loss: 0.6085\n",
      "Batch 444 Loss: 0.7304\n",
      "Batch 666 Loss: 0.7721\n",
      "Batch 888 Loss: 0.5272\n",
      "\n",
      "EPOCH 201 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 202\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6929\n",
      "Batch 222 Loss: 0.5811\n",
      "Batch 444 Loss: 1.0067\n",
      "Batch 666 Loss: 0.5157\n",
      "Batch 888 Loss: 1.0003\n",
      "\n",
      "EPOCH 202 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   202: reducing learning rate of group 0 to 1.7190e-04.\n",
      "\n",
      "\u001b[1mEpoch 203\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7184\n",
      "Batch 222 Loss: 0.7353\n",
      "Batch 444 Loss: 0.6313\n",
      "Batch 666 Loss: 0.4686\n",
      "Batch 888 Loss: 0.4970\n",
      "\n",
      "EPOCH 203 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 204\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7391\n",
      "Batch 222 Loss: 0.9443\n",
      "Batch 444 Loss: 0.6296\n",
      "Batch 666 Loss: 0.6817\n",
      "Batch 888 Loss: 0.5590\n",
      "\n",
      "EPOCH 204 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 205\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8798\n",
      "Batch 222 Loss: 0.6391\n",
      "Batch 444 Loss: 0.7029\n",
      "Batch 666 Loss: 0.5539\n",
      "Batch 888 Loss: 0.4569\n",
      "\n",
      "EPOCH 205 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   205: reducing learning rate of group 0 to 1.5471e-04.\n",
      "\n",
      "\u001b[1mEpoch 206\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6197\n",
      "Batch 222 Loss: 0.4713\n",
      "Batch 444 Loss: 0.5172\n",
      "Batch 666 Loss: 0.6167\n",
      "Batch 888 Loss: 1.6494\n",
      "\n",
      "EPOCH 206 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 207\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6713\n",
      "Batch 222 Loss: 0.5107\n",
      "Batch 444 Loss: 0.5318\n",
      "Batch 666 Loss: 0.5407\n",
      "Batch 888 Loss: 0.6131\n",
      "\n",
      "EPOCH 207 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 208\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5581\n",
      "Batch 222 Loss: 0.5035\n",
      "Batch 444 Loss: 0.8883\n",
      "Batch 666 Loss: 0.5710\n",
      "Batch 888 Loss: 0.5016\n",
      "\n",
      "EPOCH 208 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   208: reducing learning rate of group 0 to 1.3924e-04.\n",
      "\n",
      "\u001b[1mEpoch 209\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4612\n",
      "Batch 222 Loss: 0.5892\n",
      "Batch 444 Loss: 0.6982\n",
      "Batch 666 Loss: 0.6566\n",
      "Batch 888 Loss: 0.5555\n",
      "\n",
      "EPOCH 209 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 210\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6670\n",
      "Batch 222 Loss: 0.9672\n",
      "Batch 444 Loss: 0.6470\n",
      "Batch 666 Loss: 0.5308\n",
      "Batch 888 Loss: 0.8095\n",
      "\n",
      "EPOCH 210 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 211\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7464\n",
      "Batch 222 Loss: 0.4643\n",
      "Batch 444 Loss: 0.9120\n",
      "Batch 666 Loss: 0.8223\n",
      "Batch 888 Loss: 0.5806\n",
      "\n",
      "EPOCH 211 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   211: reducing learning rate of group 0 to 1.2532e-04.\n",
      "\n",
      "\u001b[1mEpoch 212\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5316\n",
      "Batch 222 Loss: 0.6097\n",
      "Batch 444 Loss: 0.6091\n",
      "Batch 666 Loss: 0.5440\n",
      "Batch 888 Loss: 0.5431\n",
      "\n",
      "EPOCH 212 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 213\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6212\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-5555341c64eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                    \u001b[0mvalidation_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_torch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                    \u001b[0mlr_rate_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                    y_val=y_val)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-b131393f30ae>\u001b[0m in \u001b[0;36mtrain_autoencoder\u001b[0;34m(model, dataset, loss_func, optimizer, epochs, batch_size, validation_tensor, y_val, lr_rate_scheduler, noise_factor, random_seed, MSE_stopping_threshold)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\033[1mEpoch {}\\033[0m\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnoise_factor\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.RMSprop(ae2.parameters(), lr=0.2, weight_decay=0.25)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.9, patience=2, verbose=True)\n",
    "train_autoencoder(model=ae2,\n",
    "                   dataset=output1,\n",
    "                   loss_func=loss_func,\n",
    "                   optimizer=optimizer,\n",
    "                   batch_size=256,\n",
    "                   epochs=500,\n",
    "                   validation_tensor=val_torch,\n",
    "                   lr_rate_scheduler=scheduler,\n",
    "                   y_val=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "output2 = ae2(output1)\n",
    "train_output2 = ae2(train_output1)\n",
    "val_output2 = ae2(val_output1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder III: Denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae3 = AutoEncoder(n_features,n_features)\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mEpoch 1\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8330\n",
      "Batch 111 Loss: 0.2692\n",
      "Batch 222 Loss: 0.1376\n",
      "Batch 333 Loss: 0.1046\n",
      "Batch 444 Loss: 0.0595\n",
      "\n",
      "EPOCH 1 LOSS: 0.0040\n",
      "\n",
      "Reconstruction error recall: 0.0198\n",
      "\n",
      "\u001b[1mEpoch 2\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0651\n",
      "Batch 111 Loss: 0.0738\n",
      "Batch 222 Loss: 0.0679\n",
      "Batch 333 Loss: 0.0576\n",
      "Batch 444 Loss: 0.0553\n",
      "\n",
      "EPOCH 2 LOSS: 0.0004\n",
      "\n",
      "Reconstruction error recall 0.0198\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 3\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0536\n",
      "Batch 111 Loss: 0.0546\n",
      "Batch 222 Loss: 0.0558\n",
      "Batch 333 Loss: 0.2186\n",
      "Batch 444 Loss: 0.0683\n",
      "\n",
      "EPOCH 3 LOSS: 0.0004\n",
      "\n",
      "Reconstruction error recall 0.0198\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 4\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0587\n",
      "Batch 111 Loss: 0.0593\n",
      "Batch 222 Loss: 0.0629\n",
      "Batch 333 Loss: 0.0516\n",
      "Batch 444 Loss: 0.0464\n",
      "\n",
      "EPOCH 4 LOSS: 0.0001\n",
      "\n",
      "Reconstruction error recall 0.0198\n",
      "Change: 0.0000%\n",
      "Epoch     4: reducing learning rate of group 0 to 1.8000e-01.\n",
      "\n",
      "\u001b[1mEpoch 5\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0489\n",
      "Batch 111 Loss: 0.0498\n",
      "Batch 222 Loss: 0.0509\n",
      "Batch 333 Loss: 0.0508\n",
      "Batch 444 Loss: 0.0556\n",
      "\n",
      "EPOCH 5 LOSS: 0.0008\n",
      "\n",
      "Reconstruction error recall 0.0495\n",
      "Change: 1.5000%\n",
      "\n",
      "\u001b[1mEpoch 6\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0534\n",
      "Batch 111 Loss: 0.0471\n",
      "Batch 222 Loss: 0.0534\n",
      "Batch 333 Loss: 0.0505\n",
      "Batch 444 Loss: 0.0476\n",
      "\n",
      "EPOCH 6 LOSS: 0.0003\n",
      "\n",
      "Reconstruction error recall 0.0693\n",
      "Change: 0.4000%\n",
      "\n",
      "\u001b[1mEpoch 7\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0521\n",
      "Batch 111 Loss: 0.0875\n",
      "Batch 222 Loss: 0.0488\n",
      "Batch 333 Loss: 0.0637\n",
      "Batch 444 Loss: 0.0476\n",
      "\n",
      "EPOCH 7 LOSS: 0.0005\n",
      "\n",
      "Reconstruction error recall 0.0297\n",
      "Change: -0.5714%\n",
      "Epoch     7: reducing learning rate of group 0 to 1.6200e-01.\n",
      "\n",
      "\u001b[1mEpoch 8\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0475\n",
      "Batch 111 Loss: 0.0697\n",
      "Batch 222 Loss: 0.0489\n",
      "Batch 333 Loss: 0.0453\n",
      "Batch 444 Loss: 0.0559\n",
      "\n",
      "EPOCH 8 LOSS: 0.0055\n",
      "\n",
      "Reconstruction error recall 0.0198\n",
      "Change: -0.3333%\n",
      "\n",
      "\u001b[1mEpoch 9\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0527\n",
      "Batch 111 Loss: 0.0438\n",
      "Batch 222 Loss: 0.0484\n",
      "Batch 333 Loss: 0.0487\n",
      "Batch 444 Loss: 0.0465\n",
      "\n",
      "EPOCH 9 LOSS: 0.0005\n",
      "\n",
      "Reconstruction error recall 0.0198\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 10\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0440\n",
      "Batch 111 Loss: 0.0538\n",
      "Batch 222 Loss: 0.0493\n",
      "Batch 333 Loss: 0.0454\n",
      "Batch 444 Loss: 0.0550\n",
      "\n",
      "EPOCH 10 LOSS: 0.0002\n",
      "\n",
      "Reconstruction error recall 0.0198\n",
      "Change: 0.0000%\n",
      "Epoch    10: reducing learning rate of group 0 to 1.4580e-01.\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(ae3.parameters(), lr=0.2,momentum=0.9,nesterov=True)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.9, patience=2, verbose=True)\n",
    "train_autoencoder(model=ae3,\n",
    "                  dataset=output2,\n",
    "                  loss_func=loss_func,\n",
    "                  optimizer=optimizer,\n",
    "                  batch_size=512,\n",
    "                  epochs=10,\n",
    "                  noise_factor=0.9,\n",
    "                  validation_tensor=val_torch,\n",
    "                  y_val=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "output3 = ae3(output2)\n",
    "train_output3 = ae3(train_output2)\n",
    "val_output3 = ae3(val_output2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder IV: L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae4 = AutoEncoder(n_features,n_features)\n",
    "\n",
    "def L1_loss(recon,inputs):\n",
    "    MSELoss = nn.MSELoss()\n",
    "    loss = MSELoss(recon,inputs)\n",
    "    for param in ae4.parameters():\n",
    "        loss += lmbda*torch.sum(torch.abs(param))\n",
    "    return loss\n",
    "\n",
    "loss_func = L1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mEpoch 1\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 14.8840\n",
      "Batch 111 Loss: 4.4161\n",
      "Batch 222 Loss: 2.8226\n",
      "Batch 333 Loss: 4.5036\n",
      "Batch 444 Loss: 2.8294\n",
      "\n",
      "EPOCH 1 LOSS: 5.3624\n",
      "\n",
      "Reconstruction error recall: 0.2079\n",
      "\n",
      "\u001b[1mEpoch 2\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 5.3624\n",
      "Batch 111 Loss: 2.8056\n",
      "Batch 222 Loss: 5.4804\n",
      "Batch 333 Loss: 2.6617\n",
      "Batch 444 Loss: 5.2765\n",
      "\n",
      "EPOCH 2 LOSS: 3.3646\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 3\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 3.3646\n",
      "Batch 111 Loss: 5.0493\n",
      "Batch 222 Loss: 3.3831\n",
      "Batch 333 Loss: 4.9237\n",
      "Batch 444 Loss: 3.3378\n",
      "\n",
      "EPOCH 3 LOSS: 4.5558\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 4\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 4.5558\n",
      "Batch 111 Loss: 2.8863\n",
      "Batch 222 Loss: 4.6447\n",
      "Batch 333 Loss: 2.8796\n",
      "Batch 444 Loss: 4.4702\n",
      "\n",
      "EPOCH 4 LOSS: 2.9122\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch     4: reducing learning rate of group 0 to 1.8000e-02.\n",
      "\n",
      "\u001b[1mEpoch 5\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 2.9122\n",
      "Batch 111 Loss: 4.8211\n",
      "Batch 222 Loss: 2.5176\n",
      "Batch 333 Loss: 4.7899\n",
      "Batch 444 Loss: 2.4808\n",
      "\n",
      "EPOCH 5 LOSS: 4.5560\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 6\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 4.5560\n",
      "Batch 111 Loss: 3.0517\n",
      "Batch 222 Loss: 4.5794\n",
      "Batch 333 Loss: 3.1770\n",
      "Batch 444 Loss: 4.4759\n",
      "\n",
      "EPOCH 6 LOSS: 2.6307\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 7\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 2.6307\n",
      "Batch 111 Loss: 3.9010\n",
      "Batch 222 Loss: 2.5943\n",
      "Batch 333 Loss: 4.0981\n",
      "Batch 444 Loss: 2.4017\n",
      "\n",
      "EPOCH 7 LOSS: 4.9718\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch     7: reducing learning rate of group 0 to 1.6200e-02.\n",
      "\n",
      "\u001b[1mEpoch 8\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 4.9718\n",
      "Batch 111 Loss: 2.3040\n",
      "Batch 222 Loss: 4.2214\n",
      "Batch 333 Loss: 2.4216\n",
      "Batch 444 Loss: 4.0936\n",
      "\n",
      "EPOCH 8 LOSS: 2.7884\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 9\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 2.7884\n",
      "Batch 111 Loss: 3.8183\n",
      "Batch 222 Loss: 2.8438\n",
      "Batch 333 Loss: 3.8948\n",
      "Batch 444 Loss: 2.6894\n",
      "\n",
      "EPOCH 9 LOSS: 3.6628\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 10\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 3.6628\n",
      "Batch 111 Loss: 2.4193\n",
      "Batch 222 Loss: 3.6744\n",
      "Batch 333 Loss: 2.2945\n",
      "Batch 444 Loss: 3.7624\n",
      "\n",
      "EPOCH 10 LOSS: 2.4349\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    10: reducing learning rate of group 0 to 1.4580e-02.\n",
      "\n",
      "\u001b[1mEpoch 11\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 2.4349\n",
      "Batch 111 Loss: 3.8242\n",
      "Batch 222 Loss: 2.1637\n",
      "Batch 333 Loss: 3.7560\n",
      "Batch 444 Loss: 2.0109\n",
      "\n",
      "EPOCH 11 LOSS: 3.7282\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 12\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 3.7282\n",
      "Batch 111 Loss: 2.3794\n",
      "Batch 222 Loss: 3.6198\n",
      "Batch 333 Loss: 2.5063\n",
      "Batch 444 Loss: 3.6529\n",
      "\n",
      "EPOCH 12 LOSS: 2.2413\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 13\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 2.2413\n",
      "Batch 111 Loss: 3.3242\n",
      "Batch 222 Loss: 2.1224\n",
      "Batch 333 Loss: 3.2999\n",
      "Batch 444 Loss: 2.0813\n",
      "\n",
      "EPOCH 13 LOSS: 3.7998\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    13: reducing learning rate of group 0 to 1.3122e-02.\n",
      "\n",
      "\u001b[1mEpoch 14\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 3.7998\n",
      "Batch 111 Loss: 1.9786\n",
      "Batch 222 Loss: 3.2942\n",
      "Batch 333 Loss: 2.0112\n",
      "Batch 444 Loss: 3.1006\n",
      "\n",
      "EPOCH 14 LOSS: 2.0939\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 15\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 2.0939\n",
      "Batch 111 Loss: 3.0026\n",
      "Batch 222 Loss: 2.1882\n",
      "Batch 333 Loss: 3.1302\n",
      "Batch 444 Loss: 2.0385\n",
      "\n",
      "EPOCH 15 LOSS: 3.1873\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 16\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 3.1873\n",
      "Batch 111 Loss: 2.0088\n",
      "Batch 222 Loss: 3.2040\n",
      "Batch 333 Loss: 1.9091\n",
      "Batch 444 Loss: 3.2363\n",
      "\n",
      "EPOCH 16 LOSS: 2.0368\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    16: reducing learning rate of group 0 to 1.1810e-02.\n",
      "\n",
      "\u001b[1mEpoch 17\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 2.0368\n",
      "Batch 111 Loss: 2.9839\n",
      "Batch 222 Loss: 1.7446\n",
      "Batch 333 Loss: 2.8123\n",
      "Batch 444 Loss: 1.7921\n",
      "\n",
      "EPOCH 17 LOSS: 2.9270\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 18\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 2.9270\n",
      "Batch 111 Loss: 1.8748\n",
      "Batch 222 Loss: 2.9251\n",
      "Batch 333 Loss: 1.8623\n",
      "Batch 444 Loss: 2.9702\n",
      "\n",
      "EPOCH 18 LOSS: 1.8313\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 19\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.8313\n",
      "Batch 111 Loss: 2.8159\n",
      "Batch 222 Loss: 1.8178\n",
      "Batch 333 Loss: 2.7738\n",
      "Batch 444 Loss: 1.8183\n",
      "\n",
      "EPOCH 19 LOSS: 2.9149\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0629e-02.\n",
      "\n",
      "\u001b[1mEpoch 20\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 2.9149\n",
      "Batch 111 Loss: 1.6740\n",
      "Batch 222 Loss: 2.6121\n",
      "Batch 333 Loss: 1.6270\n",
      "Batch 444 Loss: 2.5085\n",
      "\n",
      "EPOCH 20 LOSS: 1.6488\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 21\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.6488\n",
      "Batch 111 Loss: 2.5385\n",
      "Batch 222 Loss: 1.6250\n",
      "Batch 333 Loss: 2.5526\n",
      "Batch 444 Loss: 1.6231\n",
      "\n",
      "EPOCH 21 LOSS: 2.6578\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 22\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 2.6578\n",
      "Batch 111 Loss: 1.6366\n",
      "Batch 222 Loss: 2.6277\n",
      "Batch 333 Loss: 1.6099\n",
      "Batch 444 Loss: 2.6959\n",
      "\n",
      "EPOCH 22 LOSS: 1.6483\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    22: reducing learning rate of group 0 to 9.5659e-03.\n",
      "\n",
      "\u001b[1mEpoch 23\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.6483\n",
      "Batch 111 Loss: 2.3582\n",
      "Batch 222 Loss: 1.4589\n",
      "Batch 333 Loss: 2.3060\n",
      "Batch 444 Loss: 1.4416\n",
      "\n",
      "EPOCH 23 LOSS: 2.3716\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 24\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 2.3716\n",
      "Batch 111 Loss: 1.4675\n",
      "Batch 222 Loss: 2.3559\n",
      "Batch 333 Loss: 1.4256\n",
      "Batch 444 Loss: 2.4422\n",
      "\n",
      "EPOCH 24 LOSS: 1.5540\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 25\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.5540\n",
      "Batch 111 Loss: 2.3787\n",
      "Batch 222 Loss: 1.5095\n",
      "Batch 333 Loss: 2.3195\n",
      "Batch 444 Loss: 1.4908\n",
      "\n",
      "EPOCH 25 LOSS: 2.3174\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    25: reducing learning rate of group 0 to 8.6093e-03.\n",
      "\n",
      "\u001b[1mEpoch 26\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 2.3174\n",
      "Batch 111 Loss: 1.3329\n",
      "Batch 222 Loss: 2.0428\n",
      "Batch 333 Loss: 1.3114\n",
      "Batch 444 Loss: 2.0015\n",
      "\n",
      "EPOCH 26 LOSS: 1.3100\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 27\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.3100\n",
      "Batch 111 Loss: 2.1074\n",
      "Batch 222 Loss: 1.3237\n",
      "Batch 333 Loss: 2.1187\n",
      "Batch 444 Loss: 1.2955\n",
      "\n",
      "EPOCH 27 LOSS: 2.1395\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 28\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 2.1395\n",
      "Batch 111 Loss: 1.3743\n",
      "Batch 222 Loss: 2.1159\n",
      "Batch 333 Loss: 1.3258\n",
      "Batch 444 Loss: 2.2060\n",
      "\n",
      "EPOCH 28 LOSS: 1.3515\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    28: reducing learning rate of group 0 to 7.7484e-03.\n",
      "\n",
      "\u001b[1mEpoch 29\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.3515\n",
      "Batch 111 Loss: 1.8684\n",
      "Batch 222 Loss: 1.1414\n",
      "Batch 333 Loss: 1.8367\n",
      "Batch 444 Loss: 1.1244\n",
      "\n",
      "EPOCH 29 LOSS: 1.9874\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 30\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.9874\n",
      "Batch 111 Loss: 1.1733\n",
      "Batch 222 Loss: 1.9403\n",
      "Batch 333 Loss: 1.1588\n",
      "Batch 444 Loss: 1.9706\n",
      "\n",
      "EPOCH 30 LOSS: 1.2666\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 31\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.2666\n",
      "Batch 111 Loss: 1.9073\n",
      "Batch 222 Loss: 1.2513\n",
      "Batch 333 Loss: 1.9216\n",
      "Batch 444 Loss: 1.2590\n",
      "\n",
      "EPOCH 31 LOSS: 1.8539\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    31: reducing learning rate of group 0 to 6.9736e-03.\n",
      "\n",
      "\u001b[1mEpoch 32\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.8539\n",
      "Batch 111 Loss: 1.0579\n",
      "Batch 222 Loss: 1.6516\n",
      "Batch 333 Loss: 1.0499\n",
      "Batch 444 Loss: 1.6234\n",
      "\n",
      "EPOCH 32 LOSS: 1.0227\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 33\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.0227\n",
      "Batch 111 Loss: 1.7106\n",
      "Batch 222 Loss: 1.0396\n",
      "Batch 333 Loss: 1.7301\n",
      "Batch 444 Loss: 1.0769\n",
      "\n",
      "EPOCH 33 LOSS: 1.7198\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 34\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.7198\n",
      "Batch 111 Loss: 1.1407\n",
      "Batch 222 Loss: 1.7526\n",
      "Batch 333 Loss: 1.0742\n",
      "Batch 444 Loss: 1.8103\n",
      "\n",
      "EPOCH 34 LOSS: 1.0458\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    34: reducing learning rate of group 0 to 6.2762e-03.\n",
      "\n",
      "\u001b[1mEpoch 35\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.0458\n",
      "Batch 111 Loss: 1.5260\n",
      "Batch 222 Loss: 0.9453\n",
      "Batch 333 Loss: 1.4489\n",
      "Batch 444 Loss: 0.9359\n",
      "\n",
      "EPOCH 35 LOSS: 1.6052\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 36\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.6052\n",
      "Batch 111 Loss: 0.9241\n",
      "Batch 222 Loss: 1.5635\n",
      "Batch 333 Loss: 0.9466\n",
      "Batch 444 Loss: 1.6165\n",
      "\n",
      "EPOCH 36 LOSS: 1.0498\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 37\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.0498\n",
      "Batch 111 Loss: 1.5757\n",
      "Batch 222 Loss: 0.9942\n",
      "Batch 333 Loss: 1.5639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 444 Loss: 1.0322\n",
      "\n",
      "EPOCH 37 LOSS: 1.4880\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    37: reducing learning rate of group 0 to 5.6486e-03.\n",
      "\n",
      "\u001b[1mEpoch 38\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.4880\n",
      "Batch 111 Loss: 0.8611\n",
      "Batch 222 Loss: 1.3516\n",
      "Batch 333 Loss: 0.8455\n",
      "Batch 444 Loss: 1.3007\n",
      "\n",
      "EPOCH 38 LOSS: 0.8287\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 39\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8287\n",
      "Batch 111 Loss: 1.3905\n",
      "Batch 222 Loss: 0.8394\n",
      "Batch 333 Loss: 1.4246\n",
      "Batch 444 Loss: 0.8678\n",
      "\n",
      "EPOCH 39 LOSS: 1.4004\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 40\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.4004\n",
      "Batch 111 Loss: 0.9065\n",
      "Batch 222 Loss: 1.4385\n",
      "Batch 333 Loss: 0.8729\n",
      "Batch 444 Loss: 1.4523\n",
      "\n",
      "EPOCH 40 LOSS: 0.8644\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    40: reducing learning rate of group 0 to 5.0837e-03.\n",
      "\n",
      "\u001b[1mEpoch 41\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8644\n",
      "Batch 111 Loss: 1.2067\n",
      "Batch 222 Loss: 0.7708\n",
      "Batch 333 Loss: 1.1845\n",
      "Batch 444 Loss: 0.7687\n",
      "\n",
      "EPOCH 41 LOSS: 1.2847\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 42\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.2847\n",
      "Batch 111 Loss: 0.7622\n",
      "Batch 222 Loss: 1.2773\n",
      "Batch 333 Loss: 0.7643\n",
      "Batch 444 Loss: 1.3225\n",
      "\n",
      "EPOCH 42 LOSS: 0.8282\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 43\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8282\n",
      "Batch 111 Loss: 1.2875\n",
      "Batch 222 Loss: 0.8208\n",
      "Batch 333 Loss: 1.2656\n",
      "Batch 444 Loss: 0.8091\n",
      "\n",
      "EPOCH 43 LOSS: 1.2226\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    43: reducing learning rate of group 0 to 4.5754e-03.\n",
      "\n",
      "\u001b[1mEpoch 44\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.2226\n",
      "Batch 111 Loss: 0.7007\n",
      "Batch 222 Loss: 1.1040\n",
      "Batch 333 Loss: 0.6889\n",
      "Batch 444 Loss: 1.0636\n",
      "\n",
      "EPOCH 44 LOSS: 0.6646\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 45\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6646\n",
      "Batch 111 Loss: 1.1319\n",
      "Batch 222 Loss: 0.6912\n",
      "Batch 333 Loss: 1.1318\n",
      "Batch 444 Loss: 0.6797\n",
      "\n",
      "EPOCH 45 LOSS: 1.1449\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 46\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.1449\n",
      "Batch 111 Loss: 0.7445\n",
      "Batch 222 Loss: 1.1616\n",
      "Batch 333 Loss: 0.7117\n",
      "Batch 444 Loss: 1.1779\n",
      "\n",
      "EPOCH 46 LOSS: 0.6989\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    46: reducing learning rate of group 0 to 4.1178e-03.\n",
      "\n",
      "\u001b[1mEpoch 47\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6989\n",
      "Batch 111 Loss: 0.9990\n",
      "Batch 222 Loss: 0.6284\n",
      "Batch 333 Loss: 0.9541\n",
      "Batch 444 Loss: 0.6270\n",
      "\n",
      "EPOCH 47 LOSS: 1.0350\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 48\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.0350\n",
      "Batch 111 Loss: 0.6191\n",
      "Batch 222 Loss: 1.0360\n",
      "Batch 333 Loss: 0.6142\n",
      "Batch 444 Loss: 1.0500\n",
      "\n",
      "EPOCH 48 LOSS: 0.6744\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 49\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6744\n",
      "Batch 111 Loss: 1.0454\n",
      "Batch 222 Loss: 0.6680\n",
      "Batch 333 Loss: 1.0241\n",
      "Batch 444 Loss: 0.6561\n",
      "\n",
      "EPOCH 49 LOSS: 0.9911\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    49: reducing learning rate of group 0 to 3.7060e-03.\n",
      "\n",
      "\u001b[1mEpoch 50\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.9911\n",
      "Batch 111 Loss: 0.5591\n",
      "Batch 222 Loss: 0.9105\n",
      "Batch 333 Loss: 0.5670\n",
      "Batch 444 Loss: 0.8839\n",
      "\n",
      "EPOCH 50 LOSS: 0.5471\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 51\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5471\n",
      "Batch 111 Loss: 0.9240\n",
      "Batch 222 Loss: 0.5586\n",
      "Batch 333 Loss: 0.9139\n",
      "Batch 444 Loss: 0.5673\n",
      "\n",
      "EPOCH 51 LOSS: 0.9253\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 52\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.9253\n",
      "Batch 111 Loss: 0.5999\n",
      "Batch 222 Loss: 0.9393\n",
      "Batch 333 Loss: 0.5732\n",
      "Batch 444 Loss: 0.9556\n",
      "\n",
      "EPOCH 52 LOSS: 0.5571\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    52: reducing learning rate of group 0 to 3.3354e-03.\n",
      "\n",
      "\u001b[1mEpoch 53\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5571\n",
      "Batch 111 Loss: 0.8199\n",
      "Batch 222 Loss: 0.5132\n",
      "Batch 333 Loss: 0.7895\n",
      "Batch 444 Loss: 0.4941\n",
      "\n",
      "EPOCH 53 LOSS: 0.8522\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 54\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8522\n",
      "Batch 111 Loss: 0.5018\n",
      "Batch 222 Loss: 0.8289\n",
      "Batch 333 Loss: 0.5116\n",
      "Batch 444 Loss: 0.8611\n",
      "\n",
      "EPOCH 54 LOSS: 0.5320\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 55\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5320\n",
      "Batch 111 Loss: 0.8449\n",
      "Batch 222 Loss: 0.5252\n",
      "Batch 333 Loss: 0.8386\n",
      "Batch 444 Loss: 0.5146\n",
      "\n",
      "EPOCH 55 LOSS: 0.8217\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    55: reducing learning rate of group 0 to 3.0019e-03.\n",
      "\n",
      "\u001b[1mEpoch 56\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8217\n",
      "Batch 111 Loss: 0.4509\n",
      "Batch 222 Loss: 0.7489\n",
      "Batch 333 Loss: 0.4529\n",
      "Batch 444 Loss: 0.7107\n",
      "\n",
      "EPOCH 56 LOSS: 0.4460\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 57\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4460\n",
      "Batch 111 Loss: 0.7471\n",
      "Batch 222 Loss: 0.4580\n",
      "Batch 333 Loss: 0.7452\n",
      "Batch 444 Loss: 0.4607\n",
      "\n",
      "EPOCH 57 LOSS: 0.7397\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 58\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7397\n",
      "Batch 111 Loss: 0.4751\n",
      "Batch 222 Loss: 0.7626\n",
      "Batch 333 Loss: 0.4586\n",
      "Batch 444 Loss: 0.7708\n",
      "\n",
      "EPOCH 58 LOSS: 0.4633\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    58: reducing learning rate of group 0 to 2.7017e-03.\n",
      "\n",
      "\u001b[1mEpoch 59\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4633\n",
      "Batch 111 Loss: 0.6617\n",
      "Batch 222 Loss: 0.4151\n",
      "Batch 333 Loss: 0.6406\n",
      "Batch 444 Loss: 0.4031\n",
      "\n",
      "EPOCH 59 LOSS: 0.6731\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 60\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6731\n",
      "Batch 111 Loss: 0.4131\n",
      "Batch 222 Loss: 0.6783\n",
      "Batch 333 Loss: 0.4073\n",
      "Batch 444 Loss: 0.6971\n",
      "\n",
      "EPOCH 60 LOSS: 0.4284\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 61\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4284\n",
      "Batch 111 Loss: 0.6876\n",
      "Batch 222 Loss: 0.4228\n",
      "Batch 333 Loss: 0.6695\n",
      "Batch 444 Loss: 0.4102\n",
      "\n",
      "EPOCH 61 LOSS: 0.6669\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    61: reducing learning rate of group 0 to 2.4315e-03.\n",
      "\n",
      "\u001b[1mEpoch 62\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6669\n",
      "Batch 111 Loss: 0.3642\n",
      "Batch 222 Loss: 0.5992\n",
      "Batch 333 Loss: 0.3713\n",
      "Batch 444 Loss: 0.5799\n",
      "\n",
      "EPOCH 62 LOSS: 0.3771\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 63\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3771\n",
      "Batch 111 Loss: 0.6042\n",
      "Batch 222 Loss: 0.3813\n",
      "Batch 333 Loss: 0.6018\n",
      "Batch 444 Loss: 0.3737\n",
      "\n",
      "EPOCH 63 LOSS: 0.6018\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 64\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6018\n",
      "Batch 111 Loss: 0.3872\n",
      "Batch 222 Loss: 0.6070\n",
      "Batch 333 Loss: 0.3665\n",
      "Batch 444 Loss: 0.6172\n",
      "\n",
      "EPOCH 64 LOSS: 0.3713\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    64: reducing learning rate of group 0 to 2.1884e-03.\n",
      "\n",
      "\u001b[1mEpoch 65\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3713\n",
      "Batch 111 Loss: 0.5429\n",
      "Batch 222 Loss: 0.3347\n",
      "Batch 333 Loss: 0.5267\n",
      "Batch 444 Loss: 0.3265\n",
      "\n",
      "EPOCH 65 LOSS: 0.5572\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 66\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5572\n",
      "Batch 111 Loss: 0.3283\n",
      "Batch 222 Loss: 0.5466\n",
      "Batch 333 Loss: 0.3328\n",
      "Batch 444 Loss: 0.5541\n",
      "\n",
      "EPOCH 66 LOSS: 0.3470\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 67\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3470\n",
      "Batch 111 Loss: 0.5533\n",
      "Batch 222 Loss: 0.3494\n",
      "Batch 333 Loss: 0.5428\n",
      "Batch 444 Loss: 0.3352\n",
      "\n",
      "EPOCH 67 LOSS: 0.5439\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    67: reducing learning rate of group 0 to 1.9695e-03.\n",
      "\n",
      "\u001b[1mEpoch 68\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5439\n",
      "Batch 111 Loss: 0.2941\n",
      "Batch 222 Loss: 0.4920\n",
      "Batch 333 Loss: 0.3002\n",
      "Batch 444 Loss: 0.4700\n",
      "\n",
      "EPOCH 68 LOSS: 0.3043\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 69\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3043\n",
      "Batch 111 Loss: 0.4894\n",
      "Batch 222 Loss: 0.3074\n",
      "Batch 333 Loss: 0.4807\n",
      "Batch 444 Loss: 0.3082\n",
      "\n",
      "EPOCH 69 LOSS: 0.4868\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 70\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4868\n",
      "Batch 111 Loss: 0.3126\n",
      "Batch 222 Loss: 0.4932\n",
      "Batch 333 Loss: 0.2962\n",
      "Batch 444 Loss: 0.4959\n",
      "\n",
      "EPOCH 70 LOSS: 0.2978\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    70: reducing learning rate of group 0 to 1.7726e-03.\n",
      "\n",
      "\u001b[1mEpoch 71\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2978\n",
      "Batch 111 Loss: 0.4389\n",
      "Batch 222 Loss: 0.2733\n",
      "Batch 333 Loss: 0.4311\n",
      "Batch 444 Loss: 0.2592\n",
      "\n",
      "EPOCH 71 LOSS: 0.4553\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 72\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4553\n",
      "Batch 111 Loss: 0.2714\n",
      "Batch 222 Loss: 0.4467\n",
      "Batch 333 Loss: 0.2696\n",
      "Batch 444 Loss: 0.4536\n",
      "\n",
      "EPOCH 72 LOSS: 0.2771\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 73\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2771\n",
      "Batch 111 Loss: 0.4417\n",
      "Batch 222 Loss: 0.2765\n",
      "Batch 333 Loss: 0.4349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 444 Loss: 0.2745\n",
      "\n",
      "EPOCH 73 LOSS: 0.4386\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    73: reducing learning rate of group 0 to 1.5953e-03.\n",
      "\n",
      "\u001b[1mEpoch 74\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4386\n",
      "Batch 111 Loss: 0.2430\n",
      "Batch 222 Loss: 0.3932\n",
      "Batch 333 Loss: 0.2399\n",
      "Batch 444 Loss: 0.3902\n",
      "\n",
      "EPOCH 74 LOSS: 0.2464\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 75\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2464\n",
      "Batch 111 Loss: 0.3954\n",
      "Batch 222 Loss: 0.2478\n",
      "Batch 333 Loss: 0.3943\n",
      "Batch 444 Loss: 0.2514\n",
      "\n",
      "EPOCH 75 LOSS: 0.3904\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 76\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3904\n",
      "Batch 111 Loss: 0.2487\n",
      "Batch 222 Loss: 0.3936\n",
      "Batch 333 Loss: 0.2431\n",
      "Batch 444 Loss: 0.4021\n",
      "\n",
      "EPOCH 76 LOSS: 0.2406\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    76: reducing learning rate of group 0 to 1.4358e-03.\n",
      "\n",
      "\u001b[1mEpoch 77\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2406\n",
      "Batch 111 Loss: 0.3612\n",
      "Batch 222 Loss: 0.2196\n",
      "Batch 333 Loss: 0.3509\n",
      "Batch 444 Loss: 0.2165\n",
      "\n",
      "EPOCH 77 LOSS: 0.3632\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 78\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3632\n",
      "Batch 111 Loss: 0.2236\n",
      "Batch 222 Loss: 0.3600\n",
      "Batch 333 Loss: 0.2168\n",
      "Batch 444 Loss: 0.3662\n",
      "\n",
      "EPOCH 78 LOSS: 0.2205\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 79\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2205\n",
      "Batch 111 Loss: 0.3562\n",
      "Batch 222 Loss: 0.2262\n",
      "Batch 333 Loss: 0.3481\n",
      "Batch 444 Loss: 0.2170\n",
      "\n",
      "EPOCH 79 LOSS: 0.3588\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    79: reducing learning rate of group 0 to 1.2922e-03.\n",
      "\n",
      "\u001b[1mEpoch 80\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3588\n",
      "Batch 111 Loss: 0.1944\n",
      "Batch 222 Loss: 0.3187\n",
      "Batch 333 Loss: 0.1993\n",
      "Batch 444 Loss: 0.3159\n",
      "\n",
      "EPOCH 80 LOSS: 0.2012\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 81\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2012\n",
      "Batch 111 Loss: 0.3212\n",
      "Batch 222 Loss: 0.2031\n",
      "Batch 333 Loss: 0.3210\n",
      "Batch 444 Loss: 0.2005\n",
      "\n",
      "EPOCH 81 LOSS: 0.3187\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 82\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3187\n",
      "Batch 111 Loss: 0.2061\n",
      "Batch 222 Loss: 0.3200\n",
      "Batch 333 Loss: 0.1954\n",
      "Batch 444 Loss: 0.3237\n",
      "\n",
      "EPOCH 82 LOSS: 0.1944\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    82: reducing learning rate of group 0 to 1.1630e-03.\n",
      "\n",
      "\u001b[1mEpoch 83\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1944\n",
      "Batch 111 Loss: 0.2952\n",
      "Batch 222 Loss: 0.1781\n",
      "Batch 333 Loss: 0.2848\n",
      "Batch 444 Loss: 0.1712\n",
      "\n",
      "EPOCH 83 LOSS: 0.2970\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 84\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2970\n",
      "Batch 111 Loss: 0.1832\n",
      "Batch 222 Loss: 0.2922\n",
      "Batch 333 Loss: 0.1788\n",
      "Batch 444 Loss: 0.2958\n",
      "\n",
      "EPOCH 84 LOSS: 0.1789\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 85\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1789\n",
      "Batch 111 Loss: 0.2869\n",
      "Batch 222 Loss: 0.1850\n",
      "Batch 333 Loss: 0.2830\n",
      "Batch 444 Loss: 0.1803\n",
      "\n",
      "EPOCH 85 LOSS: 0.2917\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0467e-03.\n",
      "\n",
      "\u001b[1mEpoch 86\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2917\n",
      "Batch 111 Loss: 0.1578\n",
      "Batch 222 Loss: 0.2600\n",
      "Batch 333 Loss: 0.1589\n",
      "Batch 444 Loss: 0.2518\n",
      "\n",
      "EPOCH 86 LOSS: 0.1608\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 87\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1608\n",
      "Batch 111 Loss: 0.2625\n",
      "Batch 222 Loss: 0.1634\n",
      "Batch 333 Loss: 0.2591\n",
      "Batch 444 Loss: 0.1650\n",
      "\n",
      "EPOCH 87 LOSS: 0.2564\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 88\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2564\n",
      "Batch 111 Loss: 0.1684\n",
      "Batch 222 Loss: 0.2548\n",
      "Batch 333 Loss: 0.1629\n",
      "Batch 444 Loss: 0.2640\n",
      "\n",
      "EPOCH 88 LOSS: 0.1598\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    88: reducing learning rate of group 0 to 9.4203e-04.\n",
      "\n",
      "\u001b[1mEpoch 89\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1598\n",
      "Batch 111 Loss: 0.2365\n",
      "Batch 222 Loss: 0.1436\n",
      "Batch 333 Loss: 0.2284\n",
      "Batch 444 Loss: 0.1370\n",
      "\n",
      "EPOCH 89 LOSS: 0.2409\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 90\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2409\n",
      "Batch 111 Loss: 0.1459\n",
      "Batch 222 Loss: 0.2382\n",
      "Batch 333 Loss: 0.1483\n",
      "Batch 444 Loss: 0.2429\n",
      "\n",
      "EPOCH 90 LOSS: 0.1508\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 91\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1508\n",
      "Batch 111 Loss: 0.2346\n",
      "Batch 222 Loss: 0.1480\n",
      "Batch 333 Loss: 0.2292\n",
      "Batch 444 Loss: 0.1455\n",
      "\n",
      "EPOCH 91 LOSS: 0.2363\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    91: reducing learning rate of group 0 to 8.4782e-04.\n",
      "\n",
      "\u001b[1mEpoch 92\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2363\n",
      "Batch 111 Loss: 0.1276\n",
      "Batch 222 Loss: 0.2094\n",
      "Batch 333 Loss: 0.1298\n",
      "Batch 444 Loss: 0.2043\n",
      "\n",
      "EPOCH 92 LOSS: 0.1317\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 93\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1317\n",
      "Batch 111 Loss: 0.2094\n",
      "Batch 222 Loss: 0.1365\n",
      "Batch 333 Loss: 0.2075\n",
      "Batch 444 Loss: 0.1310\n",
      "\n",
      "EPOCH 93 LOSS: 0.2099\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 94\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2099\n",
      "Batch 111 Loss: 0.1325\n",
      "Batch 222 Loss: 0.2110\n",
      "Batch 333 Loss: 0.1257\n",
      "Batch 444 Loss: 0.2139\n",
      "\n",
      "EPOCH 94 LOSS: 0.1271\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    94: reducing learning rate of group 0 to 7.6304e-04.\n",
      "\n",
      "\u001b[1mEpoch 95\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1271\n",
      "Batch 111 Loss: 0.1908\n",
      "Batch 222 Loss: 0.1159\n",
      "Batch 333 Loss: 0.1844\n",
      "Batch 444 Loss: 0.1158\n",
      "\n",
      "EPOCH 95 LOSS: 0.1930\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 96\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1930\n",
      "Batch 111 Loss: 0.1208\n",
      "Batch 222 Loss: 0.1898\n",
      "Batch 333 Loss: 0.1181\n",
      "Batch 444 Loss: 0.1962\n",
      "\n",
      "EPOCH 96 LOSS: 0.1222\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 97\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1222\n",
      "Batch 111 Loss: 0.1894\n",
      "Batch 222 Loss: 0.1210\n",
      "Batch 333 Loss: 0.1832\n",
      "Batch 444 Loss: 0.1187\n",
      "\n",
      "EPOCH 97 LOSS: 0.1889\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    97: reducing learning rate of group 0 to 6.8674e-04.\n",
      "\n",
      "\u001b[1mEpoch 98\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1889\n",
      "Batch 111 Loss: 0.1016\n",
      "Batch 222 Loss: 0.1704\n",
      "Batch 333 Loss: 0.1056\n",
      "Batch 444 Loss: 0.1645\n",
      "\n",
      "EPOCH 98 LOSS: 0.1072\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 99\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1072\n",
      "Batch 111 Loss: 0.1740\n",
      "Batch 222 Loss: 0.1072\n",
      "Batch 333 Loss: 0.1696\n",
      "Batch 444 Loss: 0.1071\n",
      "\n",
      "EPOCH 99 LOSS: 0.1708\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 100\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1708\n",
      "Batch 111 Loss: 0.1071\n",
      "Batch 222 Loss: 0.1711\n",
      "Batch 333 Loss: 0.1054\n",
      "Batch 444 Loss: 0.1724\n",
      "\n",
      "EPOCH 100 LOSS: 0.1042\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   100: reducing learning rate of group 0 to 6.1806e-04.\n",
      "\n",
      "\u001b[1mEpoch 101\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1042\n",
      "Batch 111 Loss: 0.1544\n",
      "Batch 222 Loss: 0.0961\n",
      "Batch 333 Loss: 0.1477\n",
      "Batch 444 Loss: 0.0950\n",
      "\n",
      "EPOCH 101 LOSS: 0.1559\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 102\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1559\n",
      "Batch 111 Loss: 0.0979\n",
      "Batch 222 Loss: 0.1586\n",
      "Batch 333 Loss: 0.0938\n",
      "Batch 444 Loss: 0.1577\n",
      "\n",
      "EPOCH 102 LOSS: 0.0944\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 103\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0944\n",
      "Batch 111 Loss: 0.1538\n",
      "Batch 222 Loss: 0.0992\n",
      "Batch 333 Loss: 0.1479\n",
      "Batch 444 Loss: 0.0958\n",
      "\n",
      "EPOCH 103 LOSS: 0.1540\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   103: reducing learning rate of group 0 to 5.5626e-04.\n",
      "\n",
      "\u001b[1mEpoch 104\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1540\n",
      "Batch 111 Loss: 0.0826\n",
      "Batch 222 Loss: 0.1371\n",
      "Batch 333 Loss: 0.0850\n",
      "Batch 444 Loss: 0.1329\n",
      "\n",
      "EPOCH 104 LOSS: 0.0866\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 105\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0866\n",
      "Batch 111 Loss: 0.1379\n",
      "Batch 222 Loss: 0.0882\n",
      "Batch 333 Loss: 0.1370\n",
      "Batch 444 Loss: 0.0881\n",
      "\n",
      "EPOCH 105 LOSS: 0.1360\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 106\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1360\n",
      "Batch 111 Loss: 0.0893\n",
      "Batch 222 Loss: 0.1386\n",
      "Batch 333 Loss: 0.0838\n",
      "Batch 444 Loss: 0.1408\n",
      "\n",
      "EPOCH 106 LOSS: 0.0846\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   106: reducing learning rate of group 0 to 5.0063e-04.\n",
      "\n",
      "\u001b[1mEpoch 107\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0846\n",
      "Batch 111 Loss: 0.1261\n",
      "Batch 222 Loss: 0.0764\n",
      "Batch 333 Loss: 0.1203\n",
      "Batch 444 Loss: 0.0751\n",
      "\n",
      "EPOCH 107 LOSS: 0.1258\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 108\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1258\n",
      "Batch 111 Loss: 0.0775\n",
      "Batch 222 Loss: 0.1248\n",
      "Batch 333 Loss: 0.0785\n",
      "Batch 444 Loss: 0.1276\n",
      "\n",
      "EPOCH 108 LOSS: 0.0788\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 109\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0788\n",
      "Batch 111 Loss: 0.1253\n",
      "Batch 222 Loss: 0.0797\n",
      "Batch 333 Loss: 0.1227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 444 Loss: 0.0776\n",
      "\n",
      "EPOCH 109 LOSS: 0.1247\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   109: reducing learning rate of group 0 to 4.5057e-04.\n",
      "\n",
      "\u001b[1mEpoch 110\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1247\n",
      "Batch 111 Loss: 0.0680\n",
      "Batch 222 Loss: 0.1108\n",
      "Batch 333 Loss: 0.0696\n",
      "Batch 444 Loss: 0.1080\n",
      "\n",
      "EPOCH 110 LOSS: 0.0698\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 111\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0698\n",
      "Batch 111 Loss: 0.1119\n",
      "Batch 222 Loss: 0.0703\n",
      "Batch 333 Loss: 0.1124\n",
      "Batch 444 Loss: 0.0707\n",
      "\n",
      "EPOCH 111 LOSS: 0.1119\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 112\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1119\n",
      "Batch 111 Loss: 0.0721\n",
      "Batch 222 Loss: 0.1128\n",
      "Batch 333 Loss: 0.0680\n",
      "Batch 444 Loss: 0.1145\n",
      "\n",
      "EPOCH 112 LOSS: 0.0682\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   112: reducing learning rate of group 0 to 4.0551e-04.\n",
      "\n",
      "\u001b[1mEpoch 113\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0682\n",
      "Batch 111 Loss: 0.1017\n",
      "Batch 222 Loss: 0.0637\n",
      "Batch 333 Loss: 0.0971\n",
      "Batch 444 Loss: 0.0617\n",
      "\n",
      "EPOCH 113 LOSS: 0.1013\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 114\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1013\n",
      "Batch 111 Loss: 0.0638\n",
      "Batch 222 Loss: 0.1028\n",
      "Batch 333 Loss: 0.0624\n",
      "Batch 444 Loss: 0.1021\n",
      "\n",
      "EPOCH 114 LOSS: 0.0630\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 115\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0630\n",
      "Batch 111 Loss: 0.1008\n",
      "Batch 222 Loss: 0.0646\n",
      "Batch 333 Loss: 0.0986\n",
      "Batch 444 Loss: 0.0630\n",
      "\n",
      "EPOCH 115 LOSS: 0.1009\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   115: reducing learning rate of group 0 to 3.6496e-04.\n",
      "\n",
      "\u001b[1mEpoch 116\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1009\n",
      "Batch 111 Loss: 0.0546\n",
      "Batch 222 Loss: 0.0907\n",
      "Batch 333 Loss: 0.0546\n",
      "Batch 444 Loss: 0.0886\n",
      "\n",
      "EPOCH 116 LOSS: 0.0562\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 117\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0562\n",
      "Batch 111 Loss: 0.0914\n",
      "Batch 222 Loss: 0.0584\n",
      "Batch 333 Loss: 0.0905\n",
      "Batch 444 Loss: 0.0575\n",
      "\n",
      "EPOCH 117 LOSS: 0.0892\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 118\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0892\n",
      "Batch 111 Loss: 0.0572\n",
      "Batch 222 Loss: 0.0907\n",
      "Batch 333 Loss: 0.0562\n",
      "Batch 444 Loss: 0.0914\n",
      "\n",
      "EPOCH 118 LOSS: 0.0557\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   118: reducing learning rate of group 0 to 3.2846e-04.\n",
      "\n",
      "\u001b[1mEpoch 119\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0557\n",
      "Batch 111 Loss: 0.0823\n",
      "Batch 222 Loss: 0.0512\n",
      "Batch 333 Loss: 0.0793\n",
      "Batch 444 Loss: 0.0497\n",
      "\n",
      "EPOCH 119 LOSS: 0.0831\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 120\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0831\n",
      "Batch 111 Loss: 0.0518\n",
      "Batch 222 Loss: 0.0831\n",
      "Batch 333 Loss: 0.0509\n",
      "Batch 444 Loss: 0.0837\n",
      "\n",
      "EPOCH 120 LOSS: 0.0511\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 121\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0511\n",
      "Batch 111 Loss: 0.0823\n",
      "Batch 222 Loss: 0.0518\n",
      "Batch 333 Loss: 0.0804\n",
      "Batch 444 Loss: 0.0512\n",
      "\n",
      "EPOCH 121 LOSS: 0.0821\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   121: reducing learning rate of group 0 to 2.9562e-04.\n",
      "\n",
      "\u001b[1mEpoch 122\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0821\n",
      "Batch 111 Loss: 0.0445\n",
      "Batch 222 Loss: 0.0728\n",
      "Batch 333 Loss: 0.0451\n",
      "Batch 444 Loss: 0.0704\n",
      "\n",
      "EPOCH 122 LOSS: 0.0462\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 123\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0462\n",
      "Batch 111 Loss: 0.0737\n",
      "Batch 222 Loss: 0.0474\n",
      "Batch 333 Loss: 0.0738\n",
      "Batch 444 Loss: 0.0462\n",
      "\n",
      "EPOCH 123 LOSS: 0.0735\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 124\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0735\n",
      "Batch 111 Loss: 0.0471\n",
      "Batch 222 Loss: 0.0727\n",
      "Batch 333 Loss: 0.0446\n",
      "Batch 444 Loss: 0.0742\n",
      "\n",
      "EPOCH 124 LOSS: 0.0447\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   124: reducing learning rate of group 0 to 2.6606e-04.\n",
      "\n",
      "\u001b[1mEpoch 125\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0447\n",
      "Batch 111 Loss: 0.0666\n",
      "Batch 222 Loss: 0.0413\n",
      "Batch 333 Loss: 0.0633\n",
      "Batch 444 Loss: 0.0401\n",
      "\n",
      "EPOCH 125 LOSS: 0.0673\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 126\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0673\n",
      "Batch 111 Loss: 0.0420\n",
      "Batch 222 Loss: 0.0676\n",
      "Batch 333 Loss: 0.0406\n",
      "Batch 444 Loss: 0.0687\n",
      "\n",
      "EPOCH 126 LOSS: 0.0405\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 127\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0405\n",
      "Batch 111 Loss: 0.0669\n",
      "Batch 222 Loss: 0.0424\n",
      "Batch 333 Loss: 0.0641\n",
      "Batch 444 Loss: 0.0419\n",
      "\n",
      "EPOCH 127 LOSS: 0.0659\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   127: reducing learning rate of group 0 to 2.3945e-04.\n",
      "\n",
      "\u001b[1mEpoch 128\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0659\n",
      "Batch 111 Loss: 0.0363\n",
      "Batch 222 Loss: 0.0592\n",
      "Batch 333 Loss: 0.0363\n",
      "Batch 444 Loss: 0.0579\n",
      "\n",
      "EPOCH 128 LOSS: 0.0379\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 129\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0379\n",
      "Batch 111 Loss: 0.0595\n",
      "Batch 222 Loss: 0.0382\n",
      "Batch 333 Loss: 0.0597\n",
      "Batch 444 Loss: 0.0377\n",
      "\n",
      "EPOCH 129 LOSS: 0.0590\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 130\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0590\n",
      "Batch 111 Loss: 0.0377\n",
      "Batch 222 Loss: 0.0596\n",
      "Batch 333 Loss: 0.0359\n",
      "Batch 444 Loss: 0.0601\n",
      "\n",
      "EPOCH 130 LOSS: 0.0354\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   130: reducing learning rate of group 0 to 2.1551e-04.\n",
      "\n",
      "\u001b[1mEpoch 131\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0354\n",
      "Batch 111 Loss: 0.0540\n",
      "Batch 222 Loss: 0.0331\n",
      "Batch 333 Loss: 0.0514\n",
      "Batch 444 Loss: 0.0333\n",
      "\n",
      "EPOCH 131 LOSS: 0.0543\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 132\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0543\n",
      "Batch 111 Loss: 0.0344\n",
      "Batch 222 Loss: 0.0547\n",
      "Batch 333 Loss: 0.0341\n",
      "Batch 444 Loss: 0.0548\n",
      "\n",
      "EPOCH 132 LOSS: 0.0341\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 133\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0341\n",
      "Batch 111 Loss: 0.0535\n",
      "Batch 222 Loss: 0.0341\n",
      "Batch 333 Loss: 0.0523\n",
      "Batch 444 Loss: 0.0336\n",
      "\n",
      "EPOCH 133 LOSS: 0.0538\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   133: reducing learning rate of group 0 to 1.9395e-04.\n",
      "\n",
      "\u001b[1mEpoch 134\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0538\n",
      "Batch 111 Loss: 0.0292\n",
      "Batch 222 Loss: 0.0478\n",
      "Batch 333 Loss: 0.0296\n",
      "Batch 444 Loss: 0.0469\n",
      "\n",
      "EPOCH 134 LOSS: 0.0305\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 135\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0305\n",
      "Batch 111 Loss: 0.0480\n",
      "Batch 222 Loss: 0.0310\n",
      "Batch 333 Loss: 0.0482\n",
      "Batch 444 Loss: 0.0301\n",
      "\n",
      "EPOCH 135 LOSS: 0.0484\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 136\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0484\n",
      "Batch 111 Loss: 0.0303\n",
      "Batch 222 Loss: 0.0480\n",
      "Batch 333 Loss: 0.0291\n",
      "Batch 444 Loss: 0.0485\n",
      "\n",
      "EPOCH 136 LOSS: 0.0297\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   136: reducing learning rate of group 0 to 1.7456e-04.\n",
      "\n",
      "\u001b[1mEpoch 137\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0297\n",
      "Batch 111 Loss: 0.0436\n",
      "Batch 222 Loss: 0.0268\n",
      "Batch 333 Loss: 0.0423\n",
      "Batch 444 Loss: 0.0262\n",
      "\n",
      "EPOCH 137 LOSS: 0.0441\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 138\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0441\n",
      "Batch 111 Loss: 0.0275\n",
      "Batch 222 Loss: 0.0444\n",
      "Batch 333 Loss: 0.0275\n",
      "Batch 444 Loss: 0.0448\n",
      "\n",
      "EPOCH 138 LOSS: 0.0278\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 139\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0278\n",
      "Batch 111 Loss: 0.0434\n",
      "Batch 222 Loss: 0.0281\n",
      "Batch 333 Loss: 0.0421\n",
      "Batch 444 Loss: 0.0276\n",
      "\n",
      "EPOCH 139 LOSS: 0.0433\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   139: reducing learning rate of group 0 to 1.5710e-04.\n",
      "\n",
      "\u001b[1mEpoch 140\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0433\n",
      "Batch 111 Loss: 0.0239\n",
      "Batch 222 Loss: 0.0395\n",
      "Batch 333 Loss: 0.0236\n",
      "Batch 444 Loss: 0.0376\n",
      "\n",
      "EPOCH 140 LOSS: 0.0247\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 141\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0247\n",
      "Batch 111 Loss: 0.0388\n",
      "Batch 222 Loss: 0.0249\n",
      "Batch 333 Loss: 0.0392\n",
      "Batch 444 Loss: 0.0248\n",
      "\n",
      "EPOCH 141 LOSS: 0.0390\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 142\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0390\n",
      "Batch 111 Loss: 0.0248\n",
      "Batch 222 Loss: 0.0382\n",
      "Batch 333 Loss: 0.0245\n",
      "Batch 444 Loss: 0.0396\n",
      "\n",
      "EPOCH 142 LOSS: 0.0243\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   142: reducing learning rate of group 0 to 1.4139e-04.\n",
      "\n",
      "\u001b[1mEpoch 143\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0243\n",
      "Batch 111 Loss: 0.0354\n",
      "Batch 222 Loss: 0.0219\n",
      "Batch 333 Loss: 0.0342\n",
      "Batch 444 Loss: 0.0217\n",
      "\n",
      "EPOCH 143 LOSS: 0.0357\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 144\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0357\n",
      "Batch 111 Loss: 0.0221\n",
      "Batch 222 Loss: 0.0357\n",
      "Batch 333 Loss: 0.0222\n",
      "Batch 444 Loss: 0.0361\n",
      "\n",
      "EPOCH 144 LOSS: 0.0228\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 145\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 111 Loss: 0.0347\n",
      "Batch 222 Loss: 0.0228\n",
      "Batch 333 Loss: 0.0341\n",
      "Batch 444 Loss: 0.0218\n",
      "\n",
      "EPOCH 145 LOSS: 0.0354\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   145: reducing learning rate of group 0 to 1.2725e-04.\n",
      "\n",
      "\u001b[1mEpoch 146\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0354\n",
      "Batch 111 Loss: 0.0193\n",
      "Batch 222 Loss: 0.0316\n",
      "Batch 333 Loss: 0.0199\n",
      "Batch 444 Loss: 0.0308\n",
      "\n",
      "EPOCH 146 LOSS: 0.0198\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 147\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0198\n",
      "Batch 111 Loss: 0.0310\n",
      "Batch 222 Loss: 0.0205\n",
      "Batch 333 Loss: 0.0316\n",
      "Batch 444 Loss: 0.0203\n",
      "\n",
      "EPOCH 147 LOSS: 0.0314\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 148\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0314\n",
      "Batch 111 Loss: 0.0205\n",
      "Batch 222 Loss: 0.0315\n",
      "Batch 333 Loss: 0.0193\n",
      "Batch 444 Loss: 0.0324\n",
      "\n",
      "EPOCH 148 LOSS: 0.0199\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   148: reducing learning rate of group 0 to 1.1453e-04.\n",
      "\n",
      "\u001b[1mEpoch 149\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0199\n",
      "Batch 111 Loss: 0.0290\n",
      "Batch 222 Loss: 0.0179\n",
      "Batch 333 Loss: 0.0278\n",
      "Batch 444 Loss: 0.0173\n",
      "\n",
      "EPOCH 149 LOSS: 0.0294\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 150\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0294\n",
      "Batch 111 Loss: 0.0180\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-97708da475b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                   \u001b[0mvalidation_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_torch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                   y_val=y_val)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-b131393f30ae>\u001b[0m in \u001b[0;36mtrain_autoencoder\u001b[0;34m(model, dataset, loss_func, optimizer, epochs, batch_size, validation_tensor, y_val, lr_rate_scheduler, noise_factor, random_seed, MSE_stopping_threshold)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\033[1mEpoch {}\\033[0m\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnoise_factor\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lmbda=0.25\n",
    "optimizer = torch.optim.SGD(ae4.parameters(), lr=0.02,momentum=0.9,nesterov=True)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.9, patience=2, verbose=True)\n",
    "train_autoencoder(model=ae4,\n",
    "                  dataset=output3,\n",
    "                  loss_func=loss_func,\n",
    "                  optimizer=optimizer,\n",
    "                  batch_size=512,\n",
    "                  epochs=200,\n",
    "                  validation_tensor=val_torch,\n",
    "                  y_val=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "output4 = ae4(output3)\n",
    "train_output4 = ae4(train_output3)\n",
    "val_output4 = ae4(val_output3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder V: Kitchen Sink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae5 = AutoEncoder(n_features,int(n_features//4),dropout=0.5)\n",
    "loss_func = L1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mEpoch 1\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3079\n",
      "Batch 55 Loss: 0.2757\n",
      "Batch 110 Loss: 0.2761\n",
      "Batch 165 Loss: 0.2779\n",
      "Batch 220 Loss: 0.2804\n",
      "\n",
      "EPOCH 1 LOSS: 0.0281\n",
      "\n",
      "Reconstruction error recall: 0.2079\n",
      "\n",
      "\u001b[1mEpoch 2\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2761\n",
      "Batch 55 Loss: 0.2778\n",
      "Batch 110 Loss: 0.2804\n",
      "Batch 165 Loss: 0.2748\n",
      "Batch 220 Loss: 0.2793\n",
      "\n",
      "EPOCH 2 LOSS: 0.0281\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   163: reducing learning rate of group 0 to 6.7628e-05.\n",
      "\n",
      "\u001b[1mEpoch 3\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2768\n",
      "Batch 55 Loss: 0.2819\n",
      "Batch 110 Loss: 0.2805\n",
      "Batch 165 Loss: 0.2801\n",
      "Batch 220 Loss: 0.2792\n",
      "\n",
      "EPOCH 3 LOSS: 0.0280\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 4\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2782\n",
      "Batch 55 Loss: 0.2770\n",
      "Batch 110 Loss: 0.2773\n",
      "Batch 165 Loss: 0.2768\n",
      "Batch 220 Loss: 0.2766\n",
      "\n",
      "EPOCH 4 LOSS: 0.0280\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 5\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2761\n",
      "Batch 55 Loss: 0.2778\n",
      "Batch 110 Loss: 0.2772\n",
      "Batch 165 Loss: 0.2763\n",
      "Batch 220 Loss: 0.2799\n",
      "\n",
      "EPOCH 5 LOSS: 0.0281\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   166: reducing learning rate of group 0 to 6.0865e-05.\n",
      "\n",
      "\u001b[1mEpoch 6\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2793\n",
      "Batch 55 Loss: 0.2778\n",
      "Batch 110 Loss: 0.2748\n",
      "Batch 165 Loss: 0.2757\n",
      "Batch 220 Loss: 0.2785\n",
      "\n",
      "EPOCH 6 LOSS: 0.0281\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 7\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2754\n",
      "Batch 55 Loss: 0.2830\n",
      "Batch 110 Loss: 0.2760\n",
      "Batch 165 Loss: 0.2776\n",
      "Batch 220 Loss: 0.2782\n",
      "\n",
      "EPOCH 7 LOSS: 0.0281\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 8\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2748\n",
      "Batch 55 Loss: 0.2759\n",
      "Batch 110 Loss: 0.2743\n",
      "Batch 165 Loss: 0.2796\n",
      "Batch 220 Loss: 0.2796\n",
      "\n",
      "EPOCH 8 LOSS: 0.0281\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   169: reducing learning rate of group 0 to 5.4779e-05.\n",
      "\n",
      "\u001b[1mEpoch 9\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2776\n",
      "Batch 55 Loss: 0.2764\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-376843786839>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m                   \u001b[0mnoise_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                   \u001b[0mvalidation_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_torch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                   y_val=y_val)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-b131393f30ae>\u001b[0m in \u001b[0;36mtrain_autoencoder\u001b[0;34m(model, dataset, loss_func, optimizer, epochs, batch_size, validation_tensor, y_val, lr_rate_scheduler, noise_factor, random_seed, MSE_stopping_threshold)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnoise_factor\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnoise_factor\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.RMSprop(ae5.parameters(), lr=0.02, weight_decay=0.5)\n",
    "train_autoencoder(model=ae5,\n",
    "                  dataset=output4,\n",
    "                  loss_func=loss_func,\n",
    "                  optimizer=optimizer,\n",
    "                  batch_size=1024,\n",
    "                  epochs=200,\n",
    "                  noise_factor=0.5,\n",
    "                  validation_tensor=val_torch,\n",
    "                  y_val=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "output5 = ae5(output4)\n",
    "train_output5 = ae5(train_output4)\n",
    "val_output5 = ae5(val_output4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add reconstruction score to DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_output = train_output5.detach().numpy()\n",
    "final_val_output = val_output5.detach().numpy()\n",
    "\n",
    "#calculate reconstruction score\n",
    "train_reconstruction_score = np.power(X_train_sc - final_train_output,2).sum(axis=1)\n",
    "train_reconstruction score = train_reconstruction_score/(train_reconstruction_score.max()-train_reconstruction_score.min())\n",
    "val_reconstruction_score = np.power(X_val_sc - final_val_output,2).sum(axis=1)\n",
    "val_reconstruction score = val_reconstruction_score/(val_reconstruction_score.max()-val_reconstruction_score.min())\n",
    "train_results['recon_score']=train_reconstruction_score\n",
    "val_results['recon_score']= val_reconstruction_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with L2 regularization on SMOTE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(n_jobs=-1)\n",
    "smote_train_X, smote_train_y = smote.fit_resample(X_train,y_train)\n",
    "sklearn = LogisticRegression()\n",
    "sklearn.fit(smote_train_X,smote_train_y)\n",
    "train_results['smote']=sklearn.predict_proba(X_train)[:,1]\n",
    "val_results['smote']=sklearn.predict_proba(X_val)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class-Weighted MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add time data to columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.join(time_df)\n",
    "X_val = X_val.join(time_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_keras = to_categorical(y_train)\n",
    "y_val_keras = to_categorical(y_val)\n",
    "class_weights = {0:1,1:1/y_train.mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_keras = sc.fit_transform(X_train)\n",
    "X_val_keras = sc.fit_transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set checkpoint and learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = ReduceLROnPlateau(monitor='loss',\n",
    "                                factor=0.8, \n",
    "                                patience=10, \n",
    "                                verbose=1,\n",
    "                                mode='auto', \n",
    "                                min_delta=0.0001, \n",
    "                                cooldown=0, \n",
    "                                min_lr=0)\n",
    "checkpoint = ModelCheckpoint('checkpoint.best.hdf5',  verbose=1, save_best_only=True, mode='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate and compile MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = models.Sequential()\n",
    "nn.add(layers.Dropout(.3))\n",
    "nn.add(layers.Dense(128, input_shape=(val_results.shape[1],), activation='relu'))\n",
    "nn.add(layers.Dense(64,activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "nn.add(layers.Dropout(.3))\n",
    "nn.add(layers.Dense(32,activation='relu'))\n",
    "nn.add(layers.Dense(16,activation='relu'))\n",
    "nn.add(layers.Dropout(.3))\n",
    "nn.add(layers.Dense(8,activation='relu'))\n",
    "nn.add(layers.Dense(4,activation='relu'))\n",
    "nn.add(layers.Dense(2,activation='sigmoid'))\n",
    "nn.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = models.Sequential()\n",
    "nn.add(layers.Dropout(.3))\n",
    "nn.add(layers.Dense(64,activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "nn.add(layers.Dropout(.3))\n",
    "nn.add(layers.Dense(32,activation='relu'))\n",
    "nn.add(layers.Dense(16,activation='relu'))\n",
    "nn.add(layers.Dropout(.3))\n",
    "nn.add(layers.Dense(8,activation='relu'))\n",
    "nn.add(layers.Dense(4,activation='relu'))\n",
    "nn.add(layers.Dense(2,activation='sigmoid'))\n",
    "nn.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 227845 samples, validate on 56962 samples\n",
      "Epoch 1/1000\n",
      "227845/227845 [==============================] - 6s 24us/step - loss: 0.8567 - val_loss: 0.1358\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13583, saving model to checkpoint.best.hdf5\n",
      "Epoch 2/1000\n",
      "227845/227845 [==============================] - 4s 18us/step - loss: 0.3642 - val_loss: 0.1089\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.13583 to 0.10887, saving model to checkpoint.best.hdf5\n",
      "Epoch 3/1000\n",
      "227845/227845 [==============================] - 4s 19us/step - loss: 0.3368 - val_loss: 0.2072\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.10887\n",
      "Epoch 4/1000\n",
      "227845/227845 [==============================] - 4s 19us/step - loss: 0.3068 - val_loss: 0.0806\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.10887 to 0.08056, saving model to checkpoint.best.hdf5\n",
      "Epoch 5/1000\n",
      "227845/227845 [==============================] - 4s 19us/step - loss: 0.3132 - val_loss: 0.0860\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.08056\n",
      "Epoch 6/1000\n",
      "227845/227845 [==============================] - 4s 19us/step - loss: 0.3185 - val_loss: 0.0792\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.08056 to 0.07918, saving model to checkpoint.best.hdf5\n",
      "Epoch 7/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.2955 - val_loss: 0.0626\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.07918 to 0.06264, saving model to checkpoint.best.hdf5\n",
      "Epoch 8/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.2631 - val_loss: 0.1191\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06264\n",
      "Epoch 9/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.3135 - val_loss: 0.0882\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06264\n",
      "Epoch 10/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.2852 - val_loss: 0.1188\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06264\n",
      "Epoch 11/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.2097 - val_loss: 0.0877\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.06264\n",
      "Epoch 12/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.2852 - val_loss: 0.0772\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.06264\n",
      "Epoch 13/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.2066 - val_loss: 0.0276\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.06264 to 0.02763, saving model to checkpoint.best.hdf5\n",
      "Epoch 14/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.2727 - val_loss: 0.0718\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.02763\n",
      "Epoch 15/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.1997 - val_loss: 0.0402\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.02763\n",
      "Epoch 16/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.2511 - val_loss: 0.0701\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.02763\n",
      "Epoch 17/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.2446 - val_loss: 0.0552\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.02763\n",
      "Epoch 18/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.3111 - val_loss: 0.1201\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.02763\n",
      "Epoch 19/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.2408 - val_loss: 0.0418\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.02763\n",
      "Epoch 20/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.3098 - val_loss: 0.0483\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.02763\n",
      "Epoch 21/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.2919 - val_loss: 0.0612\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.02763\n",
      "Epoch 22/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.2139 - val_loss: 0.0654\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.02763\n",
      "Epoch 23/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.2641 - val_loss: 0.0390\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.02763\n",
      "Epoch 24/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.2677 - val_loss: 0.0624\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.02763\n",
      "Epoch 25/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.2421 - val_loss: 0.0427\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.02763\n",
      "Epoch 26/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.2619 - val_loss: 0.0402\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.02763\n",
      "Epoch 27/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.2552 - val_loss: 0.0886\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.02763\n",
      "Epoch 28/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.2543 - val_loss: 0.0476\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.02763\n",
      "Epoch 29/1000\n",
      "227845/227845 [==============================] - 5s 24us/step - loss: 0.2381 - val_loss: 0.0274\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.02763 to 0.02737, saving model to checkpoint.best.hdf5\n",
      "Epoch 30/1000\n",
      "227845/227845 [==============================] - 5s 24us/step - loss: 0.2256 - val_loss: 0.0421\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.02737\n",
      "Epoch 31/1000\n",
      "227845/227845 [==============================] - 5s 24us/step - loss: 0.2124 - val_loss: 0.0353\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.02737\n",
      "Epoch 32/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.2156 - val_loss: 0.0324\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.02737\n",
      "Epoch 33/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.2186 - val_loss: 0.0520\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.02737\n",
      "Epoch 34/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.2435 - val_loss: 0.0460\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.02737\n",
      "Epoch 35/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.2415 - val_loss: 0.0622\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.02737\n",
      "Epoch 36/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.1932 - val_loss: 0.0438\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.02737\n",
      "Epoch 37/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.2397 - val_loss: 0.0557\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.02737\n",
      "Epoch 38/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.2357 - val_loss: 0.0327\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.02737\n",
      "Epoch 39/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.2201 - val_loss: 0.0406\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.02737\n",
      "Epoch 40/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.2021 - val_loss: 0.0416\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.02737\n",
      "Epoch 41/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.2061 - val_loss: 0.0396\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.02737\n",
      "Epoch 42/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.2375 - val_loss: 0.0431\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.02737\n",
      "Epoch 43/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.2405 - val_loss: 0.0453\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.02737\n",
      "Epoch 44/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.2314 - val_loss: 0.0543\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.02737\n",
      "Epoch 45/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.2524 - val_loss: 0.0560\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.02737\n",
      "Epoch 46/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.2330 - val_loss: 0.0682\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.02737\n",
      "Epoch 47/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.2594 - val_loss: 0.0554\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.02737\n",
      "Epoch 48/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.2022 - val_loss: 0.0436\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.02737\n",
      "Epoch 49/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.2229 - val_loss: 0.0502\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.02737\n",
      "Epoch 50/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.2137 - val_loss: 0.0439\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.02737\n",
      "Epoch 51/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.2087 - val_loss: 0.0531\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.02737\n",
      "Epoch 52/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.1741 - val_loss: 0.0565\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.02737\n",
      "Epoch 53/1000\n",
      "227845/227845 [==============================] - 5s 24us/step - loss: 0.2148 - val_loss: 0.0454\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.02737\n",
      "Epoch 54/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.2378 - val_loss: 0.0334\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.02737\n",
      "Epoch 55/1000\n",
      "227845/227845 [==============================] - 5s 24us/step - loss: 0.1891 - val_loss: 0.0444\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.02737\n",
      "Epoch 56/1000\n",
      "227845/227845 [==============================] - 6s 25us/step - loss: 0.1732 - val_loss: 0.0324\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.02737\n",
      "Epoch 57/1000\n",
      "227845/227845 [==============================] - 5s 24us/step - loss: 0.2690 - val_loss: 0.0532\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.02737\n",
      "Epoch 58/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.2210 - val_loss: 0.0741\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.02737\n",
      "Epoch 59/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.2161 - val_loss: 0.0407\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.02737\n",
      "Epoch 60/1000\n",
      "227845/227845 [==============================] - 5s 24us/step - loss: 0.1823 - val_loss: 0.0309\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.02737\n",
      "Epoch 61/1000\n",
      "227845/227845 [==============================] - 5s 24us/step - loss: 0.2254 - val_loss: 0.0354\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.02737\n",
      "Epoch 62/1000\n",
      "227845/227845 [==============================] - 5s 24us/step - loss: 0.1693 - val_loss: 0.0428\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.02737\n",
      "Epoch 63/1000\n",
      "227845/227845 [==============================] - 5s 24us/step - loss: 0.2279 - val_loss: 0.0778\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.02737\n",
      "Epoch 64/1000\n",
      "227845/227845 [==============================] - 5s 24us/step - loss: 0.2063 - val_loss: 0.0576\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.02737\n",
      "Epoch 65/1000\n",
      "227845/227845 [==============================] - 6s 24us/step - loss: 0.2120 - val_loss: 0.0461\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.02737\n",
      "Epoch 66/1000\n",
      "227845/227845 [==============================] - 6s 25us/step - loss: 0.1522 - val_loss: 0.0270\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.02737 to 0.02701, saving model to checkpoint.best.hdf5\n",
      "Epoch 67/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.1879 - val_loss: 0.0296\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.02701\n",
      "Epoch 68/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1970 - val_loss: 0.0301\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.02701\n",
      "Epoch 69/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.2504 - val_loss: 0.0471\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.02701\n",
      "Epoch 70/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.2241 - val_loss: 0.0306\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.02701\n",
      "Epoch 71/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.2251 - val_loss: 0.0486\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.02701\n",
      "Epoch 72/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1858 - val_loss: 0.0383\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.02701\n",
      "Epoch 73/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.2523 - val_loss: 0.0359\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.02701\n",
      "Epoch 74/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.2179 - val_loss: 0.0236\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.02701 to 0.02356, saving model to checkpoint.best.hdf5\n",
      "Epoch 75/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.2139 - val_loss: 0.0287\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.02356\n",
      "Epoch 76/1000\n",
      "227845/227845 [==============================] - 5s 24us/step - loss: 0.1978 - val_loss: 0.0384\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.02356\n",
      "Epoch 77/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.1603 - val_loss: 0.0226\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.02356 to 0.02260, saving model to checkpoint.best.hdf5\n",
      "Epoch 78/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.2367 - val_loss: 0.0390\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.02260\n",
      "Epoch 79/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.2086 - val_loss: 0.0513\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.02260\n",
      "Epoch 80/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.1992 - val_loss: 0.0313\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.02260\n",
      "Epoch 81/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.1915 - val_loss: 0.0366\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.02260\n",
      "Epoch 82/1000\n",
      "227845/227845 [==============================] - 6s 25us/step - loss: 0.1506 - val_loss: 0.0360\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.02260\n",
      "Epoch 83/1000\n",
      "227845/227845 [==============================] - 6s 25us/step - loss: 0.1441 - val_loss: 0.0199\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.02260 to 0.01987, saving model to checkpoint.best.hdf5\n",
      "Epoch 84/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.2115 - val_loss: 0.0269\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.01987\n",
      "Epoch 85/1000\n",
      "227845/227845 [==============================] - 6s 27us/step - loss: 0.1942 - val_loss: 0.0229\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.01987\n",
      "Epoch 86/1000\n",
      "227845/227845 [==============================] - 6s 27us/step - loss: 0.1711 - val_loss: 0.0216\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.01987\n",
      "Epoch 87/1000\n",
      "227845/227845 [==============================] - 6s 28us/step - loss: 0.2322 - val_loss: 0.0392\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.01987\n",
      "Epoch 88/1000\n",
      "227845/227845 [==============================] - 6s 28us/step - loss: 0.2115 - val_loss: 0.0402\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.01987\n",
      "Epoch 89/1000\n",
      "227845/227845 [==============================] - 6s 28us/step - loss: 0.2086 - val_loss: 0.0260\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.01987\n",
      "Epoch 90/1000\n",
      "227845/227845 [==============================] - 6s 28us/step - loss: 0.1834 - val_loss: 0.0249\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.01987\n",
      "Epoch 91/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.2232 - val_loss: 0.0319\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.01987\n",
      "Epoch 92/1000\n",
      "227845/227845 [==============================] - 6s 25us/step - loss: 0.2002 - val_loss: 0.0380\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.01987\n",
      "Epoch 93/1000\n",
      "227845/227845 [==============================] - 6s 25us/step - loss: 0.1801 - val_loss: 0.0264\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.01987\n",
      "Epoch 94/1000\n",
      "227845/227845 [==============================] - 6s 25us/step - loss: 0.1771 - val_loss: 0.0294\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.01987\n",
      "Epoch 95/1000\n",
      "227845/227845 [==============================] - 6s 25us/step - loss: 0.1603 - val_loss: 0.0288\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.01987\n",
      "Epoch 96/1000\n",
      "227845/227845 [==============================] - 6s 25us/step - loss: 0.2076 - val_loss: 0.0357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00096: val_loss did not improve from 0.01987\n",
      "Epoch 97/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.2022 - val_loss: 0.0399\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.01987\n",
      "Epoch 98/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.2012 - val_loss: 0.0452\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.01987\n",
      "Epoch 99/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1539 - val_loss: 0.0338\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.01987\n",
      "Epoch 100/1000\n",
      "227845/227845 [==============================] - 6s 27us/step - loss: 0.1825 - val_loss: 0.0342\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.01987\n",
      "Epoch 101/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1645 - val_loss: 0.0219\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.01987\n",
      "Epoch 102/1000\n",
      "227845/227845 [==============================] - 6s 25us/step - loss: 0.2227 - val_loss: 0.0429\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.01987\n",
      "Epoch 103/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1759 - val_loss: 0.0358\n",
      "\n",
      "Epoch 00103: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.01987\n",
      "Epoch 104/1000\n",
      "227845/227845 [==============================] - 6s 25us/step - loss: 0.2047 - val_loss: 0.0314\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.01987\n",
      "Epoch 105/1000\n",
      "227845/227845 [==============================] - 6s 25us/step - loss: 0.1507 - val_loss: 0.0266\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.01987\n",
      "Epoch 106/1000\n",
      "227845/227845 [==============================] - 6s 25us/step - loss: 0.1848 - val_loss: 0.0252\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.01987\n",
      "Epoch 107/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.2152 - val_loss: 0.0253\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.01987\n",
      "Epoch 108/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1760 - val_loss: 0.0289\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.01987\n",
      "Epoch 109/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1548 - val_loss: 0.0234\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.01987\n",
      "Epoch 110/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1893 - val_loss: 0.0278\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.01987\n",
      "Epoch 111/1000\n",
      "227845/227845 [==============================] - 6s 27us/step - loss: 0.2226 - val_loss: 0.0351\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.01987\n",
      "Epoch 112/1000\n",
      "227845/227845 [==============================] - 6s 27us/step - loss: 0.1685 - val_loss: 0.0264\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.01987\n",
      "Epoch 113/1000\n",
      "227845/227845 [==============================] - 7s 29us/step - loss: 0.1620 - val_loss: 0.0309\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.01987\n",
      "Epoch 114/1000\n",
      "227845/227845 [==============================] - 7s 31us/step - loss: 0.2103 - val_loss: 0.0360\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.01987\n",
      "Epoch 115/1000\n",
      "227845/227845 [==============================] - 8s 33us/step - loss: 0.1915 - val_loss: 0.0265\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.01987\n",
      "Epoch 116/1000\n",
      "227845/227845 [==============================] - 8s 35us/step - loss: 0.1366 - val_loss: 0.0253\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.01987\n",
      "Epoch 117/1000\n",
      "227845/227845 [==============================] - 8s 34us/step - loss: 0.1889 - val_loss: 0.0251\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.01987\n",
      "Epoch 118/1000\n",
      "227845/227845 [==============================] - 7s 32us/step - loss: 0.1605 - val_loss: 0.0261\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.01987\n",
      "Epoch 119/1000\n",
      "227845/227845 [==============================] - 7s 30us/step - loss: 0.1372 - val_loss: 0.0199\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.01987\n",
      "Epoch 120/1000\n",
      "227845/227845 [==============================] - 7s 31us/step - loss: 0.1438 - val_loss: 0.0206\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.01987\n",
      "Epoch 121/1000\n",
      "227845/227845 [==============================] - 7s 31us/step - loss: 0.1976 - val_loss: 0.0310\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.01987\n",
      "Epoch 122/1000\n",
      "227845/227845 [==============================] - 7s 29us/step - loss: 0.1831 - val_loss: 0.0263\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.01987\n",
      "Epoch 123/1000\n",
      "227845/227845 [==============================] - 7s 29us/step - loss: 0.2251 - val_loss: 0.0350\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.01987\n",
      "Epoch 124/1000\n",
      "227845/227845 [==============================] - 6s 28us/step - loss: 0.1593 - val_loss: 0.0239\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.01987\n",
      "Epoch 125/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1958 - val_loss: 0.0220\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.01987\n",
      "Epoch 126/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1686 - val_loss: 0.0249\n",
      "\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.01987\n",
      "Epoch 127/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.2326 - val_loss: 0.0388\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.01987\n",
      "Epoch 128/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1767 - val_loss: 0.0246\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.01987\n",
      "Epoch 129/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1747 - val_loss: 0.0276\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.01987\n",
      "Epoch 130/1000\n",
      "227845/227845 [==============================] - 6s 25us/step - loss: 0.1840 - val_loss: 0.0226\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.01987\n",
      "Epoch 131/1000\n",
      "227845/227845 [==============================] - 6s 25us/step - loss: 0.1869 - val_loss: 0.0300\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.01987\n",
      "Epoch 132/1000\n",
      "227845/227845 [==============================] - 6s 25us/step - loss: 0.1666 - val_loss: 0.0277\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.01987\n",
      "Epoch 133/1000\n",
      "227845/227845 [==============================] - 6s 28us/step - loss: 0.1854 - val_loss: 0.0265\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.01987\n",
      "Epoch 134/1000\n",
      "227845/227845 [==============================] - 8s 33us/step - loss: 0.2084 - val_loss: 0.0260\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.01987\n",
      "Epoch 135/1000\n",
      "227845/227845 [==============================] - 10s 45us/step - loss: 0.2035 - val_loss: 0.0350\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.01987\n",
      "Epoch 136/1000\n",
      "227845/227845 [==============================] - 12s 52us/step - loss: 0.1786 - val_loss: 0.0236\n",
      "\n",
      "Epoch 00136: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.01987\n",
      "Epoch 137/1000\n",
      "227845/227845 [==============================] - 9s 38us/step - loss: 0.1609 - val_loss: 0.0240\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.01987\n",
      "Epoch 138/1000\n",
      "227845/227845 [==============================] - 7s 30us/step - loss: 0.2340 - val_loss: 0.0355\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.01987\n",
      "Epoch 139/1000\n",
      "227845/227845 [==============================] - 6s 27us/step - loss: 0.1901 - val_loss: 0.0380\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.01987\n",
      "Epoch 140/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.2212 - val_loss: 0.0297\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.01987\n",
      "Epoch 141/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.2035 - val_loss: 0.0286\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.01987\n",
      "Epoch 142/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1670 - val_loss: 0.0257\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.01987\n",
      "Epoch 143/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.2066 - val_loss: 0.0262\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.01987\n",
      "Epoch 144/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1399 - val_loss: 0.0214\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.01987\n",
      "Epoch 145/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1627 - val_loss: 0.0263\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.01987\n",
      "Epoch 146/1000\n",
      "227845/227845 [==============================] - 6s 25us/step - loss: 0.1740 - val_loss: 0.0232\n",
      "\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.01987\n",
      "Epoch 147/1000\n",
      "227845/227845 [==============================] - 6s 25us/step - loss: 0.1686 - val_loss: 0.0266\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.01987\n",
      "Epoch 148/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1836 - val_loss: 0.0249\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.01987\n",
      "Epoch 149/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1794 - val_loss: 0.0235\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.01987\n",
      "Epoch 150/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1823 - val_loss: 0.0284\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.01987\n",
      "Epoch 151/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1406 - val_loss: 0.0203\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.01987\n",
      "Epoch 152/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1977 - val_loss: 0.0267\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.01987\n",
      "Epoch 153/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1650 - val_loss: 0.0245\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.01987\n",
      "Epoch 154/1000\n",
      "227845/227845 [==============================] - 6s 27us/step - loss: 0.2352 - val_loss: 0.0326\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.01987\n",
      "Epoch 155/1000\n",
      "227845/227845 [==============================] - 6s 27us/step - loss: 0.1695 - val_loss: 0.0240\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.01987\n",
      "Epoch 156/1000\n",
      "227845/227845 [==============================] - 6s 28us/step - loss: 0.1722 - val_loss: 0.0231\n",
      "\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.01987\n",
      "Epoch 157/1000\n",
      "227845/227845 [==============================] - 6s 28us/step - loss: 0.1556 - val_loss: 0.0218\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.01987\n",
      "Epoch 158/1000\n",
      "227845/227845 [==============================] - 6s 27us/step - loss: 0.1541 - val_loss: 0.0230\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.01987\n",
      "Epoch 159/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1751 - val_loss: 0.0260\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.01987\n",
      "Epoch 160/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1770 - val_loss: 0.0280\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.01987\n",
      "Epoch 161/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1505 - val_loss: 0.0218\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.01987\n",
      "Epoch 162/1000\n",
      "227845/227845 [==============================] - 6s 27us/step - loss: 0.2022 - val_loss: 0.0273\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.01987\n",
      "Epoch 163/1000\n",
      "227845/227845 [==============================] - 7s 29us/step - loss: 0.2111 - val_loss: 0.0347\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.01987\n",
      "Epoch 164/1000\n",
      "227845/227845 [==============================] - 7s 30us/step - loss: 0.1554 - val_loss: 0.0205\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.01987\n",
      "Epoch 165/1000\n",
      "227845/227845 [==============================] - 7s 29us/step - loss: 0.1378 - val_loss: 0.0183\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.01987 to 0.01833, saving model to checkpoint.best.hdf5\n",
      "Epoch 166/1000\n",
      "227845/227845 [==============================] - 7s 29us/step - loss: 0.1596 - val_loss: 0.0228\n",
      "\n",
      "Epoch 00166: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.01833\n",
      "Epoch 167/1000\n",
      "227845/227845 [==============================] - 6s 28us/step - loss: 0.1774 - val_loss: 0.0263\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.01833\n",
      "Epoch 168/1000\n",
      "227845/227845 [==============================] - 6s 27us/step - loss: 0.1843 - val_loss: 0.0259\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.01833\n",
      "Epoch 169/1000\n",
      "227845/227845 [==============================] - 6s 27us/step - loss: 0.1363 - val_loss: 0.0201\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.01833\n",
      "Epoch 170/1000\n",
      "227845/227845 [==============================] - 6s 27us/step - loss: 0.1337 - val_loss: 0.0221\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.01833\n",
      "Epoch 171/1000\n",
      "227845/227845 [==============================] - 6s 27us/step - loss: 0.1680 - val_loss: 0.0226\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.01833\n",
      "Epoch 172/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1420 - val_loss: 0.0218\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.01833\n",
      "Epoch 173/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1517 - val_loss: 0.0208\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.01833\n",
      "Epoch 174/1000\n",
      "227845/227845 [==============================] - 6s 25us/step - loss: 0.1659 - val_loss: 0.0268\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.01833\n",
      "Epoch 175/1000\n",
      "227845/227845 [==============================] - 6s 25us/step - loss: 0.1802 - val_loss: 0.0254\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.01833\n",
      "Epoch 176/1000\n",
      "227845/227845 [==============================] - 6s 25us/step - loss: 0.1851 - val_loss: 0.0228\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.01833\n",
      "Epoch 177/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1679 - val_loss: 0.0215\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.01833\n",
      "Epoch 178/1000\n",
      "227845/227845 [==============================] - 6s 27us/step - loss: 0.1462 - val_loss: 0.0207\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.01833\n",
      "Epoch 179/1000\n",
      "227845/227845 [==============================] - 6s 27us/step - loss: 0.1658 - val_loss: 0.0204\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.01833\n",
      "Epoch 180/1000\n",
      "227845/227845 [==============================] - 6s 27us/step - loss: 0.1921 - val_loss: 0.0228\n",
      "\n",
      "Epoch 00180: ReduceLROnPlateau reducing learning rate to 5.497558740898967e-05.\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.01833\n",
      "Epoch 181/1000\n",
      "227845/227845 [==============================] - 6s 28us/step - loss: 0.1265 - val_loss: 0.0195\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.01833\n",
      "Epoch 182/1000\n",
      "227845/227845 [==============================] - 7s 30us/step - loss: 0.1855 - val_loss: 0.0239\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.01833\n",
      "Epoch 183/1000\n",
      "227845/227845 [==============================] - 7s 30us/step - loss: 0.1916 - val_loss: 0.0255\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.01833\n",
      "Epoch 184/1000\n",
      "227845/227845 [==============================] - 7s 29us/step - loss: 0.1987 - val_loss: 0.0251\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.01833\n",
      "Epoch 185/1000\n",
      "227845/227845 [==============================] - 6s 27us/step - loss: 0.1626 - val_loss: 0.0243\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.01833\n",
      "Epoch 186/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.2059 - val_loss: 0.0263\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.01833\n",
      "Epoch 187/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1483 - val_loss: 0.0213\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.01833\n",
      "Epoch 188/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1739 - val_loss: 0.0240\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.01833\n",
      "Epoch 189/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1977 - val_loss: 0.0296\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.01833\n",
      "Epoch 190/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1610 - val_loss: 0.0258\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.01833\n",
      "Epoch 191/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1734 - val_loss: 0.0232\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 4.398046876303852e-05.\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.01833\n",
      "Epoch 192/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1658 - val_loss: 0.0233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00192: val_loss did not improve from 0.01833\n",
      "Epoch 193/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1768 - val_loss: 0.0253\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.01833\n",
      "Epoch 194/1000\n",
      "227845/227845 [==============================] - 6s 27us/step - loss: 0.1747 - val_loss: 0.0239\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.01833\n",
      "Epoch 195/1000\n",
      "227845/227845 [==============================] - 6s 27us/step - loss: 0.1654 - val_loss: 0.0228\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.01833\n",
      "Epoch 196/1000\n",
      "227845/227845 [==============================] - 6s 27us/step - loss: 0.1757 - val_loss: 0.0265\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.01833\n",
      "Epoch 197/1000\n",
      "227845/227845 [==============================] - 6s 27us/step - loss: 0.1918 - val_loss: 0.0305\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.01833\n",
      "Epoch 198/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1927 - val_loss: 0.0289\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.01833\n",
      "Epoch 199/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1859 - val_loss: 0.0258\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.01833\n",
      "Epoch 200/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1565 - val_loss: 0.0238\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.01833\n",
      "Epoch 201/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1743 - val_loss: 0.0262\n",
      "\n",
      "Epoch 00201: ReduceLROnPlateau reducing learning rate to 3.518437442835421e-05.\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.01833\n",
      "Epoch 202/1000\n",
      "227845/227845 [==============================] - 6s 27us/step - loss: 0.1655 - val_loss: 0.0247\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.01833\n",
      "Epoch 203/1000\n",
      "227845/227845 [==============================] - 6s 27us/step - loss: 0.1587 - val_loss: 0.0226\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.01833\n",
      "Epoch 204/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1612 - val_loss: 0.0217\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.01833\n",
      "Epoch 205/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1402 - val_loss: 0.0203\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.01833\n",
      "Epoch 206/1000\n",
      "227845/227845 [==============================] - 6s 25us/step - loss: 0.1208 - val_loss: 0.0186\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.01833\n",
      "Epoch 207/1000\n",
      "227845/227845 [==============================] - 6s 25us/step - loss: 0.1665 - val_loss: 0.0216\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.01833\n",
      "Epoch 208/1000\n",
      "227845/227845 [==============================] - 6s 25us/step - loss: 0.1571 - val_loss: 0.0194\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.01833\n",
      "Epoch 209/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1269 - val_loss: 0.0190\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.01833\n",
      "Epoch 210/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1211 - val_loss: 0.0199\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.01833\n",
      "Epoch 211/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1227 - val_loss: 0.0182\n",
      "\n",
      "Epoch 00211: val_loss improved from 0.01833 to 0.01824, saving model to checkpoint.best.hdf5\n",
      "Epoch 212/1000\n",
      "227845/227845 [==============================] - 6s 27us/step - loss: 0.1351 - val_loss: 0.0186\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.01824\n",
      "Epoch 213/1000\n",
      "227845/227845 [==============================] - 6s 27us/step - loss: 0.1586 - val_loss: 0.0220\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.01824\n",
      "Epoch 214/1000\n",
      "227845/227845 [==============================] - 6s 27us/step - loss: 0.1630 - val_loss: 0.0203\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.01824\n",
      "Epoch 215/1000\n",
      "227845/227845 [==============================] - 6s 27us/step - loss: 0.1556 - val_loss: 0.0197\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.01824\n",
      "Epoch 216/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1862 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00216: ReduceLROnPlateau reducing learning rate to 2.8147498960606756e-05.\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.01824\n",
      "Epoch 217/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1691 - val_loss: 0.0206\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.01824\n",
      "Epoch 218/1000\n",
      "227845/227845 [==============================] - 6s 25us/step - loss: 0.1304 - val_loss: 0.0194\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.01824\n",
      "Epoch 219/1000\n",
      "227845/227845 [==============================] - 6s 25us/step - loss: 0.1485 - val_loss: 0.0194\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.01824\n",
      "Epoch 220/1000\n",
      "227845/227845 [==============================] - 6s 25us/step - loss: 0.1719 - val_loss: 0.0206\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.01824\n",
      "Epoch 221/1000\n",
      "227845/227845 [==============================] - 6s 25us/step - loss: 0.2107 - val_loss: 0.0239\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.01824\n",
      "Epoch 222/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1534 - val_loss: 0.0224\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.01824\n",
      "Epoch 223/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1759 - val_loss: 0.0224\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.01824\n",
      "Epoch 224/1000\n",
      "227845/227845 [==============================] - 6s 27us/step - loss: 0.1687 - val_loss: 0.0234\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.01824\n",
      "Epoch 225/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1299 - val_loss: 0.0208\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.01824\n",
      "Epoch 226/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1497 - val_loss: 0.0207\n",
      "\n",
      "Epoch 00226: ReduceLROnPlateau reducing learning rate to 2.25179988774471e-05.\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.01824\n",
      "Epoch 227/1000\n",
      "227845/227845 [==============================] - 6s 25us/step - loss: 0.1683 - val_loss: 0.0211\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.01824\n",
      "Epoch 228/1000\n",
      "227845/227845 [==============================] - 6s 25us/step - loss: 0.1585 - val_loss: 0.0218\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.01824\n",
      "Epoch 229/1000\n",
      "227845/227845 [==============================] - 6s 25us/step - loss: 0.1491 - val_loss: 0.0212\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.01824\n",
      "Epoch 230/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1584 - val_loss: 0.0220\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.01824\n",
      "Epoch 231/1000\n",
      "227845/227845 [==============================] - 6s 27us/step - loss: 0.1586 - val_loss: 0.0217\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.01824\n",
      "Epoch 232/1000\n",
      "227845/227845 [==============================] - 6s 28us/step - loss: 0.1146 - val_loss: 0.0196\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.01824\n",
      "Epoch 233/1000\n",
      "227845/227845 [==============================] - 6s 28us/step - loss: 0.1580 - val_loss: 0.0206\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.01824\n",
      "Epoch 234/1000\n",
      "227845/227845 [==============================] - 6s 28us/step - loss: 0.1408 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.01824\n",
      "Epoch 235/1000\n",
      "227845/227845 [==============================] - 6s 28us/step - loss: 0.1891 - val_loss: 0.0221\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.01824\n",
      "Epoch 236/1000\n",
      "227845/227845 [==============================] - 6s 27us/step - loss: 0.1621 - val_loss: 0.0221\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.01824\n",
      "Epoch 237/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1839 - val_loss: 0.0224\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.01824\n",
      "Epoch 238/1000\n",
      "227845/227845 [==============================] - 6s 25us/step - loss: 0.2193 - val_loss: 0.0246\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.01824\n",
      "Epoch 239/1000\n",
      "227845/227845 [==============================] - 6s 25us/step - loss: 0.1908 - val_loss: 0.0258\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.01824\n",
      "Epoch 240/1000\n",
      "227845/227845 [==============================] - 6s 25us/step - loss: 0.1828 - val_loss: 0.0232\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.01824\n",
      "Epoch 241/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1733 - val_loss: 0.0230\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.01824\n",
      "Epoch 242/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1631 - val_loss: 0.0228\n",
      "\n",
      "Epoch 00242: ReduceLROnPlateau reducing learning rate to 1.8014399392995985e-05.\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.01824\n",
      "Epoch 243/1000\n",
      "227845/227845 [==============================] - 6s 26us/step - loss: 0.1618 - val_loss: 0.0227\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.01824\n",
      "Epoch 244/1000\n",
      "227845/227845 [==============================] - 6s 25us/step - loss: 0.1473 - val_loss: 0.0220\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.01824\n",
      "Epoch 245/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.1698 - val_loss: 0.0219\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.01824\n",
      "Epoch 246/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.1533 - val_loss: 0.0207\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.01824\n",
      "Epoch 247/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.1340 - val_loss: 0.0196\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.01824\n",
      "Epoch 248/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1857 - val_loss: 0.0211\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.01824\n",
      "Epoch 249/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1353 - val_loss: 0.0201\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.01824\n",
      "Epoch 250/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.1647 - val_loss: 0.0202\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.01824\n",
      "Epoch 251/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.1279 - val_loss: 0.0196\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.01824\n",
      "Epoch 252/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.1228 - val_loss: 0.0195\n",
      "\n",
      "Epoch 00252: ReduceLROnPlateau reducing learning rate to 1.4411519805435093e-05.\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.01824\n",
      "Epoch 253/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.2031 - val_loss: 0.0213\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.01824\n",
      "Epoch 254/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.1268 - val_loss: 0.0198\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.01824\n",
      "Epoch 255/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.1718 - val_loss: 0.0199\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.01824\n",
      "Epoch 256/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.1503 - val_loss: 0.0200\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.01824\n",
      "Epoch 257/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.1669 - val_loss: 0.0202\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.01824\n",
      "Epoch 258/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.1491 - val_loss: 0.0194\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.01824\n",
      "Epoch 259/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.1783 - val_loss: 0.0206\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.01824\n",
      "Epoch 260/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.1588 - val_loss: 0.0201\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.01824\n",
      "Epoch 261/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.1206 - val_loss: 0.0191\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.01824\n",
      "Epoch 262/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.1966 - val_loss: 0.0219\n",
      "\n",
      "Epoch 00262: ReduceLROnPlateau reducing learning rate to 1.1529216135386379e-05.\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.01824\n",
      "Epoch 263/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.1661 - val_loss: 0.0217\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.01824\n",
      "Epoch 264/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.1604 - val_loss: 0.0220\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.01824\n",
      "Epoch 265/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.1512 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.01824\n",
      "Epoch 266/1000\n",
      "227845/227845 [==============================] - 5s 24us/step - loss: 0.1634 - val_loss: 0.0203\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.01824\n",
      "Epoch 267/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.1450 - val_loss: 0.0204\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.01824\n",
      "Epoch 268/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.1924 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.01824\n",
      "Epoch 269/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1397 - val_loss: 0.0205\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.01824\n",
      "Epoch 270/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1690 - val_loss: 0.0212\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.01824\n",
      "Epoch 271/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1436 - val_loss: 0.0199\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.01824\n",
      "Epoch 272/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1531 - val_loss: 0.0198\n",
      "\n",
      "Epoch 00272: ReduceLROnPlateau reducing learning rate to 9.223372762789951e-06.\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.01824\n",
      "Epoch 273/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.1499 - val_loss: 0.0200\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.01824\n",
      "Epoch 274/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.1664 - val_loss: 0.0205\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.01824\n",
      "Epoch 275/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.1620 - val_loss: 0.0208\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.01824\n",
      "Epoch 276/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1496 - val_loss: 0.0205\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.01824\n",
      "Epoch 277/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1745 - val_loss: 0.0205\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.01824\n",
      "Epoch 278/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1944 - val_loss: 0.0216\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.01824\n",
      "Epoch 279/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1430 - val_loss: 0.0203\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.01824\n",
      "Epoch 280/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1512 - val_loss: 0.0203\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.01824\n",
      "Epoch 281/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1483 - val_loss: 0.0201\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.01824\n",
      "Epoch 282/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.2010 - val_loss: 0.0211\n",
      "\n",
      "Epoch 00282: ReduceLROnPlateau reducing learning rate to 7.378698501270265e-06.\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.01824\n",
      "Epoch 283/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1387 - val_loss: 0.0204\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.01824\n",
      "Epoch 284/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1604 - val_loss: 0.0199\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.01824\n",
      "Epoch 285/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1327 - val_loss: 0.0194\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.01824\n",
      "Epoch 286/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.1762 - val_loss: 0.0198\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.01824\n",
      "Epoch 287/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.1555 - val_loss: 0.0196\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.01824\n",
      "Epoch 288/1000\n",
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.1503 - val_loss: 0.0193\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.01824\n",
      "Epoch 289/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227845/227845 [==============================] - 5s 23us/step - loss: 0.1383 - val_loss: 0.0190\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.01824\n",
      "Epoch 290/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1775 - val_loss: 0.0198\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.01824\n",
      "Epoch 291/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1512 - val_loss: 0.0201\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.01824\n",
      "Epoch 292/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1905 - val_loss: 0.0207\n",
      "\n",
      "Epoch 00292: ReduceLROnPlateau reducing learning rate to 5.902958946535364e-06.\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.01824\n",
      "Epoch 293/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1802 - val_loss: 0.0215\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.01824\n",
      "Epoch 294/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1789 - val_loss: 0.0212\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.01824\n",
      "Epoch 295/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1492 - val_loss: 0.0211\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.01824\n",
      "Epoch 296/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1624 - val_loss: 0.0206\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.01824\n",
      "Epoch 297/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1813 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.01824\n",
      "Epoch 298/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1564 - val_loss: 0.0207\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.01824\n",
      "Epoch 299/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1532 - val_loss: 0.0201\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.01824\n",
      "Epoch 300/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1577 - val_loss: 0.0202\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.01824\n",
      "Epoch 301/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1743 - val_loss: 0.0202\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.01824\n",
      "Epoch 302/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1616 - val_loss: 0.0203\n",
      "\n",
      "Epoch 00302: ReduceLROnPlateau reducing learning rate to 4.7223671572282915e-06.\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.01824\n",
      "Epoch 303/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1523 - val_loss: 0.0200\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.01824\n",
      "Epoch 304/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1628 - val_loss: 0.0200\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.01824\n",
      "Epoch 305/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1673 - val_loss: 0.0203\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.01824\n",
      "Epoch 306/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1574 - val_loss: 0.0202\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.01824\n",
      "Epoch 307/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1554 - val_loss: 0.0201\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.01824\n",
      "Epoch 308/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1749 - val_loss: 0.0204\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.01824\n",
      "Epoch 309/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1409 - val_loss: 0.0203\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.01824\n",
      "Epoch 310/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1737 - val_loss: 0.0207\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.01824\n",
      "Epoch 311/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1392 - val_loss: 0.0206\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.01824\n",
      "Epoch 312/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1691 - val_loss: 0.0206\n",
      "\n",
      "Epoch 00312: ReduceLROnPlateau reducing learning rate to 3.7778936530230567e-06.\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.01824\n",
      "Epoch 313/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1623 - val_loss: 0.0208\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.01824\n",
      "Epoch 314/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1734 - val_loss: 0.0211\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.01824\n",
      "Epoch 315/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1460 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.01824\n",
      "Epoch 316/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1520 - val_loss: 0.0207\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.01824\n",
      "Epoch 317/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1799 - val_loss: 0.0208\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.01824\n",
      "Epoch 318/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1337 - val_loss: 0.0205\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.01824\n",
      "Epoch 319/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1744 - val_loss: 0.0206\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.01824\n",
      "Epoch 320/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1485 - val_loss: 0.0206\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.01824\n",
      "Epoch 321/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1566 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.01824\n",
      "Epoch 322/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1957 - val_loss: 0.0217\n",
      "\n",
      "Epoch 00322: ReduceLROnPlateau reducing learning rate to 3.0223149224184457e-06.\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.01824\n",
      "Epoch 323/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1775 - val_loss: 0.0220\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.01824\n",
      "Epoch 324/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1677 - val_loss: 0.0220\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.01824\n",
      "Epoch 325/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1767 - val_loss: 0.0220\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.01824\n",
      "Epoch 326/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1564 - val_loss: 0.0220\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.01824\n",
      "Epoch 327/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1579 - val_loss: 0.0218\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.01824\n",
      "Epoch 328/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1599 - val_loss: 0.0219\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.01824\n",
      "Epoch 329/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1795 - val_loss: 0.0219\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.01824\n",
      "Epoch 330/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1411 - val_loss: 0.0217\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.01824\n",
      "Epoch 331/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1768 - val_loss: 0.0219\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.01824\n",
      "Epoch 332/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1635 - val_loss: 0.0218\n",
      "\n",
      "Epoch 00332: ReduceLROnPlateau reducing learning rate to 2.4178520106943328e-06.\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.01824\n",
      "Epoch 333/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1612 - val_loss: 0.0218\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.01824\n",
      "Epoch 334/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1447 - val_loss: 0.0215\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.01824\n",
      "Epoch 335/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1894 - val_loss: 0.0216\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.01824\n",
      "Epoch 336/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1412 - val_loss: 0.0215\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.01824\n",
      "Epoch 337/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1615 - val_loss: 0.0215\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.01824\n",
      "Epoch 338/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1520 - val_loss: 0.0214\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.01824\n",
      "Epoch 339/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1488 - val_loss: 0.0212\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.01824\n",
      "Epoch 340/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1772 - val_loss: 0.0214\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.01824\n",
      "Epoch 341/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1386 - val_loss: 0.0211\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 0.01824\n",
      "Epoch 342/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1731 - val_loss: 0.0213\n",
      "\n",
      "Epoch 00342: ReduceLROnPlateau reducing learning rate to 1.9342816813150422e-06.\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.01824\n",
      "Epoch 343/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1428 - val_loss: 0.0211\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.01824\n",
      "Epoch 344/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.2119 - val_loss: 0.0215\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.01824\n",
      "Epoch 345/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1625 - val_loss: 0.0216\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.01824\n",
      "Epoch 346/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1799 - val_loss: 0.0218\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.01824\n",
      "Epoch 347/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1893 - val_loss: 0.0220\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.01824\n",
      "Epoch 348/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1496 - val_loss: 0.0219\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.01824\n",
      "Epoch 349/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1646 - val_loss: 0.0220\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.01824\n",
      "Epoch 350/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1702 - val_loss: 0.0220\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.01824\n",
      "Epoch 351/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1736 - val_loss: 0.0222\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.01824\n",
      "Epoch 352/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1254 - val_loss: 0.0220\n",
      "\n",
      "Epoch 00352: ReduceLROnPlateau reducing learning rate to 1.547425381431822e-06.\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.01824\n",
      "Epoch 353/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1421 - val_loss: 0.0218\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.01824\n",
      "Epoch 354/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1481 - val_loss: 0.0217\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.01824\n",
      "Epoch 355/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1462 - val_loss: 0.0216\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.01824\n",
      "Epoch 356/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1713 - val_loss: 0.0216\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.01824\n",
      "Epoch 357/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1534 - val_loss: 0.0215\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 0.01824\n",
      "Epoch 358/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1785 - val_loss: 0.0215\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.01824\n",
      "Epoch 359/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1488 - val_loss: 0.0214\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.01824\n",
      "Epoch 360/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1349 - val_loss: 0.0214\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.01824\n",
      "Epoch 361/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1539 - val_loss: 0.0212\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.01824\n",
      "Epoch 362/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1684 - val_loss: 0.0212\n",
      "\n",
      "Epoch 00362: ReduceLROnPlateau reducing learning rate to 1.2379403415252455e-06.\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 0.01824\n",
      "Epoch 363/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1174 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 0.01824\n",
      "Epoch 364/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1777 - val_loss: 0.0211\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.01824\n",
      "Epoch 365/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1450 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.01824\n",
      "Epoch 366/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1656 - val_loss: 0.0212\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.01824\n",
      "Epoch 367/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1752 - val_loss: 0.0212\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 0.01824\n",
      "Epoch 368/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1835 - val_loss: 0.0212\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.01824\n",
      "Epoch 369/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1628 - val_loss: 0.0212\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.01824\n",
      "Epoch 370/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1555 - val_loss: 0.0213\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.01824\n",
      "Epoch 371/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1557 - val_loss: 0.0213\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.01824\n",
      "Epoch 372/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1086 - val_loss: 0.0211\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.01824\n",
      "Epoch 373/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1552 - val_loss: 0.0211\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.01824\n",
      "Epoch 374/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1723 - val_loss: 0.0212\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 0.01824\n",
      "Epoch 375/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.2108 - val_loss: 0.0214\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.01824\n",
      "Epoch 376/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1645 - val_loss: 0.0214\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.01824\n",
      "Epoch 377/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1764 - val_loss: 0.0214\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 0.01824\n",
      "Epoch 378/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1596 - val_loss: 0.0214\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.01824\n",
      "Epoch 379/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1562 - val_loss: 0.0214\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.01824\n",
      "Epoch 380/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.2035 - val_loss: 0.0215\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.01824\n",
      "Epoch 381/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1661 - val_loss: 0.0217\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 0.01824\n",
      "Epoch 382/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1664 - val_loss: 0.0218\n",
      "\n",
      "Epoch 00382: ReduceLROnPlateau reducing learning rate to 9.903522368404083e-07.\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 0.01824\n",
      "Epoch 383/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1358 - val_loss: 0.0217\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 0.01824\n",
      "Epoch 384/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.1441 - val_loss: 0.0216\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 0.01824\n",
      "Epoch 385/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1404 - val_loss: 0.0215\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 0.01824\n",
      "Epoch 386/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1525 - val_loss: 0.0214\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 0.01824\n",
      "Epoch 387/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.2042 - val_loss: 0.0214\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 0.01824\n",
      "Epoch 388/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1528 - val_loss: 0.0213\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.01824\n",
      "Epoch 389/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1552 - val_loss: 0.0212\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 0.01824\n",
      "Epoch 390/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1924 - val_loss: 0.0213\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.01824\n",
      "Epoch 391/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1416 - val_loss: 0.0212\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.01824\n",
      "Epoch 392/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1673 - val_loss: 0.0212\n",
      "\n",
      "Epoch 00392: ReduceLROnPlateau reducing learning rate to 7.922817530925386e-07.\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.01824\n",
      "Epoch 393/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1519 - val_loss: 0.0212\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 0.01824\n",
      "Epoch 394/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1262 - val_loss: 0.0211\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 0.01824\n",
      "Epoch 395/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1493 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 0.01824\n",
      "Epoch 396/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1487 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 0.01824\n",
      "Epoch 397/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1503 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.01824\n",
      "Epoch 398/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1433 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 0.01824\n",
      "Epoch 399/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1815 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 0.01824\n",
      "Epoch 400/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1793 - val_loss: 0.0211\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.01824\n",
      "Epoch 401/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1757 - val_loss: 0.0212\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 0.01824\n",
      "Epoch 402/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1880 - val_loss: 0.0213\n",
      "\n",
      "Epoch 00402: ReduceLROnPlateau reducing learning rate to 6.338254024740309e-07.\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 0.01824\n",
      "Epoch 403/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1546 - val_loss: 0.0212\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 0.01824\n",
      "Epoch 404/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1545 - val_loss: 0.0212\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 0.01824\n",
      "Epoch 405/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1702 - val_loss: 0.0212\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 0.01824\n",
      "Epoch 406/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1457 - val_loss: 0.0212\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 0.01824\n",
      "Epoch 407/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1746 - val_loss: 0.0212\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 0.01824\n",
      "Epoch 408/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1406 - val_loss: 0.0212\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 0.01824\n",
      "Epoch 409/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1634 - val_loss: 0.0212\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 0.01824\n",
      "Epoch 410/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1789 - val_loss: 0.0212\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 0.01824\n",
      "Epoch 411/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1240 - val_loss: 0.0211\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 0.01824\n",
      "Epoch 412/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1287 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00412: ReduceLROnPlateau reducing learning rate to 5.070603037893307e-07.\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 0.01824\n",
      "Epoch 413/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1744 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 0.01824\n",
      "Epoch 414/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1681 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 0.01824\n",
      "Epoch 415/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1353 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 0.01824\n",
      "Epoch 416/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1550 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 0.01824\n",
      "Epoch 417/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1798 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 0.01824\n",
      "Epoch 418/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1812 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 0.01824\n",
      "Epoch 419/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1435 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 0.01824\n",
      "Epoch 420/1000\n",
      "227845/227845 [==============================] - 4s 19us/step - loss: 0.1720 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 0.01824\n",
      "Epoch 421/1000\n",
      "227845/227845 [==============================] - 4s 19us/step - loss: 0.1518 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 0.01824\n",
      "Epoch 422/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1764 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00422: ReduceLROnPlateau reducing learning rate to 4.056482339365175e-07.\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 0.01824\n",
      "Epoch 423/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1527 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 0.01824\n",
      "Epoch 424/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1571 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 0.01824\n",
      "Epoch 425/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1491 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 0.01824\n",
      "Epoch 426/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1595 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 0.01824\n",
      "Epoch 427/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1424 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 0.01824\n",
      "Epoch 428/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1825 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 0.01824\n",
      "Epoch 429/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1788 - val_loss: 0.0211\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 0.01824\n",
      "Epoch 430/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1785 - val_loss: 0.0211\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 0.01824\n",
      "Epoch 431/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1770 - val_loss: 0.0211\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 0.01824\n",
      "Epoch 432/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1536 - val_loss: 0.0211\n",
      "\n",
      "Epoch 00432: ReduceLROnPlateau reducing learning rate to 3.24518578054267e-07.\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 0.01824\n",
      "Epoch 433/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1781 - val_loss: 0.0211\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 0.01824\n",
      "Epoch 434/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1501 - val_loss: 0.0211\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 0.01824\n",
      "Epoch 435/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1435 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 0.01824\n",
      "Epoch 436/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1576 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 0.01824\n",
      "Epoch 437/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1512 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 0.01824\n",
      "Epoch 438/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1576 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 0.01824\n",
      "Epoch 439/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1480 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 0.01824\n",
      "Epoch 440/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1769 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.01824\n",
      "Epoch 441/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1268 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 0.01824\n",
      "Epoch 442/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1359 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00442: ReduceLROnPlateau reducing learning rate to 2.5961485334846656e-07.\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 0.01824\n",
      "Epoch 443/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1628 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 0.01824\n",
      "Epoch 444/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1518 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.01824\n",
      "Epoch 445/1000\n",
      "227845/227845 [==============================] - 4s 19us/step - loss: 0.1390 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.01824\n",
      "Epoch 446/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1460 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 0.01824\n",
      "Epoch 447/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1731 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 0.01824\n",
      "Epoch 448/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.2009 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 0.01824\n",
      "Epoch 449/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1614 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 0.01824\n",
      "Epoch 450/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1706 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 0.01824\n",
      "Epoch 451/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1303 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 0.01824\n",
      "Epoch 452/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1511 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00452: ReduceLROnPlateau reducing learning rate to 2.076918917737203e-07.\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 0.01824\n",
      "Epoch 453/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1792 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 0.01824\n",
      "Epoch 454/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1839 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 0.01824\n",
      "Epoch 455/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1505 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 0.01824\n",
      "Epoch 456/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.1279 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 0.01824\n",
      "Epoch 457/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1494 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 0.01824\n",
      "Epoch 458/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1507 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 0.01824\n",
      "Epoch 459/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.1665 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 0.01824\n",
      "Epoch 460/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1707 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 0.01824\n",
      "Epoch 461/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1935 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 0.01824\n",
      "Epoch 462/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1864 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00462: ReduceLROnPlateau reducing learning rate to 1.6615351796644973e-07.\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 0.01824\n",
      "Epoch 463/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1426 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 0.01824\n",
      "Epoch 464/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1573 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 0.01824\n",
      "Epoch 465/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1327 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 0.01824\n",
      "Epoch 466/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1608 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 0.01824\n",
      "Epoch 467/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1313 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 0.01824\n",
      "Epoch 468/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1673 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 0.01824\n",
      "Epoch 469/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1795 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 0.01824\n",
      "Epoch 470/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1953 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 0.01824\n",
      "Epoch 471/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1549 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 0.01824\n",
      "Epoch 472/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1653 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00472: ReduceLROnPlateau reducing learning rate to 1.329228098256863e-07.\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 0.01824\n",
      "Epoch 473/1000\n",
      "227845/227845 [==============================] - 4s 19us/step - loss: 0.1869 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 0.01824\n",
      "Epoch 474/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1755 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 0.01824\n",
      "Epoch 475/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1369 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 0.01824\n",
      "Epoch 476/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1456 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 0.01824\n",
      "Epoch 477/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1839 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 0.01824\n",
      "Epoch 478/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1442 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 0.01824\n",
      "Epoch 479/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1723 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 0.01824\n",
      "Epoch 480/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1360 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.01824\n",
      "Epoch 481/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1555 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 0.01824\n",
      "Epoch 482/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1620 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00482: ReduceLROnPlateau reducing learning rate to 1.0633824558681227e-07.\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 0.01824\n",
      "Epoch 483/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.1751 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 0.01824\n",
      "Epoch 484/1000\n",
      "227845/227845 [==============================] - 4s 19us/step - loss: 0.1508 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 0.01824\n",
      "Epoch 485/1000\n",
      "227845/227845 [==============================] - 4s 19us/step - loss: 0.1996 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 0.01824\n",
      "Epoch 486/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1526 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 0.01824\n",
      "Epoch 487/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1684 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 0.01824\n",
      "Epoch 488/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1336 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 0.01824\n",
      "Epoch 489/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.2119 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 0.01824\n",
      "Epoch 490/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1227 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 0.01824\n",
      "Epoch 491/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1515 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 0.01824\n",
      "Epoch 492/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1504 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00492: ReduceLROnPlateau reducing learning rate to 8.507059874318657e-08.\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 0.01824\n",
      "Epoch 493/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1472 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 0.01824\n",
      "Epoch 494/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1459 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 0.01824\n",
      "Epoch 495/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1688 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 0.01824\n",
      "Epoch 496/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1741 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.01824\n",
      "Epoch 497/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1670 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 0.01824\n",
      "Epoch 498/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1524 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 0.01824\n",
      "Epoch 499/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1260 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 0.01824\n",
      "Epoch 500/1000\n",
      "227845/227845 [==============================] - 4s 19us/step - loss: 0.1786 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 0.01824\n",
      "Epoch 501/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.1531 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 0.01824\n",
      "Epoch 502/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1793 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00502: ReduceLROnPlateau reducing learning rate to 6.80564767208125e-08.\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 0.01824\n",
      "Epoch 503/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1606 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 0.01824\n",
      "Epoch 504/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1736 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 0.01824\n",
      "Epoch 505/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1341 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 0.01824\n",
      "Epoch 506/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1498 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 0.01824\n",
      "Epoch 507/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1767 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 0.01824\n",
      "Epoch 508/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1407 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 0.01824\n",
      "Epoch 509/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1186 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 0.01824\n",
      "Epoch 510/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1270 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 0.01824\n",
      "Epoch 511/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.2108 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 0.01824\n",
      "Epoch 512/1000\n",
      "227845/227845 [==============================] - 4s 19us/step - loss: 0.1639 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00512: ReduceLROnPlateau reducing learning rate to 5.4445183650386755e-08.\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 0.01824\n",
      "Epoch 513/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1623 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 0.01824\n",
      "Epoch 514/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1774 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 0.01824\n",
      "Epoch 515/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1605 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 0.01824\n",
      "Epoch 516/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1410 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 0.01824\n",
      "Epoch 517/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1701 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 0.01824\n",
      "Epoch 518/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1364 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 0.01824\n",
      "Epoch 519/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1379 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 0.01824\n",
      "Epoch 520/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1709 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 0.01824\n",
      "Epoch 521/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1555 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 0.01824\n",
      "Epoch 522/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1334 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00522: ReduceLROnPlateau reducing learning rate to 4.3556147488743596e-08.\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 0.01824\n",
      "Epoch 523/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1620 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 0.01824\n",
      "Epoch 524/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1666 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 0.01824\n",
      "Epoch 525/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1584 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 0.01824\n",
      "Epoch 526/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1195 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 0.01824\n",
      "Epoch 527/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1820 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 0.01824\n",
      "Epoch 528/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.2121 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00528: val_loss did not improve from 0.01824\n",
      "Epoch 529/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1366 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 0.01824\n",
      "Epoch 530/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1564 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 0.01824\n",
      "Epoch 531/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.2045 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 0.01824\n",
      "Epoch 532/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1788 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00532: ReduceLROnPlateau reducing learning rate to 3.484491912786325e-08.\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 0.01824\n",
      "Epoch 533/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1726 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 0.01824\n",
      "Epoch 534/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1553 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 0.01824\n",
      "Epoch 535/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1335 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 0.01824\n",
      "Epoch 536/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1636 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 0.01824\n",
      "Epoch 537/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1744 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 0.01824\n",
      "Epoch 538/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1259 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 0.01824\n",
      "Epoch 539/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.1621 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 0.01824\n",
      "Epoch 540/1000\n",
      "227845/227845 [==============================] - 4s 19us/step - loss: 0.1522 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 0.01824\n",
      "Epoch 541/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.1747 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 0.01824\n",
      "Epoch 542/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1964 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00542: ReduceLROnPlateau reducing learning rate to 2.787593587072479e-08.\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 0.01824\n",
      "Epoch 543/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1730 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 0.01824\n",
      "Epoch 544/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1756 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 0.01824\n",
      "Epoch 545/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1490 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 0.01824\n",
      "Epoch 546/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1258 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 0.01824\n",
      "Epoch 547/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1733 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 0.01824\n",
      "Epoch 548/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.1552 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 0.01824\n",
      "Epoch 549/1000\n",
      "227845/227845 [==============================] - 4s 19us/step - loss: 0.1629 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 0.01824\n",
      "Epoch 550/1000\n",
      "227845/227845 [==============================] - 4s 19us/step - loss: 0.1855 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 0.01824\n",
      "Epoch 551/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.1664 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00551: val_loss did not improve from 0.01824\n",
      "Epoch 552/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1564 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00552: ReduceLROnPlateau reducing learning rate to 2.2300748980796928e-08.\n",
      "\n",
      "Epoch 00552: val_loss did not improve from 0.01824\n",
      "Epoch 553/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1362 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00553: val_loss did not improve from 0.01824\n",
      "Epoch 554/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1660 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00554: val_loss did not improve from 0.01824\n",
      "Epoch 555/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1481 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00555: val_loss did not improve from 0.01824\n",
      "Epoch 556/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1657 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00556: val_loss did not improve from 0.01824\n",
      "Epoch 557/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1801 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00557: val_loss did not improve from 0.01824\n",
      "Epoch 558/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1597 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00558: val_loss did not improve from 0.01824\n",
      "Epoch 559/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1316 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00559: val_loss did not improve from 0.01824\n",
      "Epoch 560/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1443 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00560: val_loss did not improve from 0.01824\n",
      "Epoch 561/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1601 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00561: val_loss did not improve from 0.01824\n",
      "Epoch 562/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1626 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00562: ReduceLROnPlateau reducing learning rate to 1.784059975307173e-08.\n",
      "\n",
      "Epoch 00562: val_loss did not improve from 0.01824\n",
      "Epoch 563/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1306 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00563: val_loss did not improve from 0.01824\n",
      "Epoch 564/1000\n",
      "227845/227845 [==============================] - 4s 19us/step - loss: 0.1517 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00564: val_loss did not improve from 0.01824\n",
      "Epoch 565/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.1421 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00565: val_loss did not improve from 0.01824\n",
      "Epoch 566/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1552 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00566: val_loss did not improve from 0.01824\n",
      "Epoch 567/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1526 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00567: val_loss did not improve from 0.01824\n",
      "Epoch 568/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1534 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00568: val_loss did not improve from 0.01824\n",
      "Epoch 569/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.1552 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00569: val_loss did not improve from 0.01824\n",
      "Epoch 570/1000\n",
      "227845/227845 [==============================] - 4s 19us/step - loss: 0.1762 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00570: val_loss did not improve from 0.01824\n",
      "Epoch 571/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1519 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00571: val_loss did not improve from 0.01824\n",
      "Epoch 572/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1559 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00572: ReduceLROnPlateau reducing learning rate to 1.4272480086674477e-08.\n",
      "\n",
      "Epoch 00572: val_loss did not improve from 0.01824\n",
      "Epoch 573/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1612 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00573: val_loss did not improve from 0.01824\n",
      "Epoch 574/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1277 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00574: val_loss did not improve from 0.01824\n",
      "Epoch 575/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1650 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00575: val_loss did not improve from 0.01824\n",
      "Epoch 576/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.1508 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00576: val_loss did not improve from 0.01824\n",
      "Epoch 577/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1412 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00577: val_loss did not improve from 0.01824\n",
      "Epoch 578/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1730 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00578: val_loss did not improve from 0.01824\n",
      "Epoch 579/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1482 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00579: val_loss did not improve from 0.01824\n",
      "Epoch 580/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1606 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00580: val_loss did not improve from 0.01824\n",
      "Epoch 581/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1447 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00581: val_loss did not improve from 0.01824\n",
      "Epoch 582/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1738 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00582: ReduceLROnPlateau reducing learning rate to 1.1417984069339583e-08.\n",
      "\n",
      "Epoch 00582: val_loss did not improve from 0.01824\n",
      "Epoch 583/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1677 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00583: val_loss did not improve from 0.01824\n",
      "Epoch 584/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1493 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00584: val_loss did not improve from 0.01824\n",
      "Epoch 585/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1806 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00585: val_loss did not improve from 0.01824\n",
      "Epoch 586/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.1840 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00586: val_loss did not improve from 0.01824\n",
      "Epoch 587/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.1430 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00587: val_loss did not improve from 0.01824\n",
      "Epoch 588/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1150 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00588: val_loss did not improve from 0.01824\n",
      "Epoch 589/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1736 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00589: val_loss did not improve from 0.01824\n",
      "Epoch 590/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1795 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00590: val_loss did not improve from 0.01824\n",
      "Epoch 591/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1523 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00591: val_loss did not improve from 0.01824\n",
      "Epoch 592/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1225 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00592: ReduceLROnPlateau reducing learning rate to 9.13438711336312e-09.\n",
      "\n",
      "Epoch 00592: val_loss did not improve from 0.01824\n",
      "Epoch 593/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.2066 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00593: val_loss did not improve from 0.01824\n",
      "Epoch 594/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1555 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00594: val_loss did not improve from 0.01824\n",
      "Epoch 595/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1370 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00595: val_loss did not improve from 0.01824\n",
      "Epoch 596/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1952 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00596: val_loss did not improve from 0.01824\n",
      "Epoch 597/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1566 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00597: val_loss did not improve from 0.01824\n",
      "Epoch 598/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1572 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00598: val_loss did not improve from 0.01824\n",
      "Epoch 599/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1169 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00599: val_loss did not improve from 0.01824\n",
      "Epoch 600/1000\n",
      "227845/227845 [==============================] - 4s 19us/step - loss: 0.1443 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00600: val_loss did not improve from 0.01824\n",
      "Epoch 601/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.1759 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00601: val_loss did not improve from 0.01824\n",
      "Epoch 602/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1440 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00602: ReduceLROnPlateau reducing learning rate to 7.3075099749075896e-09.\n",
      "\n",
      "Epoch 00602: val_loss did not improve from 0.01824\n",
      "Epoch 603/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1864 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00603: val_loss did not improve from 0.01824\n",
      "Epoch 604/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1572 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00604: val_loss did not improve from 0.01824\n",
      "Epoch 605/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1588 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00605: val_loss did not improve from 0.01824\n",
      "Epoch 606/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1618 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00606: val_loss did not improve from 0.01824\n",
      "Epoch 607/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1326 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00607: val_loss did not improve from 0.01824\n",
      "Epoch 608/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1877 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00608: val_loss did not improve from 0.01824\n",
      "Epoch 609/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1204 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00609: val_loss did not improve from 0.01824\n",
      "Epoch 610/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1552 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00610: val_loss did not improve from 0.01824\n",
      "Epoch 611/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1760 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00611: val_loss did not improve from 0.01824\n",
      "Epoch 612/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1637 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00612: ReduceLROnPlateau reducing learning rate to 5.846008122034618e-09.\n",
      "\n",
      "Epoch 00612: val_loss did not improve from 0.01824\n",
      "Epoch 613/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1540 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00613: val_loss did not improve from 0.01824\n",
      "Epoch 614/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.1159 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00614: val_loss did not improve from 0.01824\n",
      "Epoch 615/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1133 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00615: val_loss did not improve from 0.01824\n",
      "Epoch 616/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1420 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00616: val_loss did not improve from 0.01824\n",
      "Epoch 617/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1649 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00617: val_loss did not improve from 0.01824\n",
      "Epoch 618/1000\n",
      "227845/227845 [==============================] - 4s 19us/step - loss: 0.1776 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00618: val_loss did not improve from 0.01824\n",
      "Epoch 619/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.1645 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00619: val_loss did not improve from 0.01824\n",
      "Epoch 620/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1467 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00620: val_loss did not improve from 0.01824\n",
      "Epoch 621/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1353 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00621: val_loss did not improve from 0.01824\n",
      "Epoch 622/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1419 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00622: ReduceLROnPlateau reducing learning rate to 4.676806497627695e-09.\n",
      "\n",
      "Epoch 00622: val_loss did not improve from 0.01824\n",
      "Epoch 623/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.2147 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00623: val_loss did not improve from 0.01824\n",
      "Epoch 624/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1444 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00624: val_loss did not improve from 0.01824\n",
      "Epoch 625/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1841 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00625: val_loss did not improve from 0.01824\n",
      "Epoch 626/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1581 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00626: val_loss did not improve from 0.01824\n",
      "Epoch 627/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1302 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00627: val_loss did not improve from 0.01824\n",
      "Epoch 628/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1860 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00628: val_loss did not improve from 0.01824\n",
      "Epoch 629/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1402 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00629: val_loss did not improve from 0.01824\n",
      "Epoch 630/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1695 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00630: val_loss did not improve from 0.01824\n",
      "Epoch 631/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1564 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00631: val_loss did not improve from 0.01824\n",
      "Epoch 632/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1401 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00632: ReduceLROnPlateau reducing learning rate to 3.7414451981021555e-09.\n",
      "\n",
      "Epoch 00632: val_loss did not improve from 0.01824\n",
      "Epoch 633/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1550 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00633: val_loss did not improve from 0.01824\n",
      "Epoch 634/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1432 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00634: val_loss did not improve from 0.01824\n",
      "Epoch 635/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1370 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00635: val_loss did not improve from 0.01824\n",
      "Epoch 636/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1431 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00636: val_loss did not improve from 0.01824\n",
      "Epoch 637/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1793 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00637: val_loss did not improve from 0.01824\n",
      "Epoch 638/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1424 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00638: val_loss did not improve from 0.01824\n",
      "Epoch 639/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1383 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00639: val_loss did not improve from 0.01824\n",
      "Epoch 640/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1164 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00640: val_loss did not improve from 0.01824\n",
      "Epoch 641/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1263 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00641: val_loss did not improve from 0.01824\n",
      "Epoch 642/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1802 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00642: ReduceLROnPlateau reducing learning rate to 2.993156300590272e-09.\n",
      "\n",
      "Epoch 00642: val_loss did not improve from 0.01824\n",
      "Epoch 643/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1380 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00643: val_loss did not improve from 0.01824\n",
      "Epoch 644/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1427 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00644: val_loss did not improve from 0.01824\n",
      "Epoch 645/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1471 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00645: val_loss did not improve from 0.01824\n",
      "Epoch 646/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1108 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00646: val_loss did not improve from 0.01824\n",
      "Epoch 647/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1431 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00647: val_loss did not improve from 0.01824\n",
      "Epoch 648/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1579 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00648: val_loss did not improve from 0.01824\n",
      "Epoch 649/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1568 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00649: val_loss did not improve from 0.01824\n",
      "Epoch 650/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1553 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00650: val_loss did not improve from 0.01824\n",
      "Epoch 651/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1508 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00651: val_loss did not improve from 0.01824\n",
      "Epoch 652/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1928 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00652: ReduceLROnPlateau reducing learning rate to 2.394525111526491e-09.\n",
      "\n",
      "Epoch 00652: val_loss did not improve from 0.01824\n",
      "Epoch 653/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1630 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00653: val_loss did not improve from 0.01824\n",
      "Epoch 654/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1653 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00654: val_loss did not improve from 0.01824\n",
      "Epoch 655/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1878 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00655: val_loss did not improve from 0.01824\n",
      "Epoch 656/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1418 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00656: val_loss did not improve from 0.01824\n",
      "Epoch 657/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1514 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00657: val_loss did not improve from 0.01824\n",
      "Epoch 658/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1463 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00658: val_loss did not improve from 0.01824\n",
      "Epoch 659/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1768 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00659: val_loss did not improve from 0.01824\n",
      "Epoch 660/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1358 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00660: val_loss did not improve from 0.01824\n",
      "Epoch 661/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1456 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00661: val_loss did not improve from 0.01824\n",
      "Epoch 662/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1549 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00662: ReduceLROnPlateau reducing learning rate to 1.915620018166919e-09.\n",
      "\n",
      "Epoch 00662: val_loss did not improve from 0.01824\n",
      "Epoch 663/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1480 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00663: val_loss did not improve from 0.01824\n",
      "Epoch 664/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1742 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00664: val_loss did not improve from 0.01824\n",
      "Epoch 665/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.2079 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00665: val_loss did not improve from 0.01824\n",
      "Epoch 666/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1604 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00666: val_loss did not improve from 0.01824\n",
      "Epoch 667/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1674 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00667: val_loss did not improve from 0.01824\n",
      "Epoch 668/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1780 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00668: val_loss did not improve from 0.01824\n",
      "Epoch 669/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1961 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00669: val_loss did not improve from 0.01824\n",
      "Epoch 670/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1737 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00670: val_loss did not improve from 0.01824\n",
      "Epoch 671/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1619 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00671: val_loss did not improve from 0.01824\n",
      "Epoch 672/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1776 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00672: ReduceLROnPlateau reducing learning rate to 1.532496085587809e-09.\n",
      "\n",
      "Epoch 00672: val_loss did not improve from 0.01824\n",
      "Epoch 673/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1662 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00673: val_loss did not improve from 0.01824\n",
      "Epoch 674/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1312 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00674: val_loss did not improve from 0.01824\n",
      "Epoch 675/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1552 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00675: val_loss did not improve from 0.01824\n",
      "Epoch 676/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1943 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00676: val_loss did not improve from 0.01824\n",
      "Epoch 677/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1601 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00677: val_loss did not improve from 0.01824\n",
      "Epoch 678/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1453 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00678: val_loss did not improve from 0.01824\n",
      "Epoch 679/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1628 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00679: val_loss did not improve from 0.01824\n",
      "Epoch 680/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1887 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00680: val_loss did not improve from 0.01824\n",
      "Epoch 681/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1430 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00681: val_loss did not improve from 0.01824\n",
      "Epoch 682/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1830 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00682: ReduceLROnPlateau reducing learning rate to 1.225996903997384e-09.\n",
      "\n",
      "Epoch 00682: val_loss did not improve from 0.01824\n",
      "Epoch 683/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1781 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00683: val_loss did not improve from 0.01824\n",
      "Epoch 684/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1878 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00684: val_loss did not improve from 0.01824\n",
      "Epoch 685/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1495 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00685: val_loss did not improve from 0.01824\n",
      "Epoch 686/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.2090 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00686: val_loss did not improve from 0.01824\n",
      "Epoch 687/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1784 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00687: val_loss did not improve from 0.01824\n",
      "Epoch 688/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1420 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00688: val_loss did not improve from 0.01824\n",
      "Epoch 689/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1643 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00689: val_loss did not improve from 0.01824\n",
      "Epoch 690/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1609 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00690: val_loss did not improve from 0.01824\n",
      "Epoch 691/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1717 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00691: val_loss did not improve from 0.01824\n",
      "Epoch 692/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1475 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00692: ReduceLROnPlateau reducing learning rate to 9.807974876707704e-10.\n",
      "\n",
      "Epoch 00692: val_loss did not improve from 0.01824\n",
      "Epoch 693/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1592 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00693: val_loss did not improve from 0.01824\n",
      "Epoch 694/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1598 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00694: val_loss did not improve from 0.01824\n",
      "Epoch 695/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1661 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00695: val_loss did not improve from 0.01824\n",
      "Epoch 696/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1760 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00696: val_loss did not improve from 0.01824\n",
      "Epoch 697/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1431 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00697: val_loss did not improve from 0.01824\n",
      "Epoch 698/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1623 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00698: val_loss did not improve from 0.01824\n",
      "Epoch 699/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1762 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00699: val_loss did not improve from 0.01824\n",
      "Epoch 700/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1376 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00700: val_loss did not improve from 0.01824\n",
      "Epoch 701/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1912 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00701: val_loss did not improve from 0.01824\n",
      "Epoch 702/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1640 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00702: ReduceLROnPlateau reducing learning rate to 7.846379546094795e-10.\n",
      "\n",
      "Epoch 00702: val_loss did not improve from 0.01824\n",
      "Epoch 703/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1944 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00703: val_loss did not improve from 0.01824\n",
      "Epoch 704/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1543 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00704: val_loss did not improve from 0.01824\n",
      "Epoch 705/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1441 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00705: val_loss did not improve from 0.01824\n",
      "Epoch 706/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1718 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00706: val_loss did not improve from 0.01824\n",
      "Epoch 707/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1605 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00707: val_loss did not improve from 0.01824\n",
      "Epoch 708/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1373 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00708: val_loss did not improve from 0.01824\n",
      "Epoch 709/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1516 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00709: val_loss did not improve from 0.01824\n",
      "Epoch 710/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1580 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00710: val_loss did not improve from 0.01824\n",
      "Epoch 711/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1905 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00711: val_loss did not improve from 0.01824\n",
      "Epoch 712/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1471 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00712: ReduceLROnPlateau reducing learning rate to 6.277103725693678e-10.\n",
      "\n",
      "Epoch 00712: val_loss did not improve from 0.01824\n",
      "Epoch 713/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1801 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00713: val_loss did not improve from 0.01824\n",
      "Epoch 714/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1394 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00714: val_loss did not improve from 0.01824\n",
      "Epoch 715/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1699 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00715: val_loss did not improve from 0.01824\n",
      "Epoch 716/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1852 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00716: val_loss did not improve from 0.01824\n",
      "Epoch 717/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1922 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00717: val_loss did not improve from 0.01824\n",
      "Epoch 718/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1715 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00718: val_loss did not improve from 0.01824\n",
      "Epoch 719/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1790 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00719: val_loss did not improve from 0.01824\n",
      "Epoch 720/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1657 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00720: val_loss did not improve from 0.01824\n",
      "Epoch 721/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1634 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00721: val_loss did not improve from 0.01824\n",
      "Epoch 722/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1525 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00722: ReduceLROnPlateau reducing learning rate to 5.021683069372784e-10.\n",
      "\n",
      "Epoch 00722: val_loss did not improve from 0.01824\n",
      "Epoch 723/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1608 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00723: val_loss did not improve from 0.01824\n",
      "Epoch 724/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1632 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00724: val_loss did not improve from 0.01824\n",
      "Epoch 725/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1380 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00725: val_loss did not improve from 0.01824\n",
      "Epoch 726/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1691 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00726: val_loss did not improve from 0.01824\n",
      "Epoch 727/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1815 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00727: val_loss did not improve from 0.01824\n",
      "Epoch 728/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1645 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00728: val_loss did not improve from 0.01824\n",
      "Epoch 729/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.2020 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00729: val_loss did not improve from 0.01824\n",
      "Epoch 730/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1473 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00730: val_loss did not improve from 0.01824\n",
      "Epoch 731/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1731 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00731: val_loss did not improve from 0.01824\n",
      "Epoch 732/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1741 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00732: ReduceLROnPlateau reducing learning rate to 4.0173464554982274e-10.\n",
      "\n",
      "Epoch 00732: val_loss did not improve from 0.01824\n",
      "Epoch 733/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1596 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00733: val_loss did not improve from 0.01824\n",
      "Epoch 734/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1535 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00734: val_loss did not improve from 0.01824\n",
      "Epoch 735/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1662 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00735: val_loss did not improve from 0.01824\n",
      "Epoch 736/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1420 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00736: val_loss did not improve from 0.01824\n",
      "Epoch 737/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1939 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00737: val_loss did not improve from 0.01824\n",
      "Epoch 738/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1658 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00738: val_loss did not improve from 0.01824\n",
      "Epoch 739/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1518 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00739: val_loss did not improve from 0.01824\n",
      "Epoch 740/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1338 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00740: val_loss did not improve from 0.01824\n",
      "Epoch 741/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1577 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00741: val_loss did not improve from 0.01824\n",
      "Epoch 742/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.2174 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00742: ReduceLROnPlateau reducing learning rate to 3.213877164398582e-10.\n",
      "\n",
      "Epoch 00742: val_loss did not improve from 0.01824\n",
      "Epoch 743/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1649 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00743: val_loss did not improve from 0.01824\n",
      "Epoch 744/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1373 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00744: val_loss did not improve from 0.01824\n",
      "Epoch 745/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1254 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00745: val_loss did not improve from 0.01824\n",
      "Epoch 746/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1618 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00746: val_loss did not improve from 0.01824\n",
      "Epoch 747/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1787 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00747: val_loss did not improve from 0.01824\n",
      "Epoch 748/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1747 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00748: val_loss did not improve from 0.01824\n",
      "Epoch 749/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1383 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00749: val_loss did not improve from 0.01824\n",
      "Epoch 750/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1612 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00750: val_loss did not improve from 0.01824\n",
      "Epoch 751/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1462 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00751: val_loss did not improve from 0.01824\n",
      "Epoch 752/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1569 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00752: ReduceLROnPlateau reducing learning rate to 2.5711017759277867e-10.\n",
      "\n",
      "Epoch 00752: val_loss did not improve from 0.01824\n",
      "Epoch 753/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1277 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00753: val_loss did not improve from 0.01824\n",
      "Epoch 754/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.2147 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00754: val_loss did not improve from 0.01824\n",
      "Epoch 755/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1403 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00755: val_loss did not improve from 0.01824\n",
      "Epoch 756/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1494 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00756: val_loss did not improve from 0.01824\n",
      "Epoch 757/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1276 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00757: val_loss did not improve from 0.01824\n",
      "Epoch 758/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.2101 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00758: val_loss did not improve from 0.01824\n",
      "Epoch 759/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1336 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00759: val_loss did not improve from 0.01824\n",
      "Epoch 760/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1494 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00760: val_loss did not improve from 0.01824\n",
      "Epoch 761/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.2019 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00761: val_loss did not improve from 0.01824\n",
      "Epoch 762/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1808 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00762: ReduceLROnPlateau reducing learning rate to 2.0568813319243873e-10.\n",
      "\n",
      "Epoch 00762: val_loss did not improve from 0.01824\n",
      "Epoch 763/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1483 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00763: val_loss did not improve from 0.01824\n",
      "Epoch 764/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1458 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00764: val_loss did not improve from 0.01824\n",
      "Epoch 765/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1604 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00765: val_loss did not improve from 0.01824\n",
      "Epoch 766/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1655 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00766: val_loss did not improve from 0.01824\n",
      "Epoch 767/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1318 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00767: val_loss did not improve from 0.01824\n",
      "Epoch 768/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1531 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00768: val_loss did not improve from 0.01824\n",
      "Epoch 769/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1342 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00769: val_loss did not improve from 0.01824\n",
      "Epoch 770/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1671 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00770: val_loss did not improve from 0.01824\n",
      "Epoch 771/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1616 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00771: val_loss did not improve from 0.01824\n",
      "Epoch 772/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1456 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00772: ReduceLROnPlateau reducing learning rate to 1.64550506553951e-10.\n",
      "\n",
      "Epoch 00772: val_loss did not improve from 0.01824\n",
      "Epoch 773/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1816 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00773: val_loss did not improve from 0.01824\n",
      "Epoch 774/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1638 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00774: val_loss did not improve from 0.01824\n",
      "Epoch 775/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1775 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00775: val_loss did not improve from 0.01824\n",
      "Epoch 776/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1375 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00776: val_loss did not improve from 0.01824\n",
      "Epoch 777/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1704 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00777: val_loss did not improve from 0.01824\n",
      "Epoch 778/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1882 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00778: val_loss did not improve from 0.01824\n",
      "Epoch 779/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1413 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00779: val_loss did not improve from 0.01824\n",
      "Epoch 780/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1639 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00780: val_loss did not improve from 0.01824\n",
      "Epoch 781/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1586 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00781: val_loss did not improve from 0.01824\n",
      "Epoch 782/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1381 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00782: ReduceLROnPlateau reducing learning rate to 1.316404096840529e-10.\n",
      "\n",
      "Epoch 00782: val_loss did not improve from 0.01824\n",
      "Epoch 783/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1330 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00783: val_loss did not improve from 0.01824\n",
      "Epoch 784/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1534 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00784: val_loss did not improve from 0.01824\n",
      "Epoch 785/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1668 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00785: val_loss did not improve from 0.01824\n",
      "Epoch 786/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1723 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00786: val_loss did not improve from 0.01824\n",
      "Epoch 787/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1495 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00787: val_loss did not improve from 0.01824\n",
      "Epoch 788/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1563 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00788: val_loss did not improve from 0.01824\n",
      "Epoch 789/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1719 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00789: val_loss did not improve from 0.01824\n",
      "Epoch 790/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1674 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00790: val_loss did not improve from 0.01824\n",
      "Epoch 791/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1524 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00791: val_loss did not improve from 0.01824\n",
      "Epoch 792/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1960 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00792: ReduceLROnPlateau reducing learning rate to 1.0531232552679627e-10.\n",
      "\n",
      "Epoch 00792: val_loss did not improve from 0.01824\n",
      "Epoch 793/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1841 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00793: val_loss did not improve from 0.01824\n",
      "Epoch 794/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1460 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00794: val_loss did not improve from 0.01824\n",
      "Epoch 795/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1510 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00795: val_loss did not improve from 0.01824\n",
      "Epoch 796/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1771 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00796: val_loss did not improve from 0.01824\n",
      "Epoch 797/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1688 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00797: val_loss did not improve from 0.01824\n",
      "Epoch 798/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1743 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00798: val_loss did not improve from 0.01824\n",
      "Epoch 799/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1375 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00799: val_loss did not improve from 0.01824\n",
      "Epoch 800/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1436 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00800: val_loss did not improve from 0.01824\n",
      "Epoch 801/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1746 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00801: val_loss did not improve from 0.01824\n",
      "Epoch 802/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1499 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00802: ReduceLROnPlateau reducing learning rate to 8.424986264188306e-11.\n",
      "\n",
      "Epoch 00802: val_loss did not improve from 0.01824\n",
      "Epoch 803/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1287 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00803: val_loss did not improve from 0.01824\n",
      "Epoch 804/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1560 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00804: val_loss did not improve from 0.01824\n",
      "Epoch 805/1000\n",
      "227845/227845 [==============================] - 5s 22us/step - loss: 0.1469 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00805: val_loss did not improve from 0.01824\n",
      "Epoch 806/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1122 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00806: val_loss did not improve from 0.01824\n",
      "Epoch 807/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1321 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00807: val_loss did not improve from 0.01824\n",
      "Epoch 808/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1666 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00808: val_loss did not improve from 0.01824\n",
      "Epoch 809/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1633 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00809: val_loss did not improve from 0.01824\n",
      "Epoch 810/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1689 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00810: val_loss did not improve from 0.01824\n",
      "Epoch 811/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1268 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00811: val_loss did not improve from 0.01824\n",
      "Epoch 812/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1604 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00812: ReduceLROnPlateau reducing learning rate to 6.739989122372947e-11.\n",
      "\n",
      "Epoch 00812: val_loss did not improve from 0.01824\n",
      "Epoch 813/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1812 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00813: val_loss did not improve from 0.01824\n",
      "Epoch 814/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1710 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00814: val_loss did not improve from 0.01824\n",
      "Epoch 815/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1563 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00815: val_loss did not improve from 0.01824\n",
      "Epoch 816/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1968 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00816: val_loss did not improve from 0.01824\n",
      "Epoch 817/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1865 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00817: val_loss did not improve from 0.01824\n",
      "Epoch 818/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1542 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00818: val_loss did not improve from 0.01824\n",
      "Epoch 819/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1591 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00819: val_loss did not improve from 0.01824\n",
      "Epoch 820/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1350 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00820: val_loss did not improve from 0.01824\n",
      "Epoch 821/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1382 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00821: val_loss did not improve from 0.01824\n",
      "Epoch 822/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1566 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00822: ReduceLROnPlateau reducing learning rate to 5.391991297898358e-11.\n",
      "\n",
      "Epoch 00822: val_loss did not improve from 0.01824\n",
      "Epoch 823/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1165 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00823: val_loss did not improve from 0.01824\n",
      "Epoch 824/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1548 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00824: val_loss did not improve from 0.01824\n",
      "Epoch 825/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1533 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00825: val_loss did not improve from 0.01824\n",
      "Epoch 826/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1403 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00826: val_loss did not improve from 0.01824\n",
      "Epoch 827/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1346 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00827: val_loss did not improve from 0.01824\n",
      "Epoch 828/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1794 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00828: val_loss did not improve from 0.01824\n",
      "Epoch 829/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1811 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00829: val_loss did not improve from 0.01824\n",
      "Epoch 830/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1700 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00830: val_loss did not improve from 0.01824\n",
      "Epoch 831/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1839 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00831: val_loss did not improve from 0.01824\n",
      "Epoch 832/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1403 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00832: ReduceLROnPlateau reducing learning rate to 4.313593093829838e-11.\n",
      "\n",
      "Epoch 00832: val_loss did not improve from 0.01824\n",
      "Epoch 833/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1721 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00833: val_loss did not improve from 0.01824\n",
      "Epoch 834/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1608 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00834: val_loss did not improve from 0.01824\n",
      "Epoch 835/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.1731 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00835: val_loss did not improve from 0.01824\n",
      "Epoch 836/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1806 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00836: val_loss did not improve from 0.01824\n",
      "Epoch 837/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1660 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00837: val_loss did not improve from 0.01824\n",
      "Epoch 838/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1660 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00838: val_loss did not improve from 0.01824\n",
      "Epoch 839/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1336 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00839: val_loss did not improve from 0.01824\n",
      "Epoch 840/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1553 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00840: val_loss did not improve from 0.01824\n",
      "Epoch 841/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1613 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00841: val_loss did not improve from 0.01824\n",
      "Epoch 842/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1502 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00842: ReduceLROnPlateau reducing learning rate to 3.4508745860861725e-11.\n",
      "\n",
      "Epoch 00842: val_loss did not improve from 0.01824\n",
      "Epoch 843/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1720 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00843: val_loss did not improve from 0.01824\n",
      "Epoch 844/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1350 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00844: val_loss did not improve from 0.01824\n",
      "Epoch 845/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1506 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00845: val_loss did not improve from 0.01824\n",
      "Epoch 846/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1544 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00846: val_loss did not improve from 0.01824\n",
      "Epoch 847/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.2110 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00847: val_loss did not improve from 0.01824\n",
      "Epoch 848/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1742 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00848: val_loss did not improve from 0.01824\n",
      "Epoch 849/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1563 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00849: val_loss did not improve from 0.01824\n",
      "Epoch 850/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1386 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00850: val_loss did not improve from 0.01824\n",
      "Epoch 851/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1408 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00851: val_loss did not improve from 0.01824\n",
      "Epoch 852/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1589 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00852: ReduceLROnPlateau reducing learning rate to 2.760699724380089e-11.\n",
      "\n",
      "Epoch 00852: val_loss did not improve from 0.01824\n",
      "Epoch 853/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1697 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00853: val_loss did not improve from 0.01824\n",
      "Epoch 854/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1753 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00854: val_loss did not improve from 0.01824\n",
      "Epoch 855/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1642 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00855: val_loss did not improve from 0.01824\n",
      "Epoch 856/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1620 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00856: val_loss did not improve from 0.01824\n",
      "Epoch 857/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1603 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00857: val_loss did not improve from 0.01824\n",
      "Epoch 858/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1617 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00858: val_loss did not improve from 0.01824\n",
      "Epoch 859/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1266 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00859: val_loss did not improve from 0.01824\n",
      "Epoch 860/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1651 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00860: val_loss did not improve from 0.01824\n",
      "Epoch 861/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1374 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00861: val_loss did not improve from 0.01824\n",
      "Epoch 862/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1824 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00862: ReduceLROnPlateau reducing learning rate to 2.20855972399292e-11.\n",
      "\n",
      "Epoch 00862: val_loss did not improve from 0.01824\n",
      "Epoch 863/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1690 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00863: val_loss did not improve from 0.01824\n",
      "Epoch 864/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1818 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00864: val_loss did not improve from 0.01824\n",
      "Epoch 865/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1614 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00865: val_loss did not improve from 0.01824\n",
      "Epoch 866/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1605 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00866: val_loss did not improve from 0.01824\n",
      "Epoch 867/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1396 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00867: val_loss did not improve from 0.01824\n",
      "Epoch 868/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1739 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00868: val_loss did not improve from 0.01824\n",
      "Epoch 869/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1595 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00869: val_loss did not improve from 0.01824\n",
      "Epoch 870/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1515 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00870: val_loss did not improve from 0.01824\n",
      "Epoch 871/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1425 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00871: val_loss did not improve from 0.01824\n",
      "Epoch 872/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1684 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00872: ReduceLROnPlateau reducing learning rate to 1.766847779194336e-11.\n",
      "\n",
      "Epoch 00872: val_loss did not improve from 0.01824\n",
      "Epoch 873/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1719 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00873: val_loss did not improve from 0.01824\n",
      "Epoch 874/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.1598 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00874: val_loss did not improve from 0.01824\n",
      "Epoch 875/1000\n",
      "227845/227845 [==============================] - 4s 19us/step - loss: 0.1485 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00875: val_loss did not improve from 0.01824\n",
      "Epoch 876/1000\n",
      "227845/227845 [==============================] - 4s 19us/step - loss: 0.1693 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00876: val_loss did not improve from 0.01824\n",
      "Epoch 877/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1764 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00877: val_loss did not improve from 0.01824\n",
      "Epoch 878/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1270 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00878: val_loss did not improve from 0.01824\n",
      "Epoch 879/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1509 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00879: val_loss did not improve from 0.01824\n",
      "Epoch 880/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1368 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00880: val_loss did not improve from 0.01824\n",
      "Epoch 881/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1675 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00881: val_loss did not improve from 0.01824\n",
      "Epoch 882/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1805 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00882: ReduceLROnPlateau reducing learning rate to 1.4134782233554688e-11.\n",
      "\n",
      "Epoch 00882: val_loss did not improve from 0.01824\n",
      "Epoch 883/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1397 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00883: val_loss did not improve from 0.01824\n",
      "Epoch 884/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1303 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00884: val_loss did not improve from 0.01824\n",
      "Epoch 885/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1327 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00885: val_loss did not improve from 0.01824\n",
      "Epoch 886/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1597 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00886: val_loss did not improve from 0.01824\n",
      "Epoch 887/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.1892 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00887: val_loss did not improve from 0.01824\n",
      "Epoch 888/1000\n",
      "227845/227845 [==============================] - 4s 19us/step - loss: 0.1670 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00888: val_loss did not improve from 0.01824\n",
      "Epoch 889/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.1340 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00889: val_loss did not improve from 0.01824\n",
      "Epoch 890/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1186 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00890: val_loss did not improve from 0.01824\n",
      "Epoch 891/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.2001 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00891: val_loss did not improve from 0.01824\n",
      "Epoch 892/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1340 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00892: ReduceLROnPlateau reducing learning rate to 1.1307825509287995e-11.\n",
      "\n",
      "Epoch 00892: val_loss did not improve from 0.01824\n",
      "Epoch 893/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1557 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00893: val_loss did not improve from 0.01824\n",
      "Epoch 894/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1447 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00894: val_loss did not improve from 0.01824\n",
      "Epoch 895/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1727 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00895: val_loss did not improve from 0.01824\n",
      "Epoch 896/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1714 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00896: val_loss did not improve from 0.01824\n",
      "Epoch 897/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1755 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00897: val_loss did not improve from 0.01824\n",
      "Epoch 898/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.1565 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00898: val_loss did not improve from 0.01824\n",
      "Epoch 899/1000\n",
      "227845/227845 [==============================] - 4s 19us/step - loss: 0.1599 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00899: val_loss did not improve from 0.01824\n",
      "Epoch 900/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1417 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00900: val_loss did not improve from 0.01824\n",
      "Epoch 901/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1469 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00901: val_loss did not improve from 0.01824\n",
      "Epoch 902/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1473 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00902: ReduceLROnPlateau reducing learning rate to 9.046260268652517e-12.\n",
      "\n",
      "Epoch 00902: val_loss did not improve from 0.01824\n",
      "Epoch 903/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1591 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00903: val_loss did not improve from 0.01824\n",
      "Epoch 904/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1716 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00904: val_loss did not improve from 0.01824\n",
      "Epoch 905/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1553 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00905: val_loss did not improve from 0.01824\n",
      "Epoch 906/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1485 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00906: val_loss did not improve from 0.01824\n",
      "Epoch 907/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1655 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00907: val_loss did not improve from 0.01824\n",
      "Epoch 908/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1481 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00908: val_loss did not improve from 0.01824\n",
      "Epoch 909/1000\n",
      "227845/227845 [==============================] - 4s 19us/step - loss: 0.1876 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00909: val_loss did not improve from 0.01824\n",
      "Epoch 910/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1561 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00910: val_loss did not improve from 0.01824\n",
      "Epoch 911/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1390 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00911: val_loss did not improve from 0.01824\n",
      "Epoch 912/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1542 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00912: ReduceLROnPlateau reducing learning rate to 7.237008214922014e-12.\n",
      "\n",
      "Epoch 00912: val_loss did not improve from 0.01824\n",
      "Epoch 913/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1496 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00913: val_loss did not improve from 0.01824\n",
      "Epoch 914/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1983 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00914: val_loss did not improve from 0.01824\n",
      "Epoch 915/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1944 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00915: val_loss did not improve from 0.01824\n",
      "Epoch 916/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1447 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00916: val_loss did not improve from 0.01824\n",
      "Epoch 917/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1555 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00917: val_loss did not improve from 0.01824\n",
      "Epoch 918/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.1709 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00918: val_loss did not improve from 0.01824\n",
      "Epoch 919/1000\n",
      "227845/227845 [==============================] - 4s 19us/step - loss: 0.1435 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00919: val_loss did not improve from 0.01824\n",
      "Epoch 920/1000\n",
      "227845/227845 [==============================] - 4s 19us/step - loss: 0.1323 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00920: val_loss did not improve from 0.01824\n",
      "Epoch 921/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.1372 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00921: val_loss did not improve from 0.01824\n",
      "Epoch 922/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1439 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00922: ReduceLROnPlateau reducing learning rate to 5.78960664132655e-12.\n",
      "\n",
      "Epoch 00922: val_loss did not improve from 0.01824\n",
      "Epoch 923/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1638 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00923: val_loss did not improve from 0.01824\n",
      "Epoch 924/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1313 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00924: val_loss did not improve from 0.01824\n",
      "Epoch 925/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.1476 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00925: val_loss did not improve from 0.01824\n",
      "Epoch 926/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1309 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00926: val_loss did not improve from 0.01824\n",
      "Epoch 927/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1691 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00927: val_loss did not improve from 0.01824\n",
      "Epoch 928/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1515 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00928: val_loss did not improve from 0.01824\n",
      "Epoch 929/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1742 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00929: val_loss did not improve from 0.01824\n",
      "Epoch 930/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1702 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00930: val_loss did not improve from 0.01824\n",
      "Epoch 931/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1742 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00931: val_loss did not improve from 0.01824\n",
      "Epoch 932/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1796 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00932: ReduceLROnPlateau reducing learning rate to 4.6316853130612406e-12.\n",
      "\n",
      "Epoch 00932: val_loss did not improve from 0.01824\n",
      "Epoch 933/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1939 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00933: val_loss did not improve from 0.01824\n",
      "Epoch 934/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1619 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00934: val_loss did not improve from 0.01824\n",
      "Epoch 935/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1747 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00935: val_loss did not improve from 0.01824\n",
      "Epoch 936/1000\n",
      "227845/227845 [==============================] - 5s 21us/step - loss: 0.1405 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00936: val_loss did not improve from 0.01824\n",
      "Epoch 937/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1747 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00937: val_loss did not improve from 0.01824\n",
      "Epoch 938/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.1916 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00938: val_loss did not improve from 0.01824\n",
      "Epoch 939/1000\n",
      "227845/227845 [==============================] - 4s 19us/step - loss: 0.1571 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00939: val_loss did not improve from 0.01824\n",
      "Epoch 940/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.1930 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00940: val_loss did not improve from 0.01824\n",
      "Epoch 941/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.1307 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00941: val_loss did not improve from 0.01824\n",
      "Epoch 942/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1739 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00942: ReduceLROnPlateau reducing learning rate to 3.7053481810600535e-12.\n",
      "\n",
      "Epoch 00942: val_loss did not improve from 0.01824\n",
      "Epoch 943/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1328 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00943: val_loss did not improve from 0.01824\n",
      "Epoch 944/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1604 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00944: val_loss did not improve from 0.01824\n",
      "Epoch 945/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1523 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00945: val_loss did not improve from 0.01824\n",
      "Epoch 946/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1785 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00946: val_loss did not improve from 0.01824\n",
      "Epoch 947/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1694 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00947: val_loss did not improve from 0.01824\n",
      "Epoch 948/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1628 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00948: val_loss did not improve from 0.01824\n",
      "Epoch 949/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1478 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00949: val_loss did not improve from 0.01824\n",
      "Epoch 950/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1402 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00950: val_loss did not improve from 0.01824\n",
      "Epoch 951/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1534 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00951: val_loss did not improve from 0.01824\n",
      "Epoch 952/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1444 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00952: ReduceLROnPlateau reducing learning rate to 2.9642784754591037e-12.\n",
      "\n",
      "Epoch 00952: val_loss did not improve from 0.01824\n",
      "Epoch 953/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1940 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00953: val_loss did not improve from 0.01824\n",
      "Epoch 954/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1534 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00954: val_loss did not improve from 0.01824\n",
      "Epoch 955/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1678 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00955: val_loss did not improve from 0.01824\n",
      "Epoch 956/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1819 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00956: val_loss did not improve from 0.01824\n",
      "Epoch 957/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1630 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00957: val_loss did not improve from 0.01824\n",
      "Epoch 958/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1298 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00958: val_loss did not improve from 0.01824\n",
      "Epoch 959/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1844 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00959: val_loss did not improve from 0.01824\n",
      "Epoch 960/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1289 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00960: val_loss did not improve from 0.01824\n",
      "Epoch 961/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1546 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00961: val_loss did not improve from 0.01824\n",
      "Epoch 962/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1856 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00962: ReduceLROnPlateau reducing learning rate to 2.371422849756222e-12.\n",
      "\n",
      "Epoch 00962: val_loss did not improve from 0.01824\n",
      "Epoch 963/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1406 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00963: val_loss did not improve from 0.01824\n",
      "Epoch 964/1000\n",
      "227845/227845 [==============================] - 4s 19us/step - loss: 0.1482 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00964: val_loss did not improve from 0.01824\n",
      "Epoch 965/1000\n",
      "227845/227845 [==============================] - 4s 19us/step - loss: 0.1362 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00965: val_loss did not improve from 0.01824\n",
      "Epoch 966/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1476 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00966: val_loss did not improve from 0.01824\n",
      "Epoch 967/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.1493 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00967: val_loss did not improve from 0.01824\n",
      "Epoch 968/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1730 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00968: val_loss did not improve from 0.01824\n",
      "Epoch 969/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1256 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00969: val_loss did not improve from 0.01824\n",
      "Epoch 970/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1441 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00970: val_loss did not improve from 0.01824\n",
      "Epoch 971/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1227 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00971: val_loss did not improve from 0.01824\n",
      "Epoch 972/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1417 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00972: ReduceLROnPlateau reducing learning rate to 1.8971383491939165e-12.\n",
      "\n",
      "Epoch 00972: val_loss did not improve from 0.01824\n",
      "Epoch 973/1000\n",
      "227845/227845 [==============================] - 4s 19us/step - loss: 0.1649 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00973: val_loss did not improve from 0.01824\n",
      "Epoch 974/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.1439 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00974: val_loss did not improve from 0.01824\n",
      "Epoch 975/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1732 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00975: val_loss did not improve from 0.01824\n",
      "Epoch 976/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1497 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00976: val_loss did not improve from 0.01824\n",
      "Epoch 977/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.2177 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00977: val_loss did not improve from 0.01824\n",
      "Epoch 978/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1569 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00978: val_loss did not improve from 0.01824\n",
      "Epoch 979/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1422 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00979: val_loss did not improve from 0.01824\n",
      "Epoch 980/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1744 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00980: val_loss did not improve from 0.01824\n",
      "Epoch 981/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.1817 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00981: val_loss did not improve from 0.01824\n",
      "Epoch 982/1000\n",
      "227845/227845 [==============================] - 4s 19us/step - loss: 0.1381 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00982: ReduceLROnPlateau reducing learning rate to 1.5177106099661943e-12.\n",
      "\n",
      "Epoch 00982: val_loss did not improve from 0.01824\n",
      "Epoch 983/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.1656 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00983: val_loss did not improve from 0.01824\n",
      "Epoch 984/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1384 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00984: val_loss did not improve from 0.01824\n",
      "Epoch 985/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1465 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00985: val_loss did not improve from 0.01824\n",
      "Epoch 986/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1592 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00986: val_loss did not improve from 0.01824\n",
      "Epoch 987/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1978 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00987: val_loss did not improve from 0.01824\n",
      "Epoch 988/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1557 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00988: val_loss did not improve from 0.01824\n",
      "Epoch 989/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1942 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00989: val_loss did not improve from 0.01824\n",
      "Epoch 990/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1526 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00990: val_loss did not improve from 0.01824\n",
      "Epoch 991/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1406 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00991: val_loss did not improve from 0.01824\n",
      "Epoch 992/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1427 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00992: ReduceLROnPlateau reducing learning rate to 1.2141685226674248e-12.\n",
      "\n",
      "Epoch 00992: val_loss did not improve from 0.01824\n",
      "Epoch 993/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1658 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00993: val_loss did not improve from 0.01824\n",
      "Epoch 994/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1227 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00994: val_loss did not improve from 0.01824\n",
      "Epoch 995/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1557 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00995: val_loss did not improve from 0.01824\n",
      "Epoch 996/1000\n",
      "227845/227845 [==============================] - 4s 19us/step - loss: 0.1917 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00996: val_loss did not improve from 0.01824\n",
      "Epoch 997/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.1195 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00997: val_loss did not improve from 0.01824\n",
      "Epoch 998/1000\n",
      "227845/227845 [==============================] - 4s 20us/step - loss: 0.2011 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00998: val_loss did not improve from 0.01824\n",
      "Epoch 999/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1850 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00999: val_loss did not improve from 0.01824\n",
      "Epoch 1000/1000\n",
      "227845/227845 [==============================] - 5s 20us/step - loss: 0.1603 - val_loss: 0.0210\n",
      "\n",
      "Epoch 01000: val_loss did not improve from 0.01824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x182f3a048>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(train_results.values, \n",
    "       y_train_keras, \n",
    "       epochs=1000, \n",
    "       class_weight=class_weights,\n",
    "       batch_size=512,\n",
    "       validation_data=(val_results.values,y_val_keras),\n",
    "       callbacks=[scheduler,checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_results['recon_score']=val_results.recon_score/(val_results.recon_score.max()-val_results.recon_score.min())\n",
    "train_results['recon_score']=train_results.recon_score/(train_results.recon_score.max()-train_results.recon_score.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get predictions from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nn = models.Sequential()\n",
    "results_nn.add(layers.Dense(128, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "results_nn.add(layers.Dense(64,activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "results_nn.add(layers.Dense(32,activation='relu'))\n",
    "results_nn.add(layers.Dense(16,activation='relu'))\n",
    "results_nn.add(layers.Dense(8,activation='relu'))\n",
    "results_nn.add(layers.Dense(4,activation='relu'))\n",
    "results_nn.add(layers.Dense(2,activation='sigmoid'))\n",
    "results_nn.load_weights('checkpoint.best.hdf5')\n",
    "results_nn.compile(loss='binary_crossentropy',optimizer='adam')\n",
    "\n",
    "val_preds = results_nn.predict(X_val_keras)\n",
    "train_preds = results_nn.predict(X_train_keras)\n",
    "\n",
    "train_results['mlp'] = train_preds[:,1]\n",
    "val_results['mlp'] = val_preds[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run all results through FLIC to obtain final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1e9e4cb00>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x540 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "recalls = []\n",
    "auc_rocs = []\n",
    "log_losses =[]\n",
    "for col in val_results.columns:\n",
    "    recalls.append(recall_score(y_val,val_results[col].round()))\n",
    "    auc_rocs.append(roc_auc_score(y_val,val_results[col].round()))\n",
    "    log_losses.append(log_loss(y_val,val_results[col]))\n",
    "    \n",
    "estimators = list(val_results.columns)\n",
    "width = 0.25\n",
    "\n",
    "plt.figure(figsize=(10,7.5))\n",
    "r1 = np.arange(len(recalls))\n",
    "r2 = [i + width for i in r1]\n",
    "r3 = [i + width for i in r2]\n",
    "\n",
    "plt.bar(r1, recalls, color='red', width=width, edgecolor='white', label='Recall Score')\n",
    "plt.bar(r2, auc_rocs, color='blue', width=width, edgecolor='white', label='AUC ROC')\n",
    "plt.bar(r3, log_losses, color='yellow', width=width, edgecolor='white', label='Log Loss')\n",
    "\n",
    "plt.xlabel('Estimate', fontweight='bold')\n",
    "plt.xticks([i + width for i in range(len(recalls))], estimators)\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.96164865e-05, 1.00000000e-06, 1.16454294e-02, ...,\n",
       "       8.50469210e-01, 1.00000000e-06, 9.99999000e-01])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote_train_results[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Epoch 1 Recall: 1.0\n",
      "Epoch 11 Recall: 1.0\n",
      "Epoch 21 Recall: 0.75\n",
      "Epoch 31 Recall: 0.6\n",
      "Epoch 41 Recall: 0.6\n",
      "Epoch 51 Recall: 0.6\n",
      "Epoch 61 Recall: 0.6\n",
      "Epoch 71 Recall: 0.6\n",
      "Epoch 81 Recall: 0.6\n",
      "Epoch 91 Recall: 0.6\n",
      "Epoch: 2\n",
      "Epoch 1 Recall: 1.0\n",
      "Epoch 11 Recall: 1.0\n",
      "Epoch 21 Recall: 1.0\n",
      "Epoch 31 Recall: 1.0\n",
      "Epoch 41 Recall: 1.0\n",
      "Epoch 51 Recall: 1.0\n",
      "Epoch 61 Recall: 1.0\n",
      "Epoch 71 Recall: 1.0\n",
      "Epoch 81 Recall: 1.0\n",
      "Epoch 91 Recall: 1.0\n",
      "Epoch: 3\n",
      "Epoch 1 Recall: 1.0\n",
      "Epoch 11 Recall: 1.0\n",
      "Epoch 21 Recall: 1.0\n",
      "Epoch 31 Recall: 1.0\n",
      "Epoch 41 Recall: 1.0\n",
      "Epoch 51 Recall: 1.0\n",
      "Epoch 61 Recall: 1.0\n",
      "Epoch 71 Recall: 1.0\n",
      "Epoch 81 Recall: 1.0\n",
      "Epoch 91 Recall: 1.0\n",
      "Epoch: 4\n",
      "Epoch 1 Recall: 1.0\n",
      "Epoch 11 Recall: 1.0\n",
      "Epoch 21 Recall: 1.0\n",
      "Epoch 31 Recall: 1.0\n",
      "Epoch 41 Recall: 1.0\n",
      "Epoch 51 Recall: 1.0\n",
      "Epoch 61 Recall: 1.0\n",
      "Epoch 71 Recall: 1.0\n",
      "Epoch 81 Recall: 1.0\n",
      "Epoch 91 Recall: 1.0\n",
      "Epoch: 5\n",
      "Epoch 1 Recall: 1.0\n",
      "Epoch 11 Recall: 1.0\n",
      "Epoch 21 Recall: 1.0\n",
      "Epoch 31 Recall: 1.0\n",
      "Epoch 41 Recall: 1.0\n",
      "Epoch 51 Recall: 1.0\n",
      "Epoch 61 Recall: 1.0\n",
      "Epoch 71 Recall: 1.0\n",
      "Epoch 81 Recall: 1.0\n",
      "Epoch 91 Recall: 1.0\n",
      "Epoch: 6\n",
      "Epoch 1 Recall: 1.0\n",
      "Epoch 11 Recall: 1.0\n",
      "Epoch 21 Recall: 1.0\n",
      "Epoch 31 Recall: 1.0\n",
      "Epoch 41 Recall: 1.0\n",
      "Epoch 51 Recall: 1.0\n",
      "Epoch 61 Recall: 1.0\n",
      "Epoch 71 Recall: 1.0\n",
      "Epoch 81 Recall: 1.0\n",
      "Epoch 91 Recall: 1.0\n",
      "Epoch: 7\n",
      "Epoch 1 Recall: 1.0\n",
      "Epoch 11 Recall: 1.0\n",
      "Epoch 21 Recall: 1.0\n",
      "Epoch 31 Recall: 1.0\n",
      "Epoch 41 Recall: 1.0\n",
      "Epoch 51 Recall: 1.0\n",
      "Epoch 61 Recall: 1.0\n",
      "Epoch 71 Recall: 1.0\n",
      "Epoch 81 Recall: 1.0\n",
      "Epoch 91 Recall: 1.0\n",
      "Epoch: 8\n",
      "Epoch 1 Recall: 1.0\n",
      "Epoch 11 Recall: 1.0\n",
      "Epoch 21 Recall: 1.0\n",
      "Epoch 31 Recall: 1.0\n",
      "Epoch 41 Recall: 1.0\n",
      "Epoch 51 Recall: 1.0\n",
      "Epoch 61 Recall: 1.0\n",
      "Epoch 71 Recall: 1.0\n",
      "Epoch 81 Recall: 1.0\n",
      "Epoch 91 Recall: 1.0\n",
      "Epoch: 9\n",
      "Epoch 1 Recall: 1.0\n",
      "Epoch 11 Recall: 1.0\n",
      "Epoch 21 Recall: 1.0\n",
      "Epoch 31 Recall: 1.0\n",
      "Epoch 41 Recall: 1.0\n",
      "Epoch 51 Recall: 1.0\n",
      "Epoch 61 Recall: 1.0\n",
      "Epoch 71 Recall: 1.0\n",
      "Epoch 81 Recall: 1.0\n",
      "Epoch 91 Recall: 1.0\n",
      "Epoch: 10\n",
      "Epoch 1 Recall: 1.0\n",
      "Epoch 11 Recall: 1.0\n",
      "Epoch 21 Recall: 1.0\n",
      "Epoch 31 Recall: 1.0\n",
      "Epoch 41 Recall: 1.0\n",
      "Epoch 51 Recall: 1.0\n",
      "Epoch 61 Recall: 1.0\n",
      "Epoch 71 Recall: 1.0\n",
      "Epoch 81 Recall: 1.0\n",
      "Epoch 91 Recall: 1.0\n",
      "Epoch: 11\n",
      "Epoch 1 Recall: 1.0\n",
      "Epoch 11 Recall: 1.0\n",
      "Epoch 21 Recall: 1.0\n",
      "Epoch 31 Recall: 1.0\n",
      "Epoch 41 Recall: 1.0\n",
      "Epoch 51 Recall: 1.0\n",
      "Epoch 61 Recall: 1.0\n",
      "Epoch 71 Recall: 1.0\n",
      "Epoch 81 Recall: 1.0\n",
      "Epoch 91 Recall: 1.0\n",
      "Epoch: 12\n",
      "Epoch 1 Recall: 1.0\n",
      "Epoch 11 Recall: 1.0\n",
      "Epoch 21 Recall: 1.0\n",
      "Epoch 31 Recall: 1.0\n",
      "Epoch 41 Recall: 1.0\n",
      "Epoch 51 Recall: 1.0\n",
      "Epoch 61 Recall: 1.0\n",
      "Epoch 71 Recall: 1.0\n",
      "Epoch 81 Recall: 1.0\n",
      "Epoch 91 Recall: 1.0\n",
      "Epoch: 13\n",
      "Epoch 1 Recall: 1.0\n",
      "Epoch 11 Recall: 1.0\n",
      "Epoch 21 Recall: 1.0\n",
      "Epoch 31 Recall: 1.0\n",
      "Epoch 41 Recall: 1.0\n",
      "Epoch 51 Recall: 1.0\n",
      "Epoch 61 Recall: 1.0\n",
      "Epoch 71 Recall: 1.0\n",
      "Epoch 81 Recall: 1.0\n",
      "Epoch 91 Recall: 1.0\n",
      "Epoch: 14\n",
      "Epoch 1 Recall: 1.0\n",
      "Epoch 11 Recall: 1.0\n",
      "Epoch 21 Recall: 1.0\n",
      "Epoch 31 Recall: 1.0\n",
      "Epoch 41 Recall: 1.0\n",
      "Epoch 51 Recall: 1.0\n",
      "Epoch 61 Recall: 1.0\n",
      "Epoch 71 Recall: 1.0\n",
      "Epoch 81 Recall: 1.0\n",
      "Epoch 91 Recall: 1.0\n",
      "Epoch: 15\n",
      "Epoch 1 Recall: 1.0\n",
      "Epoch 11 Recall: 1.0\n",
      "Epoch 21 Recall: 1.0\n",
      "Epoch 31 Recall: 1.0\n",
      "Epoch 41 Recall: 1.0\n",
      "Epoch 51 Recall: 1.0\n",
      "Epoch 61 Recall: 1.0\n",
      "Epoch 71 Recall: 1.0\n",
      "Epoch 81 Recall: 1.0\n",
      "Epoch 91 Recall: 1.0\n",
      "Epoch: 16\n",
      "Epoch 1 Recall: 1.0\n",
      "Epoch 11 Recall: 1.0\n",
      "Epoch 21 Recall: 1.0\n",
      "Epoch 31 Recall: 1.0\n",
      "Epoch 41 Recall: 1.0\n",
      "Epoch 51 Recall: 1.0\n",
      "Epoch 61 Recall: 1.0\n",
      "Epoch 71 Recall: 1.0\n",
      "Epoch 81 Recall: 1.0\n",
      "Epoch 91 Recall: 1.0\n",
      "Epoch: 17\n",
      "Epoch 1 Recall: 1.0\n",
      "Epoch 11 Recall: 1.0\n",
      "Epoch 21 Recall: 1.0\n",
      "Epoch 31 Recall: 1.0\n",
      "Epoch 41 Recall: 1.0\n",
      "Epoch 51 Recall: 1.0\n",
      "Epoch 61 Recall: 1.0\n",
      "Epoch 71 Recall: 1.0\n",
      "Epoch 81 Recall: 1.0\n",
      "Epoch 91 Recall: 1.0\n",
      "Epoch: 18\n",
      "Epoch 1 Recall: 1.0\n",
      "Epoch 11 Recall: 1.0\n",
      "Epoch 21 Recall: 1.0\n",
      "Epoch 31 Recall: 1.0\n",
      "Epoch 41 Recall: 1.0\n",
      "Epoch 51 Recall: 1.0\n",
      "Epoch 61 Recall: 1.0\n",
      "Epoch 71 Recall: 1.0\n",
      "Epoch 81 Recall: 1.0\n",
      "Epoch 91 Recall: 1.0\n",
      "Epoch: 19\n",
      "Epoch 1 Recall: 1.0\n",
      "Epoch 11 Recall: 1.0\n",
      "Epoch 21 Recall: 1.0\n",
      "Epoch 31 Recall: 1.0\n",
      "Epoch 41 Recall: 1.0\n",
      "Epoch 51 Recall: 1.0\n",
      "Epoch 61 Recall: 1.0\n",
      "Epoch 71 Recall: 1.0\n",
      "Epoch 81 Recall: 1.0\n",
      "Epoch 91 Recall: 1.0\n",
      "Epoch: 20\n",
      "Epoch 1 Recall: 1.0\n",
      "Epoch 11 Recall: 1.0\n",
      "Epoch 21 Recall: 1.0\n",
      "Epoch 31 Recall: 1.0\n",
      "Epoch 41 Recall: 1.0\n",
      "Epoch 51 Recall: 1.0\n",
      "Epoch 61 Recall: 1.0\n",
      "Epoch 71 Recall: 1.0\n",
      "Epoch 81 Recall: 1.0\n",
      "Epoch 91 Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "FLIC = PMLE.PMLE.Firth_Logit(num_iters=100,lr=0.05,FLIC=True, metric='recall_score', readout_rate=10)\n",
    "train = np.zeros(X_train.shape[0])\n",
    "val = np.zeros(X_val.shape[0])\n",
    "for i in range(20):\n",
    "    print('Epoch:',i+1)\n",
    "    X = train_results[y_train==1].sample(frac=0.05).append(train_results[y_train==0].sample(frac=0.05))\n",
    "    y = y_train.loc[X.index]\n",
    "    FLIC.fit(X,y)\n",
    "    train = ((i)*train + FLIC.predict_proba(train_results))/(i+1)\n",
    "    val =  ((i)*val + FLIC.predict_proba(val_results))/(i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final validation set area under the ROC curve score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9884146871274243"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_val,val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
