{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/remycanario/anaconda3/lib/python3.7/site-packages/statsmodels/compat/pandas.py:23: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  data_klasses = (pandas.Series, pandas.DataFrame, pandas.Panel)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tqdm\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "import impute\n",
    "import PMLE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "import datetime\n",
    "from statsmodels.discrete.discrete_model import Logit\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import log_loss\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "import random\n",
    "from keras import regularizers\n",
    "from keras import models,layers,optimizers\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv('creditcard.csv')\n",
    "time_df = pd.DataFrame(new_df.Time)\n",
    "time_df['hour_dummy']=(time_df.Time/(60*60)).round().astype(str)\n",
    "time_df['day_dummy']=(time_df.Time/(60*60*24)).round().astype(str)\n",
    "time_df = pd.get_dummies(time_df,drop_first=True).drop('Time',axis=1)\n",
    "new_df.drop('Time',axis=1,inplace=True)\n",
    "new_df['cents'] = new_df.Amount.apply(lambda x: int(str(x).split('.')[1]))\n",
    "new_df.Amount[new_df.Amount!=0] = np.log(new_df.Amount[new_df.Amount!=0])\n",
    "X = new_df.drop('Class',axis=1)\n",
    "y = new_df.Class\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "time_train, time_val = train_test_split(time_df,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain bagged logistic regression with penalized MLE results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_PMLE_results(X_train,y_train,functions,function_labels,iterations=20):\n",
    "    train = dict.fromkeys(function_labels,np.zeros[X_train.shape[0]])\n",
    "    val = dict.fromkeys(function_labels,np.zeros[X_val.shape[0]])\n",
    "    for i in range(iterations):\n",
    "        print('Epoch ', i)\n",
    "        X = X_train[y_train==1].sample(frac=0.05).append(X_train[y_train==0].sample(frac=0.05))\n",
    "        y = y_train.loc[X.index]\n",
    "        for j in range(len(functions)):\n",
    "            functions[j].fit(X,y)\n",
    "            train[function_labels[j]] = ((i)*train[function_labels[j]] + functions[j].predict_proba(X_train))/(i+1)\n",
    "            val[function_labels[j]] =  ((i)*val[function_labels[j]] + functions[j].predict_proba(X_val))/(i+1)\n",
    "    return train, val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firth = PMLE.PMLE.Firth_Logit(num_iters=125,alpha=0.05, metric='recall', readout_rate=10)\n",
    "FLIC = PMLE.PMLE.Firth_Logit(num_iters=125,alpha=0.05,FLIC=True, metric='recall', readout_rate=10)\n",
    "t_firth = PMLE.PMLE.Firth_Logit(num_iters=125,alpha=0.05,lmbda=0.01, metric='recall', readout_rate=10)\n",
    "\n",
    "functions = [firth, FLIC, t_firth]\n",
    "function_labels = ['firth','FLIC','t_firth']\n",
    "\n",
    "train_results, val_results = get_PMLE_results(X_train,y_train,functions,function_labels)\n",
    "X_train = X_train.join(train_results)\n",
    "X_val = X_val.join(val_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder Anomaly Detection\n",
    "### With undercomplete, regularized and denoising autoencoders using pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_inds = y_train[y_train==0].reset_index().index\n",
    "\n",
    "#Standardize dfs\n",
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_val_sc = sc.fit_transform(X_val)\n",
    "n_features = X_train_sc.shape[1]\n",
    "\n",
    "#Convert non-fraud rows to pytorch tensor\n",
    "normal_train = X_train_sc[normal_inds,:]\n",
    "normal_torch = torch.from_numpy(normal_train,).type(torch.FloatTensor)\n",
    "\n",
    "#Convert train and val sets to pytorch tensor\n",
    "train_torch = torch.from_numpy(X_train_sc).type(torch.FloatTensor)\n",
    "val_torch = torch.from_numpy(X_val_sc).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self,n_features,hidden_nodes,dropout=None,VAE=False):\n",
    "        \n",
    "        '''PARAMATERS\n",
    "           n_features: number of X variables in dataset\n",
    "           hidden_nodes: number of nodes in hidden layer\n",
    "           dropout: fraction of nodes to dropout (0 < dropout <1)'''\n",
    "        \n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.n_features=n_features\n",
    "        self.n_hidden = hidden_nodes\n",
    "        self.encoder = nn.Linear(n_features,hidden_nodes)\n",
    "        self.decoder = nn.Linear(hidden_nodes,n_features)\n",
    "        self.output_layer = nn.Linear(n_features,n_features)\n",
    "        self.dropout = dropout\n",
    "        self.best_recon = None\n",
    "        \n",
    "        \n",
    "    def forward (self,x):\n",
    "        if self.dropout!=None:\n",
    "            x = F.relu(F.dropout(self.encoder(x)))\n",
    "        else:\n",
    "            x = F.relu(self.encoder(x))\n",
    "        self.hidden_layer=x\n",
    "        x = F.relu(self.decoder(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_autoencoder(model, dataset, loss_func, optimizer, epochs=100, batch_size=1024,  \n",
    "                      validation_tensor=None,y_val=None, lr_rate_scheduler = None, noise_factor=None, \n",
    "                      random_seed=None, MSE_stopping_threshold=0):\n",
    "        '''Parameters\n",
    "           model: instantiated autoencoder\n",
    "           dataset: torch tensor of X variables\n",
    "           loss_func: instantiated loss function\n",
    "           optimizer: instantiated optimizer\n",
    "           validation_tensor: torch tensor of validation X variables\n",
    "           y_val: numpy array of y values\n",
    "           epochs: number of epochs\n",
    "           batch_size: batch_size\n",
    "           noise_factor: magnitude of noise added to data\n",
    "             for a denoising autoencoder (0 < noise_factor <=1)\n",
    "           random_seed: random_seed\n",
    "           stopping_MSE_threshold: MSE value after which autoencoder stops training'''\n",
    "\n",
    "        if random_seed!=None:\n",
    "            torch.manual_seed(random_seed)\n",
    "        train_loader = torch.utils.data.DataLoader(dataset, \n",
    "                                                   batch_size=batch_size, \n",
    "                                                   shuffle=True)\n",
    "\n",
    "        if type(validation_tensor)==torch.Tensor:\n",
    "            val = True\n",
    "            val_numpy = validation_tensor.detach().numpy()\n",
    "        else:\n",
    "            val = False\n",
    "\n",
    "        readout_batch_interval = 0.25*(dataset.shape[0]/batch_size)//1\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            counter = 0\n",
    "            print('\\n\\033[1mEpoch {}\\033[0m\\n'.format(epoch+1))\n",
    "            for batch in train_loader:\n",
    "\n",
    "                if noise_factor!=None:\n",
    "                    batch = batch + noise_factor * torch.randn(*batch.shape)\n",
    "                batch = torch.autograd.Variable(batch)\n",
    "                optimizer.zero_grad()\n",
    "                recon = model(batch)\n",
    "                loss = loss_func(recon, batch)\n",
    "\n",
    "                if (counter%readout_batch_interval==0):\n",
    "                    print('Batch {} Loss: {:.4f}'.format(counter, float(loss)))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                counter+=1\n",
    "            if epoch==0:\n",
    "                epoch_loss = loss_func(model(dataset), dataset)\n",
    "                print('\\nEPOCH {} LOSS: {:.4f}'.format(epoch+1, float(epoch_loss)))\n",
    "            else:\n",
    "                old_epoch_loss = epoch_loss\n",
    "                epoch_loss = loss_func(model(dataset), dataset)\n",
    "                print('\\nEPOCH {} LOSS: {:.4f}'.format(epoch+1, float(epoch_loss)))\n",
    "                \n",
    "            if val == True:\n",
    "                val_output = model(validation_tensor).detach().numpy()\n",
    "                reconstruction_error = np.sqrt(np.power(val_output - val_numpy, 2)).sum(axis=1)\n",
    "                reconstruction_error = sc.fit_transform(reconstruction_error.reshape(-1, 1))\n",
    "                sklogit = LogisticRegression()\n",
    "                if epoch==0:\n",
    "                    sklogit.fit(reconstruction_error,y_val)\n",
    "                    preds = sklogit.predict(reconstruction_error)\n",
    "                    score = recall_score(y_val,preds)\n",
    "                    model.best_recon=model.parameters()\n",
    "                    model.best_pr = score\n",
    "                    print('\\nReconstruction error recall: {:.4f}'.format(score))\n",
    "                else:\n",
    "                    old_score = score\n",
    "                    sklogit.fit(reconstruction_error,y_val)\n",
    "                    preds = sklogit.predict(reconstruction_error)\n",
    "                    score = recall_score(y_val,preds)\n",
    "                    if score<old_score:\n",
    "                        model.best_recon=model.parameters()\n",
    "                        model.best_recall = score\n",
    "                    print('\\nReconstruction error recall {:.4f}'.format(score))\n",
    "                    print('Change: {:.4f}%'.format(float((score-old_score)/old_score)))\n",
    "            if type(scheduler)==torch.optim.lr_scheduler.ReduceLROnPlateau:\n",
    "                scheduler.step(score) \n",
    "            if epoch_loss<=MSE_stopping_threshold:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder I: Undercomplete with Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate encoder and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae1 = AutoEncoder(n_features,int(n_features*1.5//1),dropout=0.3)\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mEpoch 1\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.4900\n",
      "Batch 222 Loss: 0.8589\n",
      "Batch 444 Loss: 0.9410\n",
      "Batch 666 Loss: 0.8289\n",
      "Batch 888 Loss: 0.7099\n",
      "\n",
      "EPOCH 1 LOSS: 0.8892\n",
      "\n",
      "Reconstruction error recall: 0.1485\n",
      "\n",
      "\u001b[1mEpoch 2\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7737\n",
      "Batch 222 Loss: 0.9750\n",
      "Batch 444 Loss: 1.0887\n",
      "Batch 666 Loss: 0.7332\n",
      "Batch 888 Loss: 0.8008\n",
      "\n",
      "EPOCH 2 LOSS: 0.8883\n",
      "\n",
      "Reconstruction error recall 0.1386\n",
      "Change: -0.0667%\n",
      "\n",
      "\u001b[1mEpoch 3\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7950\n",
      "Batch 222 Loss: 0.8598\n",
      "Batch 444 Loss: 0.8896\n",
      "Batch 666 Loss: 0.8075\n",
      "Batch 888 Loss: 0.7872\n",
      "\n",
      "EPOCH 3 LOSS: 0.8880\n",
      "\n",
      "Reconstruction error recall 0.1188\n",
      "Change: -0.1429%\n",
      "\n",
      "\u001b[1mEpoch 4\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.0196\n",
      "Batch 222 Loss: 0.8915\n",
      "Batch 444 Loss: 0.7577\n",
      "Batch 666 Loss: 0.8030\n",
      "Batch 888 Loss: 0.9440\n",
      "\n",
      "EPOCH 4 LOSS: 0.8878\n",
      "\n",
      "Reconstruction error recall 0.1683\n",
      "Change: 0.4167%\n",
      "\n",
      "\u001b[1mEpoch 5\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8061\n",
      "Batch 222 Loss: 0.7351\n",
      "Batch 444 Loss: 0.8013\n",
      "Batch 666 Loss: 0.8537\n",
      "Batch 888 Loss: 0.9079\n",
      "\n",
      "EPOCH 5 LOSS: 0.8881\n",
      "\n",
      "Reconstruction error recall 0.1089\n",
      "Change: -0.3529%\n",
      "\n",
      "\u001b[1mEpoch 6\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7109\n",
      "Batch 222 Loss: 0.9564\n",
      "Batch 444 Loss: 0.7431\n",
      "Batch 666 Loss: 1.0233\n",
      "Batch 888 Loss: 0.7770\n",
      "\n",
      "EPOCH 6 LOSS: 0.8880\n",
      "\n",
      "Reconstruction error recall 0.0990\n",
      "Change: -0.0909%\n",
      "\n",
      "\u001b[1mEpoch 7\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8641\n",
      "Batch 222 Loss: 0.8107\n",
      "Batch 444 Loss: 0.7203\n",
      "Batch 666 Loss: 1.1095\n",
      "Batch 888 Loss: 0.8240\n",
      "\n",
      "EPOCH 7 LOSS: 0.8880\n",
      "\n",
      "Reconstruction error recall 0.1089\n",
      "Change: 0.1000%\n",
      "\n",
      "\u001b[1mEpoch 8\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8482\n",
      "Batch 222 Loss: 0.9127\n",
      "Batch 444 Loss: 0.7797\n",
      "Batch 666 Loss: 0.7641\n",
      "Batch 888 Loss: 0.7402\n",
      "\n",
      "EPOCH 8 LOSS: 0.8877\n",
      "\n",
      "Reconstruction error recall 0.1683\n",
      "Change: 0.5455%\n",
      "\n",
      "\u001b[1mEpoch 9\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7327\n",
      "Batch 222 Loss: 1.1228\n",
      "Batch 444 Loss: 1.5994\n",
      "Batch 666 Loss: 1.1955\n",
      "Batch 888 Loss: 0.8515\n",
      "\n",
      "EPOCH 9 LOSS: 0.8692\n",
      "\n",
      "Reconstruction error recall 0.0198\n",
      "Change: -0.8824%\n",
      "Epoch     9: reducing learning rate of group 0 to 1.8000e-02.\n",
      "\n",
      "\u001b[1mEpoch 10\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.1054\n",
      "Batch 222 Loss: 0.6417\n",
      "Batch 444 Loss: 0.7254\n",
      "Batch 666 Loss: 0.9228\n",
      "Batch 888 Loss: 1.0243\n",
      "\n",
      "EPOCH 10 LOSS: 0.8519\n",
      "\n",
      "Reconstruction error recall 0.0000\n",
      "Change: -1.0000%\n",
      "\n",
      "\u001b[1mEpoch 11\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7824\n",
      "Batch 222 Loss: 0.7646\n",
      "Batch 444 Loss: 0.8645\n",
      "Batch 666 Loss: 0.7598\n",
      "Batch 888 Loss: 0.8834\n",
      "\n",
      "EPOCH 11 LOSS: 0.8430\n",
      "\n",
      "Reconstruction error recall 0.0000\n",
      "Change: nan%\n",
      "\n",
      "\u001b[1mEpoch 12\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7729\n",
      "Batch 222 Loss: 0.8615\n",
      "Batch 444 Loss: 0.7317\n",
      "Batch 666 Loss: 0.7520\n",
      "Batch 888 Loss: 0.7076\n",
      "\n",
      "EPOCH 12 LOSS: 0.8064\n",
      "\n",
      "Reconstruction error recall 0.0000\n",
      "Change: nan%\n",
      "\n",
      "\u001b[1mEpoch 13\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.0401\n",
      "Batch 222 Loss: 0.6518\n",
      "Batch 444 Loss: 0.7215\n",
      "Batch 666 Loss: 0.8645\n",
      "Batch 888 Loss: 0.8147\n",
      "\n",
      "EPOCH 13 LOSS: 0.7893\n",
      "\n",
      "Reconstruction error recall 0.0000\n",
      "Change: nan%\n",
      "\n",
      "\u001b[1mEpoch 14\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.4138\n",
      "Batch 222 Loss: 0.7595\n",
      "Batch 444 Loss: 0.7413\n",
      "Batch 666 Loss: 0.7094\n",
      "Batch 888 Loss: 0.6820\n",
      "\n",
      "EPOCH 14 LOSS: 0.7673\n",
      "\n",
      "Reconstruction error recall 0.0000\n",
      "Change: nan%\n",
      "Epoch    14: reducing learning rate of group 0 to 1.6200e-02.\n",
      "\n",
      "\u001b[1mEpoch 15\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.0456\n",
      "Batch 222 Loss: 0.6429\n",
      "Batch 444 Loss: 0.7016\n",
      "Batch 666 Loss: 0.8255\n",
      "Batch 888 Loss: 0.6571\n",
      "\n",
      "EPOCH 15 LOSS: 0.7462\n",
      "\n",
      "Reconstruction error recall 0.0000\n",
      "Change: nan%\n",
      "\n",
      "\u001b[1mEpoch 16\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6354\n",
      "Batch 222 Loss: 1.0289\n",
      "Batch 444 Loss: 0.6525\n",
      "Batch 666 Loss: 0.8779\n",
      "Batch 888 Loss: 0.9238\n",
      "\n",
      "EPOCH 16 LOSS: 0.7234\n",
      "\n",
      "Reconstruction error recall 0.0000\n",
      "Change: nan%\n",
      "\n",
      "\u001b[1mEpoch 17\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5969\n",
      "Batch 222 Loss: 0.6679\n",
      "Batch 444 Loss: 0.6911\n",
      "Batch 666 Loss: 0.6420\n",
      "Batch 888 Loss: 0.6142\n",
      "\n",
      "EPOCH 17 LOSS: 0.6847\n",
      "\n",
      "Reconstruction error recall 0.0000\n",
      "Change: nan%\n",
      "\n",
      "\u001b[1mEpoch 18\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7309\n",
      "Batch 222 Loss: 0.8843\n",
      "Batch 444 Loss: 0.5571\n",
      "Batch 666 Loss: 0.6046\n",
      "Batch 888 Loss: 0.5735\n",
      "\n",
      "EPOCH 18 LOSS: 0.6533\n",
      "\n",
      "Reconstruction error recall 0.0000\n",
      "Change: nan%\n",
      "\n",
      "\u001b[1mEpoch 19\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6006\n",
      "Batch 222 Loss: 0.8561\n",
      "Batch 444 Loss: 0.8285\n",
      "Batch 666 Loss: 0.6134\n",
      "Batch 888 Loss: 0.5420\n",
      "\n",
      "EPOCH 19 LOSS: 0.6251\n",
      "\n",
      "Reconstruction error recall 0.0000\n",
      "Change: nan%\n",
      "Epoch    19: reducing learning rate of group 0 to 1.4580e-02.\n",
      "\n",
      "\u001b[1mEpoch 20\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7341\n",
      "Batch 222 Loss: 0.6244\n",
      "Batch 444 Loss: 0.6324\n",
      "Batch 666 Loss: 0.5544\n",
      "Batch 888 Loss: 0.5573\n",
      "\n",
      "EPOCH 20 LOSS: 0.5880\n",
      "\n",
      "Reconstruction error recall 0.0099\n",
      "Change: inf%\n",
      "\n",
      "\u001b[1mEpoch 21\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5228\n",
      "Batch 222 Loss: 0.5431\n",
      "Batch 444 Loss: 0.5939\n",
      "Batch 666 Loss: 0.4709\n",
      "Batch 888 Loss: 0.5070\n",
      "\n",
      "EPOCH 21 LOSS: 0.5555\n",
      "\n",
      "Reconstruction error recall 0.0099\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 22\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4947\n",
      "Batch 222 Loss: 0.5128\n",
      "Batch 444 Loss: 0.5444\n",
      "Batch 666 Loss: 0.5085\n",
      "Batch 888 Loss: 0.5502\n",
      "\n",
      "EPOCH 22 LOSS: 0.5387\n",
      "\n",
      "Reconstruction error recall 0.0198\n",
      "Change: 1.0000%\n",
      "\n",
      "\u001b[1mEpoch 23\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6494\n",
      "Batch 222 Loss: 0.4562\n",
      "Batch 444 Loss: 0.6784\n",
      "Batch 666 Loss: 0.4432\n",
      "Batch 888 Loss: 0.4293\n",
      "\n",
      "EPOCH 23 LOSS: 0.5062\n",
      "\n",
      "Reconstruction error recall 0.0297\n",
      "Change: 0.5000%\n",
      "\n",
      "\u001b[1mEpoch 24\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4559\n",
      "Batch 222 Loss: 0.4427\n",
      "Batch 444 Loss: 0.4486\n",
      "Batch 666 Loss: 0.4609\n",
      "Batch 888 Loss: 0.6085\n",
      "\n",
      "EPOCH 24 LOSS: 0.4890\n",
      "\n",
      "Reconstruction error recall 0.0099\n",
      "Change: -0.6667%\n",
      "Epoch    24: reducing learning rate of group 0 to 1.3122e-02.\n",
      "\n",
      "\u001b[1mEpoch 25\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4374\n",
      "Batch 222 Loss: 0.5903\n",
      "Batch 444 Loss: 0.5608\n",
      "Batch 666 Loss: 0.4278\n",
      "Batch 888 Loss: 0.4095\n",
      "\n",
      "EPOCH 25 LOSS: 0.4787\n",
      "\n",
      "Reconstruction error recall 0.0594\n",
      "Change: 5.0000%\n",
      "\n",
      "\u001b[1mEpoch 26\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4299\n",
      "Batch 222 Loss: 0.4476\n",
      "Batch 444 Loss: 0.4292\n",
      "Batch 666 Loss: 0.5209\n",
      "Batch 888 Loss: 0.4679\n",
      "\n",
      "EPOCH 26 LOSS: 0.4672\n",
      "\n",
      "Reconstruction error recall 0.0198\n",
      "Change: -0.6667%\n",
      "\n",
      "\u001b[1mEpoch 27\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4457\n",
      "Batch 222 Loss: 0.3932\n",
      "Batch 444 Loss: 0.4261\n",
      "Batch 666 Loss: 0.5470\n",
      "Batch 888 Loss: 0.3701\n",
      "\n",
      "EPOCH 27 LOSS: 0.4495\n",
      "\n",
      "Reconstruction error recall 0.0396\n",
      "Change: 1.0000%\n",
      "\n",
      "\u001b[1mEpoch 28\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4227\n",
      "Batch 222 Loss: 0.3861\n",
      "Batch 444 Loss: 0.4116\n",
      "Batch 666 Loss: 0.7607\n",
      "Batch 888 Loss: 0.4292\n",
      "\n",
      "EPOCH 28 LOSS: 0.4364\n",
      "\n",
      "Reconstruction error recall 0.0495\n",
      "Change: 0.2500%\n",
      "\n",
      "\u001b[1mEpoch 29\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4180\n",
      "Batch 222 Loss: 0.6260\n",
      "Batch 444 Loss: 0.3929\n",
      "Batch 666 Loss: 0.3994\n",
      "Batch 888 Loss: 0.4341\n",
      "\n",
      "EPOCH 29 LOSS: 0.4258\n",
      "\n",
      "Reconstruction error recall 0.0297\n",
      "Change: -0.4000%\n",
      "Epoch    29: reducing learning rate of group 0 to 1.1810e-02.\n",
      "\n",
      "\u001b[1mEpoch 30\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3974\n",
      "Batch 222 Loss: 0.4446\n",
      "Batch 444 Loss: 0.3875\n",
      "Batch 666 Loss: 0.3759\n",
      "Batch 888 Loss: 0.4657\n",
      "\n",
      "EPOCH 30 LOSS: 0.4172\n",
      "\n",
      "Reconstruction error recall 0.0198\n",
      "Change: -0.3333%\n",
      "\n",
      "\u001b[1mEpoch 31\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3935\n",
      "Batch 222 Loss: 0.3739\n",
      "Batch 444 Loss: 0.4053\n",
      "Batch 666 Loss: 0.4180\n",
      "Batch 888 Loss: 0.3521\n",
      "\n",
      "EPOCH 31 LOSS: 0.4090\n",
      "\n",
      "Reconstruction error recall 0.0891\n",
      "Change: 3.5000%\n",
      "\n",
      "\u001b[1mEpoch 32\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3855\n",
      "Batch 222 Loss: 0.3775\n",
      "Batch 444 Loss: 0.4444\n",
      "Batch 666 Loss: 0.3867\n",
      "Batch 888 Loss: 0.3260\n",
      "\n",
      "EPOCH 32 LOSS: 0.3994\n",
      "\n",
      "Reconstruction error recall 0.0495\n",
      "Change: -0.4444%\n",
      "\n",
      "\u001b[1mEpoch 33\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3552\n",
      "Batch 222 Loss: 0.3390\n",
      "Batch 444 Loss: 0.3473\n",
      "Batch 666 Loss: 0.3373\n",
      "Batch 888 Loss: 0.3434\n",
      "\n",
      "EPOCH 33 LOSS: 0.3884\n",
      "\n",
      "Reconstruction error recall 0.0891\n",
      "Change: 0.8000%\n",
      "\n",
      "\u001b[1mEpoch 34\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3334\n",
      "Batch 222 Loss: 0.3498\n",
      "Batch 444 Loss: 0.3406\n",
      "Batch 666 Loss: 0.3520\n",
      "Batch 888 Loss: 0.2970\n",
      "\n",
      "EPOCH 34 LOSS: 0.3836\n",
      "\n",
      "Reconstruction error recall 0.0891\n",
      "Change: 0.0000%\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0629e-02.\n",
      "\n",
      "\u001b[1mEpoch 35\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3863\n",
      "Batch 222 Loss: 0.3441\n",
      "Batch 444 Loss: 0.3243\n",
      "Batch 666 Loss: 0.3475\n",
      "Batch 888 Loss: 0.3794\n",
      "\n",
      "EPOCH 35 LOSS: 0.3797\n",
      "\n",
      "Reconstruction error recall 0.0594\n",
      "Change: -0.3333%\n",
      "\n",
      "\u001b[1mEpoch 36\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3599\n",
      "Batch 222 Loss: 0.4970\n",
      "Batch 444 Loss: 0.3526\n",
      "Batch 666 Loss: 0.3957\n",
      "Batch 888 Loss: 0.3405\n",
      "\n",
      "EPOCH 36 LOSS: 0.3758\n",
      "\n",
      "Reconstruction error recall 0.0495\n",
      "Change: -0.1667%\n",
      "\n",
      "\u001b[1mEpoch 37\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3639\n",
      "Batch 222 Loss: 0.3563\n",
      "Batch 444 Loss: 0.3495\n",
      "Batch 666 Loss: 0.4215\n",
      "Batch 888 Loss: 0.3955\n",
      "\n",
      "EPOCH 37 LOSS: 0.3697\n",
      "\n",
      "Reconstruction error recall 0.0396\n",
      "Change: -0.2000%\n",
      "\n",
      "\u001b[1mEpoch 38\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3667\n",
      "Batch 222 Loss: 0.3279\n",
      "Batch 444 Loss: 0.3246\n",
      "Batch 666 Loss: 0.3451\n",
      "Batch 888 Loss: 0.3953\n",
      "\n",
      "EPOCH 38 LOSS: 0.3698\n",
      "\n",
      "Reconstruction error recall 0.0693\n",
      "Change: 0.7500%\n",
      "\n",
      "\u001b[1mEpoch 39\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 Loss: 0.3832\n",
      "Batch 222 Loss: 0.3299\n",
      "Batch 444 Loss: 0.3109\n",
      "Batch 666 Loss: 0.4096\n",
      "Batch 888 Loss: 0.3200\n",
      "\n",
      "EPOCH 39 LOSS: 0.3660\n",
      "\n",
      "Reconstruction error recall 0.0594\n",
      "Change: -0.1429%\n",
      "Epoch    39: reducing learning rate of group 0 to 9.5659e-03.\n",
      "\n",
      "\u001b[1mEpoch 40\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3145\n",
      "Batch 222 Loss: 0.3759\n",
      "Batch 444 Loss: 0.3606\n",
      "Batch 666 Loss: 0.4134\n",
      "Batch 888 Loss: 0.2971\n",
      "\n",
      "EPOCH 40 LOSS: 0.3626\n",
      "\n",
      "Reconstruction error recall 0.0594\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 41\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3436\n",
      "Batch 222 Loss: 0.3546\n",
      "Batch 444 Loss: 0.3113\n",
      "Batch 666 Loss: 0.3416\n",
      "Batch 888 Loss: 0.3593\n",
      "\n",
      "EPOCH 41 LOSS: 0.3620\n",
      "\n",
      "Reconstruction error recall 0.0495\n",
      "Change: -0.1667%\n",
      "\n",
      "\u001b[1mEpoch 42\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3401\n",
      "Batch 222 Loss: 0.3136\n",
      "Batch 444 Loss: 0.3059\n",
      "Batch 666 Loss: 0.4467\n",
      "Batch 888 Loss: 0.3053\n",
      "\n",
      "EPOCH 42 LOSS: 0.3599\n",
      "\n",
      "Reconstruction error recall 0.0396\n",
      "Change: -0.2000%\n",
      "\n",
      "\u001b[1mEpoch 43\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4845\n",
      "Batch 222 Loss: 0.3181\n",
      "Batch 444 Loss: 0.3436\n",
      "Batch 666 Loss: 0.3325\n",
      "Batch 888 Loss: 0.2859\n",
      "\n",
      "EPOCH 43 LOSS: 0.3576\n",
      "\n",
      "Reconstruction error recall 0.1089\n",
      "Change: 1.7500%\n",
      "\n",
      "\u001b[1mEpoch 44\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5788\n",
      "Batch 222 Loss: 0.3273\n",
      "Batch 444 Loss: 0.3242\n",
      "Batch 666 Loss: 0.3130\n",
      "Batch 888 Loss: 0.2826\n",
      "\n",
      "EPOCH 44 LOSS: 0.3540\n",
      "\n",
      "Reconstruction error recall 0.0594\n",
      "Change: -0.4545%\n",
      "Epoch    44: reducing learning rate of group 0 to 8.6093e-03.\n",
      "\n",
      "\u001b[1mEpoch 45\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3357\n",
      "Batch 222 Loss: 0.4875\n",
      "Batch 444 Loss: 0.4833\n",
      "Batch 666 Loss: 0.3461\n",
      "Batch 888 Loss: 0.3225\n",
      "\n",
      "EPOCH 45 LOSS: 0.3531\n",
      "\n",
      "Reconstruction error recall 0.0495\n",
      "Change: -0.1667%\n",
      "\n",
      "\u001b[1mEpoch 46\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3417\n",
      "Batch 222 Loss: 0.3310\n",
      "Batch 444 Loss: 0.3331\n",
      "Batch 666 Loss: 0.4176\n",
      "Batch 888 Loss: 0.3052\n",
      "\n",
      "EPOCH 46 LOSS: 0.3509\n",
      "\n",
      "Reconstruction error recall 0.0495\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 47\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3732\n",
      "Batch 222 Loss: 0.3142\n",
      "Batch 444 Loss: 0.3553\n",
      "Batch 666 Loss: 0.4793\n",
      "Batch 888 Loss: 0.3698\n",
      "\n",
      "EPOCH 47 LOSS: 0.3516\n",
      "\n",
      "Reconstruction error recall 0.0693\n",
      "Change: 0.4000%\n",
      "\n",
      "\u001b[1mEpoch 48\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2933\n",
      "Batch 222 Loss: 0.3054\n",
      "Batch 444 Loss: 0.4882\n",
      "Batch 666 Loss: 0.3392\n",
      "Batch 888 Loss: 0.3662\n",
      "\n",
      "EPOCH 48 LOSS: 0.3492\n",
      "\n",
      "Reconstruction error recall 0.0198\n",
      "Change: -0.7143%\n",
      "\n",
      "\u001b[1mEpoch 49\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3200\n",
      "Batch 222 Loss: 0.3098\n",
      "Batch 444 Loss: 0.3090\n",
      "Batch 666 Loss: 0.4117\n",
      "Batch 888 Loss: 0.2867\n",
      "\n",
      "EPOCH 49 LOSS: 0.3472\n",
      "\n",
      "Reconstruction error recall 0.0297\n",
      "Change: 0.5000%\n",
      "Epoch    49: reducing learning rate of group 0 to 7.7484e-03.\n",
      "\n",
      "\u001b[1mEpoch 50\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3394\n",
      "Batch 222 Loss: 0.3075\n",
      "Batch 444 Loss: 0.3761\n",
      "Batch 666 Loss: 0.3044\n",
      "Batch 888 Loss: 0.3393\n",
      "\n",
      "EPOCH 50 LOSS: 0.3462\n",
      "\n",
      "Reconstruction error recall 0.0495\n",
      "Change: 0.6667%\n",
      "\n",
      "\u001b[1mEpoch 51\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4587\n",
      "Batch 222 Loss: 0.3140\n",
      "Batch 444 Loss: 0.4898\n",
      "Batch 666 Loss: 0.4041\n",
      "Batch 888 Loss: 0.3172\n",
      "\n",
      "EPOCH 51 LOSS: 0.3477\n",
      "\n",
      "Reconstruction error recall 0.0693\n",
      "Change: 0.4000%\n",
      "\n",
      "\u001b[1mEpoch 52\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2872\n",
      "Batch 222 Loss: 0.3653\n",
      "Batch 444 Loss: 0.3746\n",
      "Batch 666 Loss: 0.3841\n",
      "Batch 888 Loss: 0.3664\n",
      "\n",
      "EPOCH 52 LOSS: 0.3455\n",
      "\n",
      "Reconstruction error recall 0.0594\n",
      "Change: -0.1429%\n",
      "\n",
      "\u001b[1mEpoch 53\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3337\n",
      "Batch 222 Loss: 0.3561\n",
      "Batch 444 Loss: 0.2936\n",
      "Batch 666 Loss: 0.4619\n",
      "Batch 888 Loss: 0.3131\n",
      "\n",
      "EPOCH 53 LOSS: 0.3452\n",
      "\n",
      "Reconstruction error recall 0.0990\n",
      "Change: 0.6667%\n",
      "\n",
      "\u001b[1mEpoch 54\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3355\n",
      "Batch 222 Loss: 0.3195\n",
      "Batch 444 Loss: 0.4956\n",
      "Batch 666 Loss: 0.3400\n",
      "Batch 888 Loss: 0.3518\n",
      "\n",
      "EPOCH 54 LOSS: 0.3442\n",
      "\n",
      "Reconstruction error recall 0.0693\n",
      "Change: -0.3000%\n",
      "Epoch    54: reducing learning rate of group 0 to 6.9736e-03.\n",
      "\n",
      "\u001b[1mEpoch 55\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3082\n",
      "Batch 222 Loss: 0.3120\n",
      "Batch 444 Loss: 0.3331\n",
      "Batch 666 Loss: 0.3176\n",
      "Batch 888 Loss: 0.4151\n",
      "\n",
      "EPOCH 55 LOSS: 0.3448\n",
      "\n",
      "Reconstruction error recall 0.0495\n",
      "Change: -0.2857%\n",
      "\n",
      "\u001b[1mEpoch 56\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3592\n",
      "Batch 222 Loss: 0.4180\n",
      "Batch 444 Loss: 0.3700\n",
      "Batch 666 Loss: 0.3426\n",
      "Batch 888 Loss: 0.3243\n",
      "\n",
      "EPOCH 56 LOSS: 0.3425\n",
      "\n",
      "Reconstruction error recall 0.0990\n",
      "Change: 1.0000%\n",
      "\n",
      "\u001b[1mEpoch 57\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3414\n",
      "Batch 222 Loss: 0.4029\n",
      "Batch 444 Loss: 0.2799\n",
      "Batch 666 Loss: 0.3358\n",
      "Batch 888 Loss: 0.2941\n",
      "\n",
      "EPOCH 57 LOSS: 0.3432\n",
      "\n",
      "Reconstruction error recall 0.0792\n",
      "Change: -0.2000%\n",
      "\n",
      "\u001b[1mEpoch 58\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3246\n",
      "Batch 222 Loss: 0.3472\n",
      "Batch 444 Loss: 0.3480\n",
      "Batch 666 Loss: 0.3208\n",
      "Batch 888 Loss: 0.2467\n",
      "\n",
      "EPOCH 58 LOSS: 0.3406\n",
      "\n",
      "Reconstruction error recall 0.0297\n",
      "Change: -0.6250%\n",
      "\n",
      "\u001b[1mEpoch 59\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3068\n",
      "Batch 222 Loss: 0.2934\n",
      "Batch 444 Loss: 0.3051\n",
      "Batch 666 Loss: 0.3103\n",
      "Batch 888 Loss: 0.3556\n",
      "\n",
      "EPOCH 59 LOSS: 0.3414\n",
      "\n",
      "Reconstruction error recall 0.0495\n",
      "Change: 0.6667%\n",
      "Epoch    59: reducing learning rate of group 0 to 6.2762e-03.\n",
      "\n",
      "\u001b[1mEpoch 60\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2978\n",
      "Batch 222 Loss: 0.3676\n",
      "Batch 444 Loss: 0.3050\n",
      "Batch 666 Loss: 0.3345\n",
      "Batch 888 Loss: 0.3433\n",
      "\n",
      "EPOCH 60 LOSS: 0.3408\n",
      "\n",
      "Reconstruction error recall 0.0297\n",
      "Change: -0.4000%\n",
      "\n",
      "\u001b[1mEpoch 61\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3126\n",
      "Batch 222 Loss: 0.3317\n",
      "Batch 444 Loss: 0.3404\n",
      "Batch 666 Loss: 0.3213\n",
      "Batch 888 Loss: 0.3012\n",
      "\n",
      "EPOCH 61 LOSS: 0.3405\n",
      "\n",
      "Reconstruction error recall 0.0693\n",
      "Change: 1.3333%\n",
      "\n",
      "\u001b[1mEpoch 62\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2867\n",
      "Batch 222 Loss: 0.4430\n",
      "Batch 444 Loss: 0.2935\n",
      "Batch 666 Loss: 0.3182\n",
      "Batch 888 Loss: 0.2696\n",
      "\n",
      "EPOCH 62 LOSS: 0.3407\n",
      "\n",
      "Reconstruction error recall 0.0990\n",
      "Change: 0.4286%\n",
      "\n",
      "\u001b[1mEpoch 63\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3214\n",
      "Batch 222 Loss: 0.2950\n",
      "Batch 444 Loss: 0.3183\n",
      "Batch 666 Loss: 0.3640\n",
      "Batch 888 Loss: 0.2740\n",
      "\n",
      "EPOCH 63 LOSS: 0.3404\n",
      "\n",
      "Reconstruction error recall 0.0099\n",
      "Change: -0.9000%\n",
      "\n",
      "\u001b[1mEpoch 64\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3442\n",
      "Batch 222 Loss: 0.3152\n",
      "Batch 444 Loss: 0.3902\n",
      "Batch 666 Loss: 0.3865\n",
      "Batch 888 Loss: 0.3137\n",
      "\n",
      "EPOCH 64 LOSS: 0.3402\n",
      "\n",
      "Reconstruction error recall 0.0594\n",
      "Change: 5.0000%\n",
      "Epoch    64: reducing learning rate of group 0 to 5.6486e-03.\n",
      "\n",
      "\u001b[1mEpoch 65\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3703\n",
      "Batch 222 Loss: 0.3184\n",
      "Batch 444 Loss: 0.2965\n",
      "Batch 666 Loss: 0.2911\n",
      "Batch 888 Loss: 0.2902\n",
      "\n",
      "EPOCH 65 LOSS: 0.3402\n",
      "\n",
      "Reconstruction error recall 0.0297\n",
      "Change: -0.5000%\n",
      "\n",
      "\u001b[1mEpoch 66\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3878\n",
      "Batch 222 Loss: 0.2877\n",
      "Batch 444 Loss: 0.4073\n",
      "Batch 666 Loss: 0.3685\n",
      "Batch 888 Loss: 0.2929\n",
      "\n",
      "EPOCH 66 LOSS: 0.3363\n",
      "\n",
      "Reconstruction error recall 0.0693\n",
      "Change: 1.3333%\n",
      "\n",
      "\u001b[1mEpoch 67\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3102\n",
      "Batch 222 Loss: 0.5217\n",
      "Batch 444 Loss: 0.3206\n",
      "Batch 666 Loss: 0.3260\n",
      "Batch 888 Loss: 0.3609\n",
      "\n",
      "EPOCH 67 LOSS: 0.3392\n",
      "\n",
      "Reconstruction error recall 0.0198\n",
      "Change: -0.7143%\n",
      "\n",
      "\u001b[1mEpoch 68\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3606\n",
      "Batch 222 Loss: 0.3133\n",
      "Batch 444 Loss: 0.3894\n",
      "Batch 666 Loss: 0.3398\n",
      "Batch 888 Loss: 0.3106\n",
      "\n",
      "EPOCH 68 LOSS: 0.3378\n",
      "\n",
      "Reconstruction error recall 0.0396\n",
      "Change: 1.0000%\n",
      "\n",
      "\u001b[1mEpoch 69\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2979\n",
      "Batch 222 Loss: 0.3114\n",
      "Batch 444 Loss: 0.2988\n",
      "Batch 666 Loss: 0.3126\n",
      "Batch 888 Loss: 0.3167\n",
      "\n",
      "EPOCH 69 LOSS: 0.3376\n",
      "\n",
      "Reconstruction error recall 0.0396\n",
      "Change: 0.0000%\n",
      "Epoch    69: reducing learning rate of group 0 to 5.0837e-03.\n",
      "\n",
      "\u001b[1mEpoch 70\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2974\n",
      "Batch 222 Loss: 0.3802\n",
      "Batch 444 Loss: 0.3702\n",
      "Batch 666 Loss: 0.3278\n",
      "Batch 888 Loss: 0.4194\n",
      "\n",
      "EPOCH 70 LOSS: 0.3359\n",
      "\n",
      "Reconstruction error recall 0.0297\n",
      "Change: -0.2500%\n",
      "\n",
      "\u001b[1mEpoch 71\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2896\n",
      "Batch 222 Loss: 0.3124\n",
      "Batch 444 Loss: 0.2921\n",
      "Batch 666 Loss: 0.3095\n",
      "Batch 888 Loss: 0.3084\n",
      "\n",
      "EPOCH 71 LOSS: 0.3350\n",
      "\n",
      "Reconstruction error recall 0.0693\n",
      "Change: 1.3333%\n",
      "\n",
      "\u001b[1mEpoch 72\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3795\n",
      "Batch 222 Loss: 0.3181\n",
      "Batch 444 Loss: 0.3008\n",
      "Batch 666 Loss: 0.4231\n",
      "Batch 888 Loss: 0.2903\n",
      "\n",
      "EPOCH 72 LOSS: 0.3367\n",
      "\n",
      "Reconstruction error recall 0.0594\n",
      "Change: -0.1429%\n",
      "\n",
      "\u001b[1mEpoch 73\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3026\n",
      "Batch 222 Loss: 0.3436\n",
      "Batch 444 Loss: 0.2821\n",
      "Batch 666 Loss: 0.3650\n",
      "Batch 888 Loss: 0.4764\n",
      "\n",
      "EPOCH 73 LOSS: 0.3344\n",
      "\n",
      "Reconstruction error recall 0.0891\n",
      "Change: 0.5000%\n",
      "\n",
      "\u001b[1mEpoch 74\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3432\n",
      "Batch 222 Loss: 0.3768\n",
      "Batch 444 Loss: 0.3479\n",
      "Batch 666 Loss: 0.6752\n",
      "Batch 888 Loss: 0.3219\n",
      "\n",
      "EPOCH 74 LOSS: 0.3340\n",
      "\n",
      "Reconstruction error recall 0.0693\n",
      "Change: -0.2222%\n",
      "Epoch    74: reducing learning rate of group 0 to 4.5754e-03.\n",
      "\n",
      "\u001b[1mEpoch 75\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3085\n",
      "Batch 222 Loss: 0.3902\n",
      "Batch 444 Loss: 0.2630\n",
      "Batch 666 Loss: 0.3538\n",
      "Batch 888 Loss: 0.2679\n",
      "\n",
      "EPOCH 75 LOSS: 0.3319\n",
      "\n",
      "Reconstruction error recall 0.0495\n",
      "Change: -0.2857%\n",
      "\n",
      "\u001b[1mEpoch 76\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 222 Loss: 0.5397\n",
      "Batch 444 Loss: 0.3343\n",
      "Batch 666 Loss: 0.3153\n",
      "Batch 888 Loss: 0.3083\n",
      "\n",
      "EPOCH 76 LOSS: 0.3320\n",
      "\n",
      "Reconstruction error recall 0.0495\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 77\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3109\n",
      "Batch 222 Loss: 0.3106\n",
      "Batch 444 Loss: 0.3967\n",
      "Batch 666 Loss: 0.3246\n",
      "Batch 888 Loss: 0.3530\n",
      "\n",
      "EPOCH 77 LOSS: 0.3317\n",
      "\n",
      "Reconstruction error recall 0.0396\n",
      "Change: -0.2000%\n",
      "\n",
      "\u001b[1mEpoch 78\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3665\n",
      "Batch 222 Loss: 0.3123\n",
      "Batch 444 Loss: 0.3017\n",
      "Batch 666 Loss: 0.3230\n",
      "Batch 888 Loss: 0.2849\n",
      "\n",
      "EPOCH 78 LOSS: 0.3306\n",
      "\n",
      "Reconstruction error recall 0.0297\n",
      "Change: -0.2500%\n",
      "\n",
      "\u001b[1mEpoch 79\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3707\n",
      "Batch 222 Loss: 0.4081\n",
      "Batch 444 Loss: 0.2870\n",
      "Batch 666 Loss: 0.3588\n",
      "Batch 888 Loss: 0.3440\n",
      "\n",
      "EPOCH 79 LOSS: 0.3309\n",
      "\n",
      "Reconstruction error recall 0.0594\n",
      "Change: 1.0000%\n",
      "Epoch    79: reducing learning rate of group 0 to 4.1178e-03.\n",
      "\n",
      "\u001b[1mEpoch 80\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3151\n",
      "Batch 222 Loss: 0.3304\n",
      "Batch 444 Loss: 0.2774\n",
      "Batch 666 Loss: 0.3049\n",
      "Batch 888 Loss: 0.3757\n",
      "\n",
      "EPOCH 80 LOSS: 0.3287\n",
      "\n",
      "Reconstruction error recall 0.0495\n",
      "Change: -0.1667%\n",
      "\n",
      "\u001b[1mEpoch 81\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2869\n",
      "Batch 222 Loss: 0.3160\n",
      "Batch 444 Loss: 0.3143\n",
      "Batch 666 Loss: 0.3761\n",
      "Batch 888 Loss: 0.2911\n",
      "\n",
      "EPOCH 81 LOSS: 0.3286\n",
      "\n",
      "Reconstruction error recall 0.0792\n",
      "Change: 0.6000%\n",
      "\n",
      "\u001b[1mEpoch 82\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2876\n",
      "Batch 222 Loss: 0.2825\n",
      "Batch 444 Loss: 0.2840\n",
      "Batch 666 Loss: 0.3216\n",
      "Batch 888 Loss: 0.2686\n",
      "\n",
      "EPOCH 82 LOSS: 0.3287\n",
      "\n",
      "Reconstruction error recall 0.0693\n",
      "Change: -0.1250%\n",
      "\n",
      "\u001b[1mEpoch 83\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3407\n",
      "Batch 222 Loss: 0.3076\n",
      "Batch 444 Loss: 0.3364\n",
      "Batch 666 Loss: 0.3765\n",
      "Batch 888 Loss: 0.3315\n",
      "\n",
      "EPOCH 83 LOSS: 0.3273\n",
      "\n",
      "Reconstruction error recall 0.0594\n",
      "Change: -0.1429%\n",
      "\n",
      "\u001b[1mEpoch 84\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2441\n",
      "Batch 222 Loss: 0.2992\n",
      "Batch 444 Loss: 0.3089\n",
      "Batch 666 Loss: 0.3070\n",
      "Batch 888 Loss: 0.3026\n",
      "\n",
      "EPOCH 84 LOSS: 0.3255\n",
      "\n",
      "Reconstruction error recall 0.0297\n",
      "Change: -0.5000%\n",
      "Epoch    84: reducing learning rate of group 0 to 3.7060e-03.\n",
      "\n",
      "\u001b[1mEpoch 85\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3405\n",
      "Batch 222 Loss: 0.2729\n",
      "Batch 444 Loss: 0.3546\n",
      "Batch 666 Loss: 0.3907\n",
      "Batch 888 Loss: 0.3043\n",
      "\n",
      "EPOCH 85 LOSS: 0.3248\n",
      "\n",
      "Reconstruction error recall 0.0495\n",
      "Change: 0.6667%\n",
      "\n",
      "\u001b[1mEpoch 86\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4029\n",
      "Batch 222 Loss: 0.2979\n",
      "Batch 444 Loss: 0.3544\n",
      "Batch 666 Loss: 0.2973\n",
      "Batch 888 Loss: 0.3124\n",
      "\n",
      "EPOCH 86 LOSS: 0.3264\n",
      "\n",
      "Reconstruction error recall 0.0594\n",
      "Change: 0.2000%\n",
      "\n",
      "\u001b[1mEpoch 87\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3157\n",
      "Batch 222 Loss: 0.3023\n",
      "Batch 444 Loss: 0.2987\n",
      "Batch 666 Loss: 0.3075\n",
      "Batch 888 Loss: 0.2610\n",
      "\n",
      "EPOCH 87 LOSS: 0.3266\n",
      "\n",
      "Reconstruction error recall 0.0594\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 88\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3109\n",
      "Batch 222 Loss: 0.3157\n",
      "Batch 444 Loss: 0.4113\n",
      "Batch 666 Loss: 0.2828\n",
      "Batch 888 Loss: 0.4278\n",
      "\n",
      "EPOCH 88 LOSS: 0.3257\n",
      "\n",
      "Reconstruction error recall 0.0297\n",
      "Change: -0.5000%\n",
      "\n",
      "\u001b[1mEpoch 89\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2969\n",
      "Batch 222 Loss: 0.3620\n",
      "Batch 444 Loss: 0.3451\n",
      "Batch 666 Loss: 0.2766\n",
      "Batch 888 Loss: 0.2963\n",
      "\n",
      "EPOCH 89 LOSS: 0.3246\n",
      "\n",
      "Reconstruction error recall 0.0693\n",
      "Change: 1.3333%\n",
      "Epoch    89: reducing learning rate of group 0 to 3.3354e-03.\n",
      "\n",
      "\u001b[1mEpoch 90\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3011\n",
      "Batch 222 Loss: 0.2621\n",
      "Batch 444 Loss: 0.3032\n",
      "Batch 666 Loss: 0.4578\n",
      "Batch 888 Loss: 0.3947\n",
      "\n",
      "EPOCH 90 LOSS: 0.3234\n",
      "\n",
      "Reconstruction error recall 0.0891\n",
      "Change: 0.2857%\n",
      "\n",
      "\u001b[1mEpoch 91\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2950\n",
      "Batch 222 Loss: 0.4993\n",
      "Batch 444 Loss: 0.2725\n",
      "Batch 666 Loss: 0.4187\n",
      "Batch 888 Loss: 0.4702\n",
      "\n",
      "EPOCH 91 LOSS: 0.3243\n",
      "\n",
      "Reconstruction error recall 0.0495\n",
      "Change: -0.4444%\n",
      "\n",
      "\u001b[1mEpoch 92\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3844\n",
      "Batch 222 Loss: 0.3648\n",
      "Batch 444 Loss: 0.4457\n",
      "Batch 666 Loss: 0.3344\n",
      "Batch 888 Loss: 0.3090\n",
      "\n",
      "EPOCH 92 LOSS: 0.3239\n",
      "\n",
      "Reconstruction error recall 0.0792\n",
      "Change: 0.6000%\n",
      "\n",
      "\u001b[1mEpoch 93\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2869\n",
      "Batch 222 Loss: 0.2638\n",
      "Batch 444 Loss: 0.2924\n",
      "Batch 666 Loss: 0.2907\n",
      "Batch 888 Loss: 0.3616\n",
      "\n",
      "EPOCH 93 LOSS: 0.3232\n",
      "\n",
      "Reconstruction error recall 0.0396\n",
      "Change: -0.5000%\n",
      "\n",
      "\u001b[1mEpoch 94\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3305\n",
      "Batch 222 Loss: 0.2664\n",
      "Batch 444 Loss: 0.3881\n",
      "Batch 666 Loss: 0.3164\n",
      "Batch 888 Loss: 0.3031\n",
      "\n",
      "EPOCH 94 LOSS: 0.3223\n",
      "\n",
      "Reconstruction error recall 0.0495\n",
      "Change: 0.2500%\n",
      "Epoch    94: reducing learning rate of group 0 to 3.0019e-03.\n",
      "\n",
      "\u001b[1mEpoch 95\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2870\n",
      "Batch 222 Loss: 0.3097\n",
      "Batch 444 Loss: 0.3637\n",
      "Batch 666 Loss: 0.3093\n",
      "Batch 888 Loss: 0.3628\n",
      "\n",
      "EPOCH 95 LOSS: 0.3235\n",
      "\n",
      "Reconstruction error recall 0.0693\n",
      "Change: 0.4000%\n",
      "\n",
      "\u001b[1mEpoch 96\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3317\n",
      "Batch 222 Loss: 0.4797\n",
      "Batch 444 Loss: 0.3216\n",
      "Batch 666 Loss: 0.2872\n",
      "Batch 888 Loss: 0.3354\n",
      "\n",
      "EPOCH 96 LOSS: 0.3217\n",
      "\n",
      "Reconstruction error recall 0.0396\n",
      "Change: -0.4286%\n",
      "\n",
      "\u001b[1mEpoch 97\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3123\n",
      "Batch 222 Loss: 0.2635\n",
      "Batch 444 Loss: 0.3016\n",
      "Batch 666 Loss: 0.3062\n",
      "Batch 888 Loss: 0.2762\n",
      "\n",
      "EPOCH 97 LOSS: 0.3216\n",
      "\n",
      "Reconstruction error recall 0.0495\n",
      "Change: 0.2500%\n",
      "\n",
      "\u001b[1mEpoch 98\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3318\n",
      "Batch 222 Loss: 0.3254\n",
      "Batch 444 Loss: 0.3554\n",
      "Batch 666 Loss: 0.3300\n",
      "Batch 888 Loss: 0.3272\n",
      "\n",
      "EPOCH 98 LOSS: 0.3231\n",
      "\n",
      "Reconstruction error recall 0.0891\n",
      "Change: 0.8000%\n",
      "\n",
      "\u001b[1mEpoch 99\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3525\n",
      "Batch 222 Loss: 0.3199\n",
      "Batch 444 Loss: 0.3133\n",
      "Batch 666 Loss: 0.2836\n",
      "Batch 888 Loss: 0.3390\n",
      "\n",
      "EPOCH 99 LOSS: 0.3212\n",
      "\n",
      "Reconstruction error recall 0.0792\n",
      "Change: -0.1111%\n",
      "Epoch    99: reducing learning rate of group 0 to 2.7017e-03.\n",
      "\n",
      "\u001b[1mEpoch 100\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3173\n",
      "Batch 222 Loss: 0.3610\n",
      "Batch 444 Loss: 0.6807\n",
      "Batch 666 Loss: 0.3419\n",
      "Batch 888 Loss: 0.2412\n",
      "\n",
      "EPOCH 100 LOSS: 0.3217\n",
      "\n",
      "Reconstruction error recall 0.0099\n",
      "Change: -0.8750%\n"
     ]
    }
   ],
   "source": [
    "#Start with high learning rate\n",
    "optimizer = torch.optim.SGD(ae1.parameters(), lr=0.02, momentum=0.9,nesterov=True)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.9, patience=4, verbose=True)\n",
    "train_autoencoder(model=ae1,\n",
    "                   dataset=normal_torch,\n",
    "                   loss_func=loss_func,\n",
    "                   optimizer=optimizer,\n",
    "                   batch_size=256,\n",
    "                   epochs=100,\n",
    "                   lr_rate_scheduler=scheduler,\n",
    "                   validation_tensor=val_torch,\n",
    "                   y_val = y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "output1 = ae1(normal_torch)\n",
    "train_output1 = ae1(train_torch)\n",
    "val_output1 = ae1(val_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder II: L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae2 = AutoEncoder(n_features,n_features)\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mEpoch 1\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5115\n",
      "Batch 222 Loss: 0.8374\n",
      "Batch 444 Loss: 0.4493\n",
      "Batch 666 Loss: 0.5553\n",
      "Batch 888 Loss: 0.5016\n",
      "\n",
      "EPOCH 1 LOSS: 0.6490\n",
      "\n",
      "Reconstruction error recall: 0.2079\n",
      "\n",
      "\u001b[1mEpoch 2\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7040\n",
      "Batch 222 Loss: 0.5675\n",
      "Batch 444 Loss: 0.5542\n",
      "Batch 666 Loss: 0.5440\n",
      "Batch 888 Loss: 1.6456\n",
      "\n",
      "EPOCH 2 LOSS: 0.6498\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 3\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5355\n",
      "Batch 222 Loss: 0.5429\n",
      "Batch 444 Loss: 0.5103\n",
      "Batch 666 Loss: 0.6005\n",
      "Batch 888 Loss: 0.7870\n",
      "\n",
      "EPOCH 3 LOSS: 0.6548\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 4\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7061\n",
      "Batch 222 Loss: 0.5226\n",
      "Batch 444 Loss: 0.7563\n",
      "Batch 666 Loss: 0.6665\n",
      "Batch 888 Loss: 0.7538\n",
      "\n",
      "EPOCH 4 LOSS: 0.6543\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch     4: reducing learning rate of group 0 to 1.8000e-01.\n",
      "\n",
      "\u001b[1mEpoch 5\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5517\n",
      "Batch 222 Loss: 0.6649\n",
      "Batch 444 Loss: 0.9220\n",
      "Batch 666 Loss: 0.8240\n",
      "Batch 888 Loss: 0.4064\n",
      "\n",
      "EPOCH 5 LOSS: 0.6492\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 6\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5108\n",
      "Batch 222 Loss: 0.5743\n",
      "Batch 444 Loss: 0.5363\n",
      "Batch 666 Loss: 0.5019\n",
      "Batch 888 Loss: 0.6461\n",
      "\n",
      "EPOCH 6 LOSS: 0.6507\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 7\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5796\n",
      "Batch 222 Loss: 0.8089\n",
      "Batch 444 Loss: 0.5779\n",
      "Batch 666 Loss: 0.7183\n",
      "Batch 888 Loss: 0.4842\n",
      "\n",
      "EPOCH 7 LOSS: 0.6514\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch     7: reducing learning rate of group 0 to 1.6200e-01.\n",
      "\n",
      "\u001b[1mEpoch 8\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5346\n",
      "Batch 222 Loss: 0.7570\n",
      "Batch 444 Loss: 0.6202\n",
      "Batch 666 Loss: 0.6058\n",
      "Batch 888 Loss: 0.9533\n",
      "\n",
      "EPOCH 8 LOSS: 0.6507\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 9\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7127\n",
      "Batch 222 Loss: 0.8789\n",
      "Batch 444 Loss: 0.5417\n",
      "Batch 666 Loss: 0.7736\n",
      "Batch 888 Loss: 0.7883\n",
      "\n",
      "EPOCH 9 LOSS: 0.6480\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 10\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7080\n",
      "Batch 222 Loss: 0.6106\n",
      "Batch 444 Loss: 1.2404\n",
      "Batch 666 Loss: 0.6225\n",
      "Batch 888 Loss: 0.4802\n",
      "\n",
      "EPOCH 10 LOSS: 0.6493\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    10: reducing learning rate of group 0 to 1.4580e-01.\n",
      "\n",
      "\u001b[1mEpoch 11\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5832\n",
      "Batch 222 Loss: 0.6411\n",
      "Batch 444 Loss: 0.6573\n",
      "Batch 666 Loss: 0.5677\n",
      "Batch 888 Loss: 0.5495\n",
      "\n",
      "EPOCH 11 LOSS: 0.6481\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 12\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5478\n",
      "Batch 222 Loss: 0.5176\n",
      "Batch 444 Loss: 0.8317\n",
      "Batch 666 Loss: 1.0495\n",
      "Batch 888 Loss: 0.6129\n",
      "\n",
      "EPOCH 12 LOSS: 0.6493\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 13\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7218\n",
      "Batch 222 Loss: 0.8943\n",
      "Batch 444 Loss: 0.4890\n",
      "Batch 666 Loss: 0.6141\n",
      "Batch 888 Loss: 0.6111\n",
      "\n",
      "EPOCH 13 LOSS: 0.6461\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    13: reducing learning rate of group 0 to 1.3122e-01.\n",
      "\n",
      "\u001b[1mEpoch 14\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4951\n",
      "Batch 222 Loss: 1.4269\n",
      "Batch 444 Loss: 0.7768\n",
      "Batch 666 Loss: 0.5398\n",
      "Batch 888 Loss: 0.6984\n",
      "\n",
      "EPOCH 14 LOSS: 0.6480\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 15\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6281\n",
      "Batch 222 Loss: 0.4520\n",
      "Batch 444 Loss: 0.5096\n",
      "Batch 666 Loss: 0.5316\n",
      "Batch 888 Loss: 0.5401\n",
      "\n",
      "EPOCH 15 LOSS: 0.6479\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 16\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5396\n",
      "Batch 222 Loss: 0.5510\n",
      "Batch 444 Loss: 0.5605\n",
      "Batch 666 Loss: 0.7311\n",
      "Batch 888 Loss: 0.4728\n",
      "\n",
      "EPOCH 16 LOSS: 0.6475\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    16: reducing learning rate of group 0 to 1.1810e-01.\n",
      "\n",
      "\u001b[1mEpoch 17\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4824\n",
      "Batch 222 Loss: 0.6190\n",
      "Batch 444 Loss: 0.7792\n",
      "Batch 666 Loss: 0.5987\n",
      "Batch 888 Loss: 0.4828\n",
      "\n",
      "EPOCH 17 LOSS: 0.6470\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 18\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5956\n",
      "Batch 222 Loss: 0.4869\n",
      "Batch 444 Loss: 0.5844\n",
      "Batch 666 Loss: 0.5003\n",
      "Batch 888 Loss: 1.2759\n",
      "\n",
      "EPOCH 18 LOSS: 0.6490\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 19\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8200\n",
      "Batch 222 Loss: 0.5955\n",
      "Batch 444 Loss: 0.6079\n",
      "Batch 666 Loss: 0.6762\n",
      "Batch 888 Loss: 1.1132\n",
      "\n",
      "EPOCH 19 LOSS: 0.6485\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0629e-01.\n",
      "\n",
      "\u001b[1mEpoch 20\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6815\n",
      "Batch 222 Loss: 0.4810\n",
      "Batch 444 Loss: 0.4810\n",
      "Batch 666 Loss: 0.6911\n",
      "Batch 888 Loss: 0.5520\n",
      "\n",
      "EPOCH 20 LOSS: 0.6463\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 21\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8801\n",
      "Batch 222 Loss: 1.0395\n",
      "Batch 444 Loss: 0.5309\n",
      "Batch 666 Loss: 0.4865\n",
      "Batch 888 Loss: 0.5377\n",
      "\n",
      "EPOCH 21 LOSS: 0.6462\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 22\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6400\n",
      "Batch 222 Loss: 0.4950\n",
      "Batch 444 Loss: 0.7542\n",
      "Batch 666 Loss: 0.5133\n",
      "Batch 888 Loss: 1.1523\n",
      "\n",
      "EPOCH 22 LOSS: 0.6462\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    22: reducing learning rate of group 0 to 9.5659e-02.\n",
      "\n",
      "\u001b[1mEpoch 23\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5560\n",
      "Batch 222 Loss: 0.5774\n",
      "Batch 444 Loss: 0.7552\n",
      "Batch 666 Loss: 0.6731\n",
      "Batch 888 Loss: 0.4880\n",
      "\n",
      "EPOCH 23 LOSS: 0.6464\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 24\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5860\n",
      "Batch 222 Loss: 0.5224\n",
      "Batch 444 Loss: 0.5858\n",
      "Batch 666 Loss: 0.4777\n",
      "Batch 888 Loss: 0.4752\n",
      "\n",
      "EPOCH 24 LOSS: 0.6456\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 25\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5092\n",
      "Batch 222 Loss: 0.5805\n",
      "Batch 444 Loss: 0.5436\n",
      "Batch 666 Loss: 0.8925\n",
      "Batch 888 Loss: 0.4986\n",
      "\n",
      "EPOCH 25 LOSS: 0.6453\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    25: reducing learning rate of group 0 to 8.6093e-02.\n",
      "\n",
      "\u001b[1mEpoch 26\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6717\n",
      "Batch 222 Loss: 0.5362\n",
      "Batch 444 Loss: 0.5641\n",
      "Batch 666 Loss: 0.5530\n",
      "Batch 888 Loss: 0.5554\n",
      "\n",
      "EPOCH 26 LOSS: 0.6446\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 27\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5660\n",
      "Batch 222 Loss: 0.8504\n",
      "Batch 444 Loss: 0.5536\n",
      "Batch 666 Loss: 0.5231\n",
      "Batch 888 Loss: 0.6430\n",
      "\n",
      "EPOCH 27 LOSS: 0.6452\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 28\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.9542\n",
      "Batch 222 Loss: 0.7168\n",
      "Batch 444 Loss: 0.5601\n",
      "Batch 666 Loss: 0.5254\n",
      "Batch 888 Loss: 0.9464\n",
      "\n",
      "EPOCH 28 LOSS: 0.6446\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    28: reducing learning rate of group 0 to 7.7484e-02.\n",
      "\n",
      "\u001b[1mEpoch 29\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4852\n",
      "Batch 222 Loss: 0.5496\n",
      "Batch 444 Loss: 0.9127\n",
      "Batch 666 Loss: 0.5589\n",
      "Batch 888 Loss: 0.5321\n",
      "\n",
      "EPOCH 29 LOSS: 0.6436\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 30\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7498\n",
      "Batch 222 Loss: 0.5322\n",
      "Batch 444 Loss: 0.5687\n",
      "Batch 666 Loss: 0.5757\n",
      "Batch 888 Loss: 0.6547\n",
      "\n",
      "EPOCH 30 LOSS: 0.6454\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 31\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5406\n",
      "Batch 222 Loss: 0.6632\n",
      "Batch 444 Loss: 0.6828\n",
      "Batch 666 Loss: 0.5440\n",
      "Batch 888 Loss: 0.4784\n",
      "\n",
      "EPOCH 31 LOSS: 0.6457\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    31: reducing learning rate of group 0 to 6.9736e-02.\n",
      "\n",
      "\u001b[1mEpoch 32\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5412\n",
      "Batch 222 Loss: 0.5635\n",
      "Batch 444 Loss: 0.5113\n",
      "Batch 666 Loss: 0.6415\n",
      "Batch 888 Loss: 1.4982\n",
      "\n",
      "EPOCH 32 LOSS: 0.6446\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 33\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5170\n",
      "Batch 222 Loss: 0.4780\n",
      "Batch 444 Loss: 0.5676\n",
      "Batch 666 Loss: 0.5944\n",
      "Batch 888 Loss: 0.6204\n",
      "\n",
      "EPOCH 33 LOSS: 0.6444\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 34\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5110\n",
      "Batch 222 Loss: 0.5189\n",
      "Batch 444 Loss: 0.7185\n",
      "Batch 666 Loss: 0.5958\n",
      "Batch 888 Loss: 0.5239\n",
      "\n",
      "EPOCH 34 LOSS: 0.6439\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    34: reducing learning rate of group 0 to 6.2762e-02.\n",
      "\n",
      "\u001b[1mEpoch 35\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6279\n",
      "Batch 222 Loss: 0.4387\n",
      "Batch 444 Loss: 0.4935\n",
      "Batch 666 Loss: 0.4412\n",
      "Batch 888 Loss: 0.6469\n",
      "\n",
      "EPOCH 35 LOSS: 0.6439\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 36\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4820\n",
      "Batch 222 Loss: 0.6249\n",
      "Batch 444 Loss: 0.6883\n",
      "Batch 666 Loss: 0.6981\n",
      "Batch 888 Loss: 0.5355\n",
      "\n",
      "EPOCH 36 LOSS: 0.6444\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 37\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5064\n",
      "Batch 222 Loss: 0.7146\n",
      "Batch 444 Loss: 1.1677\n",
      "Batch 666 Loss: 0.7792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 888 Loss: 0.4321\n",
      "\n",
      "EPOCH 37 LOSS: 0.6436\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    37: reducing learning rate of group 0 to 5.6486e-02.\n",
      "\n",
      "\u001b[1mEpoch 38\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5327\n",
      "Batch 222 Loss: 0.9532\n",
      "Batch 444 Loss: 0.6344\n",
      "Batch 666 Loss: 0.5251\n",
      "Batch 888 Loss: 1.0807\n",
      "\n",
      "EPOCH 38 LOSS: 0.6444\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 39\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5375\n",
      "Batch 222 Loss: 0.5572\n",
      "Batch 444 Loss: 0.5385\n",
      "Batch 666 Loss: 0.4820\n",
      "Batch 888 Loss: 1.1792\n",
      "\n",
      "EPOCH 39 LOSS: 0.6441\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 40\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7576\n",
      "Batch 222 Loss: 0.5244\n",
      "Batch 444 Loss: 0.5185\n",
      "Batch 666 Loss: 0.5095\n",
      "Batch 888 Loss: 0.5638\n",
      "\n",
      "EPOCH 40 LOSS: 0.6440\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    40: reducing learning rate of group 0 to 5.0837e-02.\n",
      "\n",
      "\u001b[1mEpoch 41\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4971\n",
      "Batch 222 Loss: 0.7727\n",
      "Batch 444 Loss: 0.7027\n",
      "Batch 666 Loss: 0.5498\n",
      "Batch 888 Loss: 0.4948\n",
      "\n",
      "EPOCH 41 LOSS: 0.6438\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 42\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5896\n",
      "Batch 222 Loss: 0.7177\n",
      "Batch 444 Loss: 0.5309\n",
      "Batch 666 Loss: 0.7560\n",
      "Batch 888 Loss: 0.5921\n",
      "\n",
      "EPOCH 42 LOSS: 0.6434\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 43\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5563\n",
      "Batch 222 Loss: 0.5690\n",
      "Batch 444 Loss: 0.5246\n",
      "Batch 666 Loss: 0.5979\n",
      "Batch 888 Loss: 0.4680\n",
      "\n",
      "EPOCH 43 LOSS: 0.6447\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    43: reducing learning rate of group 0 to 4.5754e-02.\n",
      "\n",
      "\u001b[1mEpoch 44\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5282\n",
      "Batch 222 Loss: 0.6657\n",
      "Batch 444 Loss: 0.8866\n",
      "Batch 666 Loss: 0.5234\n",
      "Batch 888 Loss: 0.4157\n",
      "\n",
      "EPOCH 44 LOSS: 0.6434\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 45\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4719\n",
      "Batch 222 Loss: 0.9430\n",
      "Batch 444 Loss: 0.6815\n",
      "Batch 666 Loss: 0.5629\n",
      "Batch 888 Loss: 0.5068\n",
      "\n",
      "EPOCH 45 LOSS: 0.6434\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 46\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6143\n",
      "Batch 222 Loss: 0.4765\n",
      "Batch 444 Loss: 0.7439\n",
      "Batch 666 Loss: 0.4955\n",
      "Batch 888 Loss: 0.8696\n",
      "\n",
      "EPOCH 46 LOSS: 0.6435\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    46: reducing learning rate of group 0 to 4.1178e-02.\n",
      "\n",
      "\u001b[1mEpoch 47\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7020\n",
      "Batch 222 Loss: 0.6799\n",
      "Batch 444 Loss: 0.5065\n",
      "Batch 666 Loss: 0.5789\n",
      "Batch 888 Loss: 0.5580\n",
      "\n",
      "EPOCH 47 LOSS: 0.6432\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 48\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7738\n",
      "Batch 222 Loss: 0.6784\n",
      "Batch 444 Loss: 1.5102\n",
      "Batch 666 Loss: 0.6998\n",
      "Batch 888 Loss: 0.4709\n",
      "\n",
      "EPOCH 48 LOSS: 0.6431\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 49\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7813\n",
      "Batch 222 Loss: 0.6471\n",
      "Batch 444 Loss: 0.4846\n",
      "Batch 666 Loss: 0.5396\n",
      "Batch 888 Loss: 0.8811\n",
      "\n",
      "EPOCH 49 LOSS: 0.6436\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    49: reducing learning rate of group 0 to 3.7060e-02.\n",
      "\n",
      "\u001b[1mEpoch 50\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5979\n",
      "Batch 222 Loss: 0.6281\n",
      "Batch 444 Loss: 0.6111\n",
      "Batch 666 Loss: 0.7282\n",
      "Batch 888 Loss: 0.4818\n",
      "\n",
      "EPOCH 50 LOSS: 0.6433\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 51\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5156\n",
      "Batch 222 Loss: 0.4369\n",
      "Batch 444 Loss: 0.5937\n",
      "Batch 666 Loss: 0.5576\n",
      "Batch 888 Loss: 0.7668\n",
      "\n",
      "EPOCH 51 LOSS: 0.6434\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 52\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.0408\n",
      "Batch 222 Loss: 0.5707\n",
      "Batch 444 Loss: 0.7985\n",
      "Batch 666 Loss: 0.5031\n",
      "Batch 888 Loss: 0.5861\n",
      "\n",
      "EPOCH 52 LOSS: 0.6433\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    52: reducing learning rate of group 0 to 3.3354e-02.\n",
      "\n",
      "\u001b[1mEpoch 53\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5357\n",
      "Batch 222 Loss: 0.4935\n",
      "Batch 444 Loss: 0.5327\n",
      "Batch 666 Loss: 0.4894\n",
      "Batch 888 Loss: 0.5266\n",
      "\n",
      "EPOCH 53 LOSS: 0.6432\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 54\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8282\n",
      "Batch 222 Loss: 0.8017\n",
      "Batch 444 Loss: 0.4704\n",
      "Batch 666 Loss: 0.6440\n",
      "Batch 888 Loss: 0.5593\n",
      "\n",
      "EPOCH 54 LOSS: 0.6432\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 55\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6488\n",
      "Batch 222 Loss: 0.5513\n",
      "Batch 444 Loss: 0.7834\n",
      "Batch 666 Loss: 0.7802\n",
      "Batch 888 Loss: 0.5114\n",
      "\n",
      "EPOCH 55 LOSS: 0.6433\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    55: reducing learning rate of group 0 to 3.0019e-02.\n",
      "\n",
      "\u001b[1mEpoch 56\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5128\n",
      "Batch 222 Loss: 1.0427\n",
      "Batch 444 Loss: 0.5313\n",
      "Batch 666 Loss: 0.6992\n",
      "Batch 888 Loss: 1.0165\n",
      "\n",
      "EPOCH 56 LOSS: 0.6432\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 57\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6503\n",
      "Batch 222 Loss: 1.3337\n",
      "Batch 444 Loss: 0.6356\n",
      "Batch 666 Loss: 0.6205\n",
      "Batch 888 Loss: 1.0010\n",
      "\n",
      "EPOCH 57 LOSS: 0.6436\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 58\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7954\n",
      "Batch 222 Loss: 0.6478\n",
      "Batch 444 Loss: 0.5411\n",
      "Batch 666 Loss: 0.6987\n",
      "Batch 888 Loss: 0.5306\n",
      "\n",
      "EPOCH 58 LOSS: 0.6432\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    58: reducing learning rate of group 0 to 2.7017e-02.\n",
      "\n",
      "\u001b[1mEpoch 59\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5314\n",
      "Batch 222 Loss: 0.8176\n",
      "Batch 444 Loss: 0.8144\n",
      "Batch 666 Loss: 0.6208\n",
      "Batch 888 Loss: 0.4385\n",
      "\n",
      "EPOCH 59 LOSS: 0.6431\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 60\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.9906\n",
      "Batch 222 Loss: 0.6380\n",
      "Batch 444 Loss: 0.8402\n",
      "Batch 666 Loss: 0.5128\n",
      "Batch 888 Loss: 0.5585\n",
      "\n",
      "EPOCH 60 LOSS: 0.6429\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 61\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5620\n",
      "Batch 222 Loss: 0.5288\n",
      "Batch 444 Loss: 0.6708\n",
      "Batch 666 Loss: 0.4686\n",
      "Batch 888 Loss: 0.5816\n",
      "\n",
      "EPOCH 61 LOSS: 0.6433\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    61: reducing learning rate of group 0 to 2.4315e-02.\n",
      "\n",
      "\u001b[1mEpoch 62\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5293\n",
      "Batch 222 Loss: 0.6228\n",
      "Batch 444 Loss: 0.5616\n",
      "Batch 666 Loss: 0.5625\n",
      "Batch 888 Loss: 0.5462\n",
      "\n",
      "EPOCH 62 LOSS: 0.6429\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 63\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.9929\n",
      "Batch 222 Loss: 0.5577\n",
      "Batch 444 Loss: 0.6407\n",
      "Batch 666 Loss: 0.6422\n",
      "Batch 888 Loss: 0.5515\n",
      "\n",
      "EPOCH 63 LOSS: 0.6430\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 64\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6334\n",
      "Batch 222 Loss: 0.4892\n",
      "Batch 444 Loss: 0.5201\n",
      "Batch 666 Loss: 0.8332\n",
      "Batch 888 Loss: 0.6467\n",
      "\n",
      "EPOCH 64 LOSS: 0.6430\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    64: reducing learning rate of group 0 to 2.1884e-02.\n",
      "\n",
      "\u001b[1mEpoch 65\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8506\n",
      "Batch 222 Loss: 0.7158\n",
      "Batch 444 Loss: 0.5342\n",
      "Batch 666 Loss: 0.5263\n",
      "Batch 888 Loss: 0.5715\n",
      "\n",
      "EPOCH 65 LOSS: 0.6429\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 66\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5441\n",
      "Batch 222 Loss: 0.5811\n",
      "Batch 444 Loss: 0.5957\n",
      "Batch 666 Loss: 0.8245\n",
      "Batch 888 Loss: 0.5360\n",
      "\n",
      "EPOCH 66 LOSS: 0.6429\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 67\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5473\n",
      "Batch 222 Loss: 0.5314\n",
      "Batch 444 Loss: 0.6616\n",
      "Batch 666 Loss: 0.8057\n",
      "Batch 888 Loss: 0.4770\n",
      "\n",
      "EPOCH 67 LOSS: 0.6428\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    67: reducing learning rate of group 0 to 1.9695e-02.\n",
      "\n",
      "\u001b[1mEpoch 68\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6090\n",
      "Batch 222 Loss: 1.0588\n",
      "Batch 444 Loss: 0.5618\n",
      "Batch 666 Loss: 0.5707\n",
      "Batch 888 Loss: 0.6309\n",
      "\n",
      "EPOCH 68 LOSS: 0.6429\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 69\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4979\n",
      "Batch 222 Loss: 1.0542\n",
      "Batch 444 Loss: 0.5232\n",
      "Batch 666 Loss: 0.7987\n",
      "Batch 888 Loss: 0.6523\n",
      "\n",
      "EPOCH 69 LOSS: 0.6431\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 70\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7316\n",
      "Batch 222 Loss: 0.4820\n",
      "Batch 444 Loss: 0.5013\n",
      "Batch 666 Loss: 0.8368\n",
      "Batch 888 Loss: 0.5925\n",
      "\n",
      "EPOCH 70 LOSS: 0.6429\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    70: reducing learning rate of group 0 to 1.7726e-02.\n",
      "\n",
      "\u001b[1mEpoch 71\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.0229\n",
      "Batch 222 Loss: 0.5163\n",
      "Batch 444 Loss: 0.4565\n",
      "Batch 666 Loss: 0.5723\n",
      "Batch 888 Loss: 0.5168\n",
      "\n",
      "EPOCH 71 LOSS: 0.6429\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 72\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6828\n",
      "Batch 222 Loss: 0.4588\n",
      "Batch 444 Loss: 0.8272\n",
      "Batch 666 Loss: 0.7323\n",
      "Batch 888 Loss: 0.4557\n",
      "\n",
      "EPOCH 72 LOSS: 0.6429\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 73\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5463\n",
      "Batch 222 Loss: 0.6678\n",
      "Batch 444 Loss: 0.8306\n",
      "Batch 666 Loss: 0.7788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 888 Loss: 0.5774\n",
      "\n",
      "EPOCH 73 LOSS: 0.6429\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    73: reducing learning rate of group 0 to 1.5953e-02.\n",
      "\n",
      "\u001b[1mEpoch 74\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7559\n",
      "Batch 222 Loss: 0.5803\n",
      "Batch 444 Loss: 0.5087\n",
      "Batch 666 Loss: 0.5226\n",
      "Batch 888 Loss: 0.5133\n",
      "\n",
      "EPOCH 74 LOSS: 0.6429\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 75\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6443\n",
      "Batch 222 Loss: 0.4779\n",
      "Batch 444 Loss: 0.7026\n",
      "Batch 666 Loss: 0.5251\n",
      "Batch 888 Loss: 1.1018\n",
      "\n",
      "EPOCH 75 LOSS: 0.6431\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 76\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5662\n",
      "Batch 222 Loss: 0.8769\n",
      "Batch 444 Loss: 0.8016\n",
      "Batch 666 Loss: 0.6007\n",
      "Batch 888 Loss: 0.6057\n",
      "\n",
      "EPOCH 76 LOSS: 0.6429\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    76: reducing learning rate of group 0 to 1.4358e-02.\n",
      "\n",
      "\u001b[1mEpoch 77\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6362\n",
      "Batch 222 Loss: 0.6411\n",
      "Batch 444 Loss: 0.6095\n",
      "Batch 666 Loss: 0.5535\n",
      "Batch 888 Loss: 0.7551\n",
      "\n",
      "EPOCH 77 LOSS: 0.6429\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 78\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5168\n",
      "Batch 222 Loss: 0.5422\n",
      "Batch 444 Loss: 0.6749\n",
      "Batch 666 Loss: 0.4780\n",
      "Batch 888 Loss: 0.9112\n",
      "\n",
      "EPOCH 78 LOSS: 0.6431\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 79\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8203\n",
      "Batch 222 Loss: 0.7854\n",
      "Batch 444 Loss: 0.5582\n",
      "Batch 666 Loss: 0.5537\n",
      "Batch 888 Loss: 0.4849\n",
      "\n",
      "EPOCH 79 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    79: reducing learning rate of group 0 to 1.2922e-02.\n",
      "\n",
      "\u001b[1mEpoch 80\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.1910\n",
      "Batch 222 Loss: 0.5963\n",
      "Batch 444 Loss: 0.5658\n",
      "Batch 666 Loss: 0.7357\n",
      "Batch 888 Loss: 0.5504\n",
      "\n",
      "EPOCH 80 LOSS: 0.6428\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 81\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6198\n",
      "Batch 222 Loss: 0.7188\n",
      "Batch 444 Loss: 0.6823\n",
      "Batch 666 Loss: 0.8036\n",
      "Batch 888 Loss: 0.6819\n",
      "\n",
      "EPOCH 81 LOSS: 0.6428\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 82\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7474\n",
      "Batch 222 Loss: 0.6231\n",
      "Batch 444 Loss: 0.5537\n",
      "Batch 666 Loss: 0.6054\n",
      "Batch 888 Loss: 0.7160\n",
      "\n",
      "EPOCH 82 LOSS: 0.6429\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    82: reducing learning rate of group 0 to 1.1630e-02.\n",
      "\n",
      "\u001b[1mEpoch 83\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6743\n",
      "Batch 222 Loss: 0.6100\n",
      "Batch 444 Loss: 0.8063\n",
      "Batch 666 Loss: 0.5221\n",
      "Batch 888 Loss: 0.7201\n",
      "\n",
      "EPOCH 83 LOSS: 0.6428\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 84\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4902\n",
      "Batch 222 Loss: 0.5712\n",
      "Batch 444 Loss: 0.5652\n",
      "Batch 666 Loss: 0.6442\n",
      "Batch 888 Loss: 0.5134\n",
      "\n",
      "EPOCH 84 LOSS: 0.6428\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 85\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6196\n",
      "Batch 222 Loss: 0.4502\n",
      "Batch 444 Loss: 0.7003\n",
      "Batch 666 Loss: 0.5283\n",
      "Batch 888 Loss: 0.5405\n",
      "\n",
      "EPOCH 85 LOSS: 0.6428\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0467e-02.\n",
      "\n",
      "\u001b[1mEpoch 86\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6076\n",
      "Batch 222 Loss: 0.6070\n",
      "Batch 444 Loss: 0.7379\n",
      "Batch 666 Loss: 0.6125\n",
      "Batch 888 Loss: 0.7053\n",
      "\n",
      "EPOCH 86 LOSS: 0.6429\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 87\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5515\n",
      "Batch 222 Loss: 0.6589\n",
      "Batch 444 Loss: 0.5104\n",
      "Batch 666 Loss: 0.7440\n",
      "Batch 888 Loss: 0.4712\n",
      "\n",
      "EPOCH 87 LOSS: 0.6428\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 88\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5097\n",
      "Batch 222 Loss: 0.6251\n",
      "Batch 444 Loss: 0.4766\n",
      "Batch 666 Loss: 0.6593\n",
      "Batch 888 Loss: 0.6423\n",
      "\n",
      "EPOCH 88 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    88: reducing learning rate of group 0 to 9.4203e-03.\n",
      "\n",
      "\u001b[1mEpoch 89\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6339\n",
      "Batch 222 Loss: 0.7425\n",
      "Batch 444 Loss: 0.9812\n",
      "Batch 666 Loss: 0.4937\n",
      "Batch 888 Loss: 0.6536\n",
      "\n",
      "EPOCH 89 LOSS: 0.6428\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 90\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5075\n",
      "Batch 222 Loss: 0.5065\n",
      "Batch 444 Loss: 0.6221\n",
      "Batch 666 Loss: 0.6640\n",
      "Batch 888 Loss: 0.6406\n",
      "\n",
      "EPOCH 90 LOSS: 0.6428\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 91\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5462\n",
      "Batch 222 Loss: 0.9473\n",
      "Batch 444 Loss: 0.4995\n",
      "Batch 666 Loss: 0.7695\n",
      "Batch 888 Loss: 0.5812\n",
      "\n",
      "EPOCH 91 LOSS: 0.6428\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    91: reducing learning rate of group 0 to 8.4782e-03.\n",
      "\n",
      "\u001b[1mEpoch 92\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6729\n",
      "Batch 222 Loss: 0.5668\n",
      "Batch 444 Loss: 0.5452\n",
      "Batch 666 Loss: 0.4891\n",
      "Batch 888 Loss: 0.4803\n",
      "\n",
      "EPOCH 92 LOSS: 0.6428\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 93\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6728\n",
      "Batch 222 Loss: 0.4879\n",
      "Batch 444 Loss: 0.4867\n",
      "Batch 666 Loss: 0.5307\n",
      "Batch 888 Loss: 0.6983\n",
      "\n",
      "EPOCH 93 LOSS: 0.6428\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 94\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5239\n",
      "Batch 222 Loss: 0.5218\n",
      "Batch 444 Loss: 0.5260\n",
      "Batch 666 Loss: 0.6197\n",
      "Batch 888 Loss: 1.3713\n",
      "\n",
      "EPOCH 94 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    94: reducing learning rate of group 0 to 7.6304e-03.\n",
      "\n",
      "\u001b[1mEpoch 95\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6227\n",
      "Batch 222 Loss: 0.6593\n",
      "Batch 444 Loss: 0.6331\n",
      "Batch 666 Loss: 0.4888\n",
      "Batch 888 Loss: 0.6362\n",
      "\n",
      "EPOCH 95 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 96\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8073\n",
      "Batch 222 Loss: 0.5471\n",
      "Batch 444 Loss: 0.9132\n",
      "Batch 666 Loss: 0.5884\n",
      "Batch 888 Loss: 1.6526\n",
      "\n",
      "EPOCH 96 LOSS: 0.6428\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 97\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5299\n",
      "Batch 222 Loss: 0.5587\n",
      "Batch 444 Loss: 0.4587\n",
      "Batch 666 Loss: 0.5512\n",
      "Batch 888 Loss: 0.5069\n",
      "\n",
      "EPOCH 97 LOSS: 0.6428\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    97: reducing learning rate of group 0 to 6.8674e-03.\n",
      "\n",
      "\u001b[1mEpoch 98\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.9401\n",
      "Batch 222 Loss: 0.4668\n",
      "Batch 444 Loss: 0.4450\n",
      "Batch 666 Loss: 0.5544\n",
      "Batch 888 Loss: 0.5387\n",
      "\n",
      "EPOCH 98 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 99\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7282\n",
      "Batch 222 Loss: 0.6910\n",
      "Batch 444 Loss: 0.7034\n",
      "Batch 666 Loss: 0.5347\n",
      "Batch 888 Loss: 0.4535\n",
      "\n",
      "EPOCH 99 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 100\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.1022\n",
      "Batch 222 Loss: 0.6557\n",
      "Batch 444 Loss: 0.6947\n",
      "Batch 666 Loss: 0.5545\n",
      "Batch 888 Loss: 0.7853\n",
      "\n",
      "EPOCH 100 LOSS: 0.6428\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   100: reducing learning rate of group 0 to 6.1806e-03.\n",
      "\n",
      "\u001b[1mEpoch 101\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.1615\n",
      "Batch 222 Loss: 0.4898\n",
      "Batch 444 Loss: 0.5063\n",
      "Batch 666 Loss: 0.7096\n",
      "Batch 888 Loss: 1.0060\n",
      "\n",
      "EPOCH 101 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 102\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5159\n",
      "Batch 222 Loss: 0.7189\n",
      "Batch 444 Loss: 0.4771\n",
      "Batch 666 Loss: 0.6383\n",
      "Batch 888 Loss: 0.4095\n",
      "\n",
      "EPOCH 102 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 103\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7105\n",
      "Batch 222 Loss: 0.7639\n",
      "Batch 444 Loss: 0.6116\n",
      "Batch 666 Loss: 0.6676\n",
      "Batch 888 Loss: 0.5395\n",
      "\n",
      "EPOCH 103 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   103: reducing learning rate of group 0 to 5.5626e-03.\n",
      "\n",
      "\u001b[1mEpoch 104\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6382\n",
      "Batch 222 Loss: 0.5574\n",
      "Batch 444 Loss: 0.6850\n",
      "Batch 666 Loss: 0.5780\n",
      "Batch 888 Loss: 0.5854\n",
      "\n",
      "EPOCH 104 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 105\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7211\n",
      "Batch 222 Loss: 0.5301\n",
      "Batch 444 Loss: 0.5982\n",
      "Batch 666 Loss: 0.5945\n",
      "Batch 888 Loss: 0.4763\n",
      "\n",
      "EPOCH 105 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 106\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.1929\n",
      "Batch 222 Loss: 0.6036\n",
      "Batch 444 Loss: 0.4864\n",
      "Batch 666 Loss: 1.0750\n",
      "Batch 888 Loss: 0.5339\n",
      "\n",
      "EPOCH 106 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   106: reducing learning rate of group 0 to 5.0063e-03.\n",
      "\n",
      "\u001b[1mEpoch 107\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5107\n",
      "Batch 222 Loss: 0.6150\n",
      "Batch 444 Loss: 0.9068\n",
      "Batch 666 Loss: 0.5377\n",
      "Batch 888 Loss: 1.3366\n",
      "\n",
      "EPOCH 107 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 108\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5556\n",
      "Batch 222 Loss: 0.5353\n",
      "Batch 444 Loss: 0.5160\n",
      "Batch 666 Loss: 0.6360\n",
      "Batch 888 Loss: 0.4882\n",
      "\n",
      "EPOCH 108 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 109\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4469\n",
      "Batch 222 Loss: 0.5280\n",
      "Batch 444 Loss: 0.7778\n",
      "Batch 666 Loss: 1.8594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 888 Loss: 0.7435\n",
      "\n",
      "EPOCH 109 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   109: reducing learning rate of group 0 to 4.5057e-03.\n",
      "\n",
      "\u001b[1mEpoch 110\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.9641\n",
      "Batch 222 Loss: 0.7151\n",
      "Batch 444 Loss: 0.5050\n",
      "Batch 666 Loss: 0.7241\n",
      "Batch 888 Loss: 0.4268\n",
      "\n",
      "EPOCH 110 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 111\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7105\n",
      "Batch 222 Loss: 0.5884\n",
      "Batch 444 Loss: 0.4775\n",
      "Batch 666 Loss: 0.7176\n",
      "Batch 888 Loss: 0.5570\n",
      "\n",
      "EPOCH 111 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 112\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6266\n",
      "Batch 222 Loss: 0.6988\n",
      "Batch 444 Loss: 0.6759\n",
      "Batch 666 Loss: 0.5051\n",
      "Batch 888 Loss: 0.4682\n",
      "\n",
      "EPOCH 112 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   112: reducing learning rate of group 0 to 4.0551e-03.\n",
      "\n",
      "\u001b[1mEpoch 113\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5975\n",
      "Batch 222 Loss: 0.4967\n",
      "Batch 444 Loss: 0.5474\n",
      "Batch 666 Loss: 0.5409\n",
      "Batch 888 Loss: 0.4442\n",
      "\n",
      "EPOCH 113 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 114\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4816\n",
      "Batch 222 Loss: 0.6529\n",
      "Batch 444 Loss: 0.4649\n",
      "Batch 666 Loss: 0.4975\n",
      "Batch 888 Loss: 0.6278\n",
      "\n",
      "EPOCH 114 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 115\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4872\n",
      "Batch 222 Loss: 0.5724\n",
      "Batch 444 Loss: 0.5136\n",
      "Batch 666 Loss: 0.9783\n",
      "Batch 888 Loss: 0.8697\n",
      "\n",
      "EPOCH 115 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   115: reducing learning rate of group 0 to 3.6496e-03.\n",
      "\n",
      "\u001b[1mEpoch 116\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6648\n",
      "Batch 222 Loss: 0.5616\n",
      "Batch 444 Loss: 0.7047\n",
      "Batch 666 Loss: 1.0021\n",
      "Batch 888 Loss: 0.4686\n",
      "\n",
      "EPOCH 116 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 117\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5295\n",
      "Batch 222 Loss: 0.6644\n",
      "Batch 444 Loss: 0.8348\n",
      "Batch 666 Loss: 0.5127\n",
      "Batch 888 Loss: 0.8392\n",
      "\n",
      "EPOCH 117 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 118\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5092\n",
      "Batch 222 Loss: 0.6499\n",
      "Batch 444 Loss: 0.5316\n",
      "Batch 666 Loss: 0.5464\n",
      "Batch 888 Loss: 0.4297\n",
      "\n",
      "EPOCH 118 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   118: reducing learning rate of group 0 to 3.2846e-03.\n",
      "\n",
      "\u001b[1mEpoch 119\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5417\n",
      "Batch 222 Loss: 0.5702\n",
      "Batch 444 Loss: 0.6754\n",
      "Batch 666 Loss: 0.6807\n",
      "Batch 888 Loss: 0.5090\n",
      "\n",
      "EPOCH 119 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 120\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5942\n",
      "Batch 222 Loss: 0.7533\n",
      "Batch 444 Loss: 0.6227\n",
      "Batch 666 Loss: 0.5677\n",
      "Batch 888 Loss: 0.6708\n",
      "\n",
      "EPOCH 120 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 121\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.9397\n",
      "Batch 222 Loss: 0.4896\n",
      "Batch 444 Loss: 0.4812\n",
      "Batch 666 Loss: 0.9494\n",
      "Batch 888 Loss: 0.5826\n",
      "\n",
      "EPOCH 121 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   121: reducing learning rate of group 0 to 2.9562e-03.\n",
      "\n",
      "\u001b[1mEpoch 122\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5280\n",
      "Batch 222 Loss: 0.6856\n",
      "Batch 444 Loss: 0.9258\n",
      "Batch 666 Loss: 0.7104\n",
      "Batch 888 Loss: 0.6148\n",
      "\n",
      "EPOCH 122 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 123\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6498\n",
      "Batch 222 Loss: 0.6443\n",
      "Batch 444 Loss: 0.6184\n",
      "Batch 666 Loss: 0.5666\n",
      "Batch 888 Loss: 0.6143\n",
      "\n",
      "EPOCH 123 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 124\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4972\n",
      "Batch 222 Loss: 1.8148\n",
      "Batch 444 Loss: 0.5513\n",
      "Batch 666 Loss: 0.5132\n",
      "Batch 888 Loss: 0.8756\n",
      "\n",
      "EPOCH 124 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   124: reducing learning rate of group 0 to 2.6606e-03.\n",
      "\n",
      "\u001b[1mEpoch 125\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7759\n",
      "Batch 222 Loss: 0.5839\n",
      "Batch 444 Loss: 0.5465\n",
      "Batch 666 Loss: 0.8111\n",
      "Batch 888 Loss: 0.5290\n",
      "\n",
      "EPOCH 125 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 126\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5081\n",
      "Batch 222 Loss: 0.5697\n",
      "Batch 444 Loss: 0.5950\n",
      "Batch 666 Loss: 0.6086\n",
      "Batch 888 Loss: 0.5601\n",
      "\n",
      "EPOCH 126 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 127\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7001\n",
      "Batch 222 Loss: 0.5450\n",
      "Batch 444 Loss: 0.5366\n",
      "Batch 666 Loss: 0.9897\n",
      "Batch 888 Loss: 0.4967\n",
      "\n",
      "EPOCH 127 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   127: reducing learning rate of group 0 to 2.3945e-03.\n",
      "\n",
      "\u001b[1mEpoch 128\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6323\n",
      "Batch 222 Loss: 0.7730\n",
      "Batch 444 Loss: 0.6077\n",
      "Batch 666 Loss: 0.5296\n",
      "Batch 888 Loss: 0.9655\n",
      "\n",
      "EPOCH 128 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 129\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5624\n",
      "Batch 222 Loss: 0.5328\n",
      "Batch 444 Loss: 0.6366\n",
      "Batch 666 Loss: 0.5792\n",
      "Batch 888 Loss: 0.5066\n",
      "\n",
      "EPOCH 129 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 130\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5195\n",
      "Batch 222 Loss: 0.6617\n",
      "Batch 444 Loss: 0.6534\n",
      "Batch 666 Loss: 0.4649\n",
      "Batch 888 Loss: 0.5151\n",
      "\n",
      "EPOCH 130 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   130: reducing learning rate of group 0 to 2.1551e-03.\n",
      "\n",
      "\u001b[1mEpoch 131\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5631\n",
      "Batch 222 Loss: 1.2999\n",
      "Batch 444 Loss: 0.5409\n",
      "Batch 666 Loss: 0.5910\n",
      "Batch 888 Loss: 0.9694\n",
      "\n",
      "EPOCH 131 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 132\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.2553\n",
      "Batch 222 Loss: 1.2472\n",
      "Batch 444 Loss: 0.5073\n",
      "Batch 666 Loss: 0.6302\n",
      "Batch 888 Loss: 0.6559\n",
      "\n",
      "EPOCH 132 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 133\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5331\n",
      "Batch 222 Loss: 0.8965\n",
      "Batch 444 Loss: 0.5422\n",
      "Batch 666 Loss: 0.5642\n",
      "Batch 888 Loss: 0.4698\n",
      "\n",
      "EPOCH 133 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   133: reducing learning rate of group 0 to 1.9395e-03.\n",
      "\n",
      "\u001b[1mEpoch 134\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7059\n",
      "Batch 222 Loss: 0.5107\n",
      "Batch 444 Loss: 0.5971\n",
      "Batch 666 Loss: 0.4516\n",
      "Batch 888 Loss: 0.4718\n",
      "\n",
      "EPOCH 134 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 135\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6186\n",
      "Batch 222 Loss: 0.5412\n",
      "Batch 444 Loss: 0.4984\n",
      "Batch 666 Loss: 0.5028\n",
      "Batch 888 Loss: 0.4687\n",
      "\n",
      "EPOCH 135 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 136\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8202\n",
      "Batch 222 Loss: 0.6078\n",
      "Batch 444 Loss: 0.8897\n",
      "Batch 666 Loss: 0.6387\n",
      "Batch 888 Loss: 0.5673\n",
      "\n",
      "EPOCH 136 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   136: reducing learning rate of group 0 to 1.7456e-03.\n",
      "\n",
      "\u001b[1mEpoch 137\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5101\n",
      "Batch 222 Loss: 0.7217\n",
      "Batch 444 Loss: 0.4438\n",
      "Batch 666 Loss: 0.6488\n",
      "Batch 888 Loss: 0.5157\n",
      "\n",
      "EPOCH 137 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 138\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5948\n",
      "Batch 222 Loss: 0.5591\n",
      "Batch 444 Loss: 0.4596\n",
      "Batch 666 Loss: 0.5330\n",
      "Batch 888 Loss: 0.4970\n",
      "\n",
      "EPOCH 138 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 139\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8358\n",
      "Batch 222 Loss: 0.5147\n",
      "Batch 444 Loss: 0.5169\n",
      "Batch 666 Loss: 0.6515\n",
      "Batch 888 Loss: 0.6242\n",
      "\n",
      "EPOCH 139 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   139: reducing learning rate of group 0 to 1.5710e-03.\n",
      "\n",
      "\u001b[1mEpoch 140\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6974\n",
      "Batch 222 Loss: 0.5762\n",
      "Batch 444 Loss: 0.5891\n",
      "Batch 666 Loss: 0.8040\n",
      "Batch 888 Loss: 0.3952\n",
      "\n",
      "EPOCH 140 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 141\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5601\n",
      "Batch 222 Loss: 0.5484\n",
      "Batch 444 Loss: 0.7250\n",
      "Batch 666 Loss: 0.4440\n",
      "Batch 888 Loss: 0.7188\n",
      "\n",
      "EPOCH 141 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 142\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.9796\n",
      "Batch 222 Loss: 0.6909\n",
      "Batch 444 Loss: 0.5709\n",
      "Batch 666 Loss: 0.5604\n",
      "Batch 888 Loss: 0.9404\n",
      "\n",
      "EPOCH 142 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   142: reducing learning rate of group 0 to 1.4139e-03.\n",
      "\n",
      "\u001b[1mEpoch 143\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5326\n",
      "Batch 222 Loss: 0.8015\n",
      "Batch 444 Loss: 0.5679\n",
      "Batch 666 Loss: 0.5246\n",
      "Batch 888 Loss: 0.5537\n",
      "\n",
      "EPOCH 143 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 144\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6528\n",
      "Batch 222 Loss: 0.9043\n",
      "Batch 444 Loss: 1.2756\n",
      "Batch 666 Loss: 0.8875\n",
      "Batch 888 Loss: 0.4331\n",
      "\n",
      "EPOCH 144 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 145\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 222 Loss: 0.5621\n",
      "Batch 444 Loss: 0.5781\n",
      "Batch 666 Loss: 0.4696\n",
      "Batch 888 Loss: 0.5828\n",
      "\n",
      "EPOCH 145 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   145: reducing learning rate of group 0 to 1.2725e-03.\n",
      "\n",
      "\u001b[1mEpoch 146\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5743\n",
      "Batch 222 Loss: 1.1410\n",
      "Batch 444 Loss: 0.5185\n",
      "Batch 666 Loss: 0.5530\n",
      "Batch 888 Loss: 0.5931\n",
      "\n",
      "EPOCH 146 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 147\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6542\n",
      "Batch 222 Loss: 0.4474\n",
      "Batch 444 Loss: 0.5660\n",
      "Batch 666 Loss: 0.5288\n",
      "Batch 888 Loss: 1.0083\n",
      "\n",
      "EPOCH 147 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 148\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6147\n",
      "Batch 222 Loss: 0.5847\n",
      "Batch 444 Loss: 0.7350\n",
      "Batch 666 Loss: 0.7062\n",
      "Batch 888 Loss: 0.5060\n",
      "\n",
      "EPOCH 148 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   148: reducing learning rate of group 0 to 1.1453e-03.\n",
      "\n",
      "\u001b[1mEpoch 149\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6205\n",
      "Batch 222 Loss: 0.6583\n",
      "Batch 444 Loss: 0.5220\n",
      "Batch 666 Loss: 0.8312\n",
      "Batch 888 Loss: 0.7415\n",
      "\n",
      "EPOCH 149 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 150\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5921\n",
      "Batch 222 Loss: 0.5766\n",
      "Batch 444 Loss: 0.5367\n",
      "Batch 666 Loss: 0.5082\n",
      "Batch 888 Loss: 0.5562\n",
      "\n",
      "EPOCH 150 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 151\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6456\n",
      "Batch 222 Loss: 0.4591\n",
      "Batch 444 Loss: 0.5610\n",
      "Batch 666 Loss: 0.7011\n",
      "Batch 888 Loss: 0.5746\n",
      "\n",
      "EPOCH 151 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0308e-03.\n",
      "\n",
      "\u001b[1mEpoch 152\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4778\n",
      "Batch 222 Loss: 0.5663\n",
      "Batch 444 Loss: 0.5427\n",
      "Batch 666 Loss: 0.5702\n",
      "Batch 888 Loss: 0.5185\n",
      "\n",
      "EPOCH 152 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 153\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5262\n",
      "Batch 222 Loss: 0.6930\n",
      "Batch 444 Loss: 0.7726\n",
      "Batch 666 Loss: 0.7931\n",
      "Batch 888 Loss: 0.6096\n",
      "\n",
      "EPOCH 153 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 154\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6195\n",
      "Batch 222 Loss: 0.5798\n",
      "Batch 444 Loss: 0.5938\n",
      "Batch 666 Loss: 1.5486\n",
      "Batch 888 Loss: 0.5317\n",
      "\n",
      "EPOCH 154 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   154: reducing learning rate of group 0 to 9.2768e-04.\n",
      "\n",
      "\u001b[1mEpoch 155\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5571\n",
      "Batch 222 Loss: 1.1168\n",
      "Batch 444 Loss: 0.5956\n",
      "Batch 666 Loss: 0.5989\n",
      "Batch 888 Loss: 1.0699\n",
      "\n",
      "EPOCH 155 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 156\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7270\n",
      "Batch 222 Loss: 0.6332\n",
      "Batch 444 Loss: 0.4763\n",
      "Batch 666 Loss: 0.5132\n",
      "Batch 888 Loss: 0.5049\n",
      "\n",
      "EPOCH 156 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 157\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6553\n",
      "Batch 222 Loss: 0.6179\n",
      "Batch 444 Loss: 0.5607\n",
      "Batch 666 Loss: 0.5075\n",
      "Batch 888 Loss: 0.6619\n",
      "\n",
      "EPOCH 157 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   157: reducing learning rate of group 0 to 8.3491e-04.\n",
      "\n",
      "\u001b[1mEpoch 158\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6024\n",
      "Batch 222 Loss: 0.4963\n",
      "Batch 444 Loss: 0.5517\n",
      "Batch 666 Loss: 0.5698\n",
      "Batch 888 Loss: 1.0115\n",
      "\n",
      "EPOCH 158 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 159\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5885\n",
      "Batch 222 Loss: 0.5661\n",
      "Batch 444 Loss: 0.5495\n",
      "Batch 666 Loss: 0.6275\n",
      "Batch 888 Loss: 0.5429\n",
      "\n",
      "EPOCH 159 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 160\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6046\n",
      "Batch 222 Loss: 0.5064\n",
      "Batch 444 Loss: 0.6841\n",
      "Batch 666 Loss: 0.4652\n",
      "Batch 888 Loss: 0.6277\n",
      "\n",
      "EPOCH 160 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   160: reducing learning rate of group 0 to 7.5142e-04.\n",
      "\n",
      "\u001b[1mEpoch 161\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.2528\n",
      "Batch 222 Loss: 0.5910\n",
      "Batch 444 Loss: 0.6793\n",
      "Batch 666 Loss: 0.4958\n",
      "Batch 888 Loss: 1.5350\n",
      "\n",
      "EPOCH 161 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 162\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7050\n",
      "Batch 222 Loss: 0.6793\n",
      "Batch 444 Loss: 0.5801\n",
      "Batch 666 Loss: 0.4955\n",
      "Batch 888 Loss: 0.5975\n",
      "\n",
      "EPOCH 162 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 163\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5474\n",
      "Batch 222 Loss: 0.5566\n",
      "Batch 444 Loss: 0.5395\n",
      "Batch 666 Loss: 0.6093\n",
      "Batch 888 Loss: 0.9591\n",
      "\n",
      "EPOCH 163 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   163: reducing learning rate of group 0 to 6.7628e-04.\n",
      "\n",
      "\u001b[1mEpoch 164\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5601\n",
      "Batch 222 Loss: 0.5301\n",
      "Batch 444 Loss: 0.5049\n",
      "Batch 666 Loss: 0.7930\n",
      "Batch 888 Loss: 0.5434\n",
      "\n",
      "EPOCH 164 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 165\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8166\n",
      "Batch 222 Loss: 0.9300\n",
      "Batch 444 Loss: 1.5729\n",
      "Batch 666 Loss: 0.5428\n",
      "Batch 888 Loss: 0.6068\n",
      "\n",
      "EPOCH 165 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 166\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5830\n",
      "Batch 222 Loss: 0.6785\n",
      "Batch 444 Loss: 0.4780\n",
      "Batch 666 Loss: 0.7127\n",
      "Batch 888 Loss: 0.6470\n",
      "\n",
      "EPOCH 166 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   166: reducing learning rate of group 0 to 6.0865e-04.\n",
      "\n",
      "\u001b[1mEpoch 167\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5103\n",
      "Batch 222 Loss: 0.5718\n",
      "Batch 444 Loss: 0.5328\n",
      "Batch 666 Loss: 0.5818\n",
      "Batch 888 Loss: 0.4928\n",
      "\n",
      "EPOCH 167 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 168\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7651\n",
      "Batch 222 Loss: 0.5527\n",
      "Batch 444 Loss: 0.5823\n",
      "Batch 666 Loss: 0.5031\n",
      "Batch 888 Loss: 0.5428\n",
      "\n",
      "EPOCH 168 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 169\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5885\n",
      "Batch 222 Loss: 0.8665\n",
      "Batch 444 Loss: 0.5905\n",
      "Batch 666 Loss: 0.6071\n",
      "Batch 888 Loss: 1.5174\n",
      "\n",
      "EPOCH 169 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   169: reducing learning rate of group 0 to 5.4779e-04.\n",
      "\n",
      "\u001b[1mEpoch 170\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5184\n",
      "Batch 222 Loss: 0.5394\n",
      "Batch 444 Loss: 0.6295\n",
      "Batch 666 Loss: 0.5723\n",
      "Batch 888 Loss: 0.8623\n",
      "\n",
      "EPOCH 170 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 171\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5896\n",
      "Batch 222 Loss: 0.5897\n",
      "Batch 444 Loss: 0.6156\n",
      "Batch 666 Loss: 0.6132\n",
      "Batch 888 Loss: 0.4954\n",
      "\n",
      "EPOCH 171 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 172\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6247\n",
      "Batch 222 Loss: 0.5349\n",
      "Batch 444 Loss: 0.5589\n",
      "Batch 666 Loss: 0.5168\n",
      "Batch 888 Loss: 0.7014\n",
      "\n",
      "EPOCH 172 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   172: reducing learning rate of group 0 to 4.9301e-04.\n",
      "\n",
      "\u001b[1mEpoch 173\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4576\n",
      "Batch 222 Loss: 1.2020\n",
      "Batch 444 Loss: 0.6201\n",
      "Batch 666 Loss: 0.5855\n",
      "Batch 888 Loss: 0.4518\n",
      "\n",
      "EPOCH 173 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 174\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6272\n",
      "Batch 222 Loss: 0.4878\n",
      "Batch 444 Loss: 0.6713\n",
      "Batch 666 Loss: 0.5249\n",
      "Batch 888 Loss: 0.6104\n",
      "\n",
      "EPOCH 174 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 175\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4876\n",
      "Batch 222 Loss: 0.5431\n",
      "Batch 444 Loss: 0.5754\n",
      "Batch 666 Loss: 0.9005\n",
      "Batch 888 Loss: 0.4878\n",
      "\n",
      "EPOCH 175 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   175: reducing learning rate of group 0 to 4.4371e-04.\n",
      "\n",
      "\u001b[1mEpoch 176\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5679\n",
      "Batch 222 Loss: 0.4887\n",
      "Batch 444 Loss: 0.7904\n",
      "Batch 666 Loss: 0.6507\n",
      "Batch 888 Loss: 0.5352\n",
      "\n",
      "EPOCH 176 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 177\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7426\n",
      "Batch 222 Loss: 0.7450\n",
      "Batch 444 Loss: 0.6384\n",
      "Batch 666 Loss: 0.6299\n",
      "Batch 888 Loss: 0.5633\n",
      "\n",
      "EPOCH 177 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 178\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5330\n",
      "Batch 222 Loss: 0.5773\n",
      "Batch 444 Loss: 0.6561\n",
      "Batch 666 Loss: 1.2800\n",
      "Batch 888 Loss: 0.7643\n",
      "\n",
      "EPOCH 178 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   178: reducing learning rate of group 0 to 3.9934e-04.\n",
      "\n",
      "\u001b[1mEpoch 179\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5511\n",
      "Batch 222 Loss: 0.7377\n",
      "Batch 444 Loss: 0.5067\n",
      "Batch 666 Loss: 0.5187\n",
      "Batch 888 Loss: 0.4688\n",
      "\n",
      "EPOCH 179 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 180\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4953\n",
      "Batch 222 Loss: 0.9082\n",
      "Batch 444 Loss: 0.4607\n",
      "Batch 666 Loss: 0.5056\n",
      "Batch 888 Loss: 0.5644\n",
      "\n",
      "EPOCH 180 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 181\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 222 Loss: 0.6731\n",
      "Batch 444 Loss: 0.6053\n",
      "Batch 666 Loss: 0.5548\n",
      "Batch 888 Loss: 0.4276\n",
      "\n",
      "EPOCH 181 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   181: reducing learning rate of group 0 to 3.5940e-04.\n",
      "\n",
      "\u001b[1mEpoch 182\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5821\n",
      "Batch 222 Loss: 0.6065\n",
      "Batch 444 Loss: 1.4900\n",
      "Batch 666 Loss: 0.5691\n",
      "Batch 888 Loss: 0.9073\n",
      "\n",
      "EPOCH 182 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 183\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6144\n",
      "Batch 222 Loss: 0.5540\n",
      "Batch 444 Loss: 0.6311\n",
      "Batch 666 Loss: 0.5759\n",
      "Batch 888 Loss: 0.6574\n",
      "\n",
      "EPOCH 183 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 184\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.9939\n",
      "Batch 222 Loss: 0.5264\n",
      "Batch 444 Loss: 0.6228\n",
      "Batch 666 Loss: 0.7631\n",
      "Batch 888 Loss: 0.4634\n",
      "\n",
      "EPOCH 184 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   184: reducing learning rate of group 0 to 3.2346e-04.\n",
      "\n",
      "\u001b[1mEpoch 185\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6686\n",
      "Batch 222 Loss: 0.5573\n",
      "Batch 444 Loss: 0.5228\n",
      "Batch 666 Loss: 0.5562\n",
      "Batch 888 Loss: 0.4953\n",
      "\n",
      "EPOCH 185 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 186\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5514\n",
      "Batch 222 Loss: 0.6777\n",
      "Batch 444 Loss: 0.7996\n",
      "Batch 666 Loss: 0.5153\n",
      "Batch 888 Loss: 0.5547\n",
      "\n",
      "EPOCH 186 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 187\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8889\n",
      "Batch 222 Loss: 0.5287\n",
      "Batch 444 Loss: 0.4696\n",
      "Batch 666 Loss: 0.5148\n",
      "Batch 888 Loss: 0.5249\n",
      "\n",
      "EPOCH 187 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   187: reducing learning rate of group 0 to 2.9112e-04.\n",
      "\n",
      "\u001b[1mEpoch 188\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5161\n",
      "Batch 222 Loss: 0.5346\n",
      "Batch 444 Loss: 0.4920\n",
      "Batch 666 Loss: 0.6429\n",
      "Batch 888 Loss: 0.4672\n",
      "\n",
      "EPOCH 188 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 189\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6205\n",
      "Batch 222 Loss: 0.6765\n",
      "Batch 444 Loss: 0.4766\n",
      "Batch 666 Loss: 0.6064\n",
      "Batch 888 Loss: 0.6317\n",
      "\n",
      "EPOCH 189 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 190\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5911\n",
      "Batch 222 Loss: 0.8218\n",
      "Batch 444 Loss: 0.5216\n",
      "Batch 666 Loss: 0.4995\n",
      "Batch 888 Loss: 0.7189\n",
      "\n",
      "EPOCH 190 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   190: reducing learning rate of group 0 to 2.6200e-04.\n",
      "\n",
      "\u001b[1mEpoch 191\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7491\n",
      "Batch 222 Loss: 0.5277\n",
      "Batch 444 Loss: 0.6201\n",
      "Batch 666 Loss: 0.5128\n",
      "Batch 888 Loss: 0.5317\n",
      "\n",
      "EPOCH 191 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 192\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5930\n",
      "Batch 222 Loss: 0.5502\n",
      "Batch 444 Loss: 0.8811\n",
      "Batch 666 Loss: 0.6809\n",
      "Batch 888 Loss: 0.5101\n",
      "\n",
      "EPOCH 192 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 193\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4908\n",
      "Batch 222 Loss: 0.6229\n",
      "Batch 444 Loss: 0.6808\n",
      "Batch 666 Loss: 0.5443\n",
      "Batch 888 Loss: 0.7813\n",
      "\n",
      "EPOCH 193 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   193: reducing learning rate of group 0 to 2.3580e-04.\n",
      "\n",
      "\u001b[1mEpoch 194\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5246\n",
      "Batch 222 Loss: 0.6924\n",
      "Batch 444 Loss: 0.8456\n",
      "Batch 666 Loss: 0.5781\n",
      "Batch 888 Loss: 0.5867\n",
      "\n",
      "EPOCH 194 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 195\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6712\n",
      "Batch 222 Loss: 0.8615\n",
      "Batch 444 Loss: 0.4401\n",
      "Batch 666 Loss: 0.4769\n",
      "Batch 888 Loss: 0.4607\n",
      "\n",
      "EPOCH 195 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 196\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5506\n",
      "Batch 222 Loss: 0.6524\n",
      "Batch 444 Loss: 0.8334\n",
      "Batch 666 Loss: 0.6529\n",
      "Batch 888 Loss: 0.4951\n",
      "\n",
      "EPOCH 196 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   196: reducing learning rate of group 0 to 2.1222e-04.\n",
      "\n",
      "\u001b[1mEpoch 197\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6892\n",
      "Batch 222 Loss: 0.5759\n",
      "Batch 444 Loss: 0.9991\n",
      "Batch 666 Loss: 0.5195\n",
      "Batch 888 Loss: 0.5019\n",
      "\n",
      "EPOCH 197 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 198\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5658\n",
      "Batch 222 Loss: 0.5084\n",
      "Batch 444 Loss: 0.4789\n",
      "Batch 666 Loss: 0.5075\n",
      "Batch 888 Loss: 0.5755\n",
      "\n",
      "EPOCH 198 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 199\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6281\n",
      "Batch 222 Loss: 0.7745\n",
      "Batch 444 Loss: 0.6013\n",
      "Batch 666 Loss: 0.9385\n",
      "Batch 888 Loss: 0.5955\n",
      "\n",
      "EPOCH 199 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   199: reducing learning rate of group 0 to 1.9100e-04.\n",
      "\n",
      "\u001b[1mEpoch 200\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5151\n",
      "Batch 222 Loss: 0.5608\n",
      "Batch 444 Loss: 0.4833\n",
      "Batch 666 Loss: 0.4964\n",
      "Batch 888 Loss: 0.7850\n",
      "\n",
      "EPOCH 200 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 201\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5696\n",
      "Batch 222 Loss: 0.6085\n",
      "Batch 444 Loss: 0.7304\n",
      "Batch 666 Loss: 0.7721\n",
      "Batch 888 Loss: 0.5272\n",
      "\n",
      "EPOCH 201 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 202\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6929\n",
      "Batch 222 Loss: 0.5811\n",
      "Batch 444 Loss: 1.0067\n",
      "Batch 666 Loss: 0.5157\n",
      "Batch 888 Loss: 1.0003\n",
      "\n",
      "EPOCH 202 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   202: reducing learning rate of group 0 to 1.7190e-04.\n",
      "\n",
      "\u001b[1mEpoch 203\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7184\n",
      "Batch 222 Loss: 0.7353\n",
      "Batch 444 Loss: 0.6313\n",
      "Batch 666 Loss: 0.4686\n",
      "Batch 888 Loss: 0.4970\n",
      "\n",
      "EPOCH 203 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 204\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7391\n",
      "Batch 222 Loss: 0.9443\n",
      "Batch 444 Loss: 0.6296\n",
      "Batch 666 Loss: 0.6817\n",
      "Batch 888 Loss: 0.5590\n",
      "\n",
      "EPOCH 204 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 205\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8798\n",
      "Batch 222 Loss: 0.6391\n",
      "Batch 444 Loss: 0.7029\n",
      "Batch 666 Loss: 0.5539\n",
      "Batch 888 Loss: 0.4569\n",
      "\n",
      "EPOCH 205 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   205: reducing learning rate of group 0 to 1.5471e-04.\n",
      "\n",
      "\u001b[1mEpoch 206\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6197\n",
      "Batch 222 Loss: 0.4713\n",
      "Batch 444 Loss: 0.5172\n",
      "Batch 666 Loss: 0.6167\n",
      "Batch 888 Loss: 1.6494\n",
      "\n",
      "EPOCH 206 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 207\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6713\n",
      "Batch 222 Loss: 0.5107\n",
      "Batch 444 Loss: 0.5318\n",
      "Batch 666 Loss: 0.5407\n",
      "Batch 888 Loss: 0.6131\n",
      "\n",
      "EPOCH 207 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 208\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5581\n",
      "Batch 222 Loss: 0.5035\n",
      "Batch 444 Loss: 0.8883\n",
      "Batch 666 Loss: 0.5710\n",
      "Batch 888 Loss: 0.5016\n",
      "\n",
      "EPOCH 208 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   208: reducing learning rate of group 0 to 1.3924e-04.\n",
      "\n",
      "\u001b[1mEpoch 209\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4612\n",
      "Batch 222 Loss: 0.5892\n",
      "Batch 444 Loss: 0.6982\n",
      "Batch 666 Loss: 0.6566\n",
      "Batch 888 Loss: 0.5555\n",
      "\n",
      "EPOCH 209 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 210\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6670\n",
      "Batch 222 Loss: 0.9672\n",
      "Batch 444 Loss: 0.6470\n",
      "Batch 666 Loss: 0.5308\n",
      "Batch 888 Loss: 0.8095\n",
      "\n",
      "EPOCH 210 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 211\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7464\n",
      "Batch 222 Loss: 0.4643\n",
      "Batch 444 Loss: 0.9120\n",
      "Batch 666 Loss: 0.8223\n",
      "Batch 888 Loss: 0.5806\n",
      "\n",
      "EPOCH 211 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   211: reducing learning rate of group 0 to 1.2532e-04.\n",
      "\n",
      "\u001b[1mEpoch 212\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5316\n",
      "Batch 222 Loss: 0.6097\n",
      "Batch 444 Loss: 0.6091\n",
      "Batch 666 Loss: 0.5440\n",
      "Batch 888 Loss: 0.5431\n",
      "\n",
      "EPOCH 212 LOSS: 0.6427\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 213\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6212\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-5555341c64eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                    \u001b[0mvalidation_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_torch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                    \u001b[0mlr_rate_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                    y_val=y_val)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-b131393f30ae>\u001b[0m in \u001b[0;36mtrain_autoencoder\u001b[0;34m(model, dataset, loss_func, optimizer, epochs, batch_size, validation_tensor, y_val, lr_rate_scheduler, noise_factor, random_seed, MSE_stopping_threshold)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\033[1mEpoch {}\\033[0m\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnoise_factor\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.RMSprop(ae2.parameters(), lr=0.2, weight_decay=0.25)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.9, patience=2, verbose=True)\n",
    "train_autoencoder(model=ae2,\n",
    "                   dataset=output1,\n",
    "                   loss_func=loss_func,\n",
    "                   optimizer=optimizer,\n",
    "                   batch_size=256,\n",
    "                   epochs=500,\n",
    "                   validation_tensor=val_torch,\n",
    "                   lr_rate_scheduler=scheduler,\n",
    "                   y_val=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "output2 = ae2(output1)\n",
    "train_output2 = ae2(train_output1)\n",
    "val_output2 = ae2(val_output1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder III: Denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae3 = AutoEncoder(n_features,n_features)\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mEpoch 1\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8330\n",
      "Batch 111 Loss: 0.2692\n",
      "Batch 222 Loss: 0.1376\n",
      "Batch 333 Loss: 0.1046\n",
      "Batch 444 Loss: 0.0595\n",
      "\n",
      "EPOCH 1 LOSS: 0.0040\n",
      "\n",
      "Reconstruction error recall: 0.0198\n",
      "\n",
      "\u001b[1mEpoch 2\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0651\n",
      "Batch 111 Loss: 0.0738\n",
      "Batch 222 Loss: 0.0679\n",
      "Batch 333 Loss: 0.0576\n",
      "Batch 444 Loss: 0.0553\n",
      "\n",
      "EPOCH 2 LOSS: 0.0004\n",
      "\n",
      "Reconstruction error recall 0.0198\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 3\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0536\n",
      "Batch 111 Loss: 0.0546\n",
      "Batch 222 Loss: 0.0558\n",
      "Batch 333 Loss: 0.2186\n",
      "Batch 444 Loss: 0.0683\n",
      "\n",
      "EPOCH 3 LOSS: 0.0004\n",
      "\n",
      "Reconstruction error recall 0.0198\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 4\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0587\n",
      "Batch 111 Loss: 0.0593\n",
      "Batch 222 Loss: 0.0629\n",
      "Batch 333 Loss: 0.0516\n",
      "Batch 444 Loss: 0.0464\n",
      "\n",
      "EPOCH 4 LOSS: 0.0001\n",
      "\n",
      "Reconstruction error recall 0.0198\n",
      "Change: 0.0000%\n",
      "Epoch     4: reducing learning rate of group 0 to 1.8000e-01.\n",
      "\n",
      "\u001b[1mEpoch 5\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0489\n",
      "Batch 111 Loss: 0.0498\n",
      "Batch 222 Loss: 0.0509\n",
      "Batch 333 Loss: 0.0508\n",
      "Batch 444 Loss: 0.0556\n",
      "\n",
      "EPOCH 5 LOSS: 0.0008\n",
      "\n",
      "Reconstruction error recall 0.0495\n",
      "Change: 1.5000%\n",
      "\n",
      "\u001b[1mEpoch 6\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0534\n",
      "Batch 111 Loss: 0.0471\n",
      "Batch 222 Loss: 0.0534\n",
      "Batch 333 Loss: 0.0505\n",
      "Batch 444 Loss: 0.0476\n",
      "\n",
      "EPOCH 6 LOSS: 0.0003\n",
      "\n",
      "Reconstruction error recall 0.0693\n",
      "Change: 0.4000%\n",
      "\n",
      "\u001b[1mEpoch 7\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0521\n",
      "Batch 111 Loss: 0.0875\n",
      "Batch 222 Loss: 0.0488\n",
      "Batch 333 Loss: 0.0637\n",
      "Batch 444 Loss: 0.0476\n",
      "\n",
      "EPOCH 7 LOSS: 0.0005\n",
      "\n",
      "Reconstruction error recall 0.0297\n",
      "Change: -0.5714%\n",
      "Epoch     7: reducing learning rate of group 0 to 1.6200e-01.\n",
      "\n",
      "\u001b[1mEpoch 8\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0475\n",
      "Batch 111 Loss: 0.0697\n",
      "Batch 222 Loss: 0.0489\n",
      "Batch 333 Loss: 0.0453\n",
      "Batch 444 Loss: 0.0559\n",
      "\n",
      "EPOCH 8 LOSS: 0.0055\n",
      "\n",
      "Reconstruction error recall 0.0198\n",
      "Change: -0.3333%\n",
      "\n",
      "\u001b[1mEpoch 9\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0527\n",
      "Batch 111 Loss: 0.0438\n",
      "Batch 222 Loss: 0.0484\n",
      "Batch 333 Loss: 0.0487\n",
      "Batch 444 Loss: 0.0465\n",
      "\n",
      "EPOCH 9 LOSS: 0.0005\n",
      "\n",
      "Reconstruction error recall 0.0198\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 10\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0440\n",
      "Batch 111 Loss: 0.0538\n",
      "Batch 222 Loss: 0.0493\n",
      "Batch 333 Loss: 0.0454\n",
      "Batch 444 Loss: 0.0550\n",
      "\n",
      "EPOCH 10 LOSS: 0.0002\n",
      "\n",
      "Reconstruction error recall 0.0198\n",
      "Change: 0.0000%\n",
      "Epoch    10: reducing learning rate of group 0 to 1.4580e-01.\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(ae3.parameters(), lr=0.2,momentum=0.9,nesterov=True)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.9, patience=2, verbose=True)\n",
    "train_autoencoder(model=ae3,\n",
    "                  dataset=output2,\n",
    "                  loss_func=loss_func,\n",
    "                  optimizer=optimizer,\n",
    "                  batch_size=512,\n",
    "                  epochs=10,\n",
    "                  noise_factor=0.9,\n",
    "                  validation_tensor=val_torch,\n",
    "                  y_val=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "output3 = ae3(output2)\n",
    "train_output3 = ae3(train_output2)\n",
    "val_output3 = ae3(val_output2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder IV: L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae4 = AutoEncoder(n_features,n_features)\n",
    "\n",
    "def L1_loss(recon,inputs):\n",
    "    MSELoss = nn.MSELoss()\n",
    "    loss = MSELoss(recon,inputs)\n",
    "    for param in ae4.parameters():\n",
    "        loss += lmbda*torch.sum(torch.abs(param))\n",
    "    return loss\n",
    "\n",
    "loss_func = L1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mEpoch 1\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 14.8840\n",
      "Batch 111 Loss: 4.4161\n",
      "Batch 222 Loss: 2.8226\n",
      "Batch 333 Loss: 4.5036\n",
      "Batch 444 Loss: 2.8294\n",
      "\n",
      "EPOCH 1 LOSS: 5.3624\n",
      "\n",
      "Reconstruction error recall: 0.2079\n",
      "\n",
      "\u001b[1mEpoch 2\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 5.3624\n",
      "Batch 111 Loss: 2.8056\n",
      "Batch 222 Loss: 5.4804\n",
      "Batch 333 Loss: 2.6617\n",
      "Batch 444 Loss: 5.2765\n",
      "\n",
      "EPOCH 2 LOSS: 3.3646\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 3\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 3.3646\n",
      "Batch 111 Loss: 5.0493\n",
      "Batch 222 Loss: 3.3831\n",
      "Batch 333 Loss: 4.9237\n",
      "Batch 444 Loss: 3.3378\n",
      "\n",
      "EPOCH 3 LOSS: 4.5558\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 4\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 4.5558\n",
      "Batch 111 Loss: 2.8863\n",
      "Batch 222 Loss: 4.6447\n",
      "Batch 333 Loss: 2.8796\n",
      "Batch 444 Loss: 4.4702\n",
      "\n",
      "EPOCH 4 LOSS: 2.9122\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch     4: reducing learning rate of group 0 to 1.8000e-02.\n",
      "\n",
      "\u001b[1mEpoch 5\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 2.9122\n",
      "Batch 111 Loss: 4.8211\n",
      "Batch 222 Loss: 2.5176\n",
      "Batch 333 Loss: 4.7899\n",
      "Batch 444 Loss: 2.4808\n",
      "\n",
      "EPOCH 5 LOSS: 4.5560\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 6\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 4.5560\n",
      "Batch 111 Loss: 3.0517\n",
      "Batch 222 Loss: 4.5794\n",
      "Batch 333 Loss: 3.1770\n",
      "Batch 444 Loss: 4.4759\n",
      "\n",
      "EPOCH 6 LOSS: 2.6307\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 7\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 2.6307\n",
      "Batch 111 Loss: 3.9010\n",
      "Batch 222 Loss: 2.5943\n",
      "Batch 333 Loss: 4.0981\n",
      "Batch 444 Loss: 2.4017\n",
      "\n",
      "EPOCH 7 LOSS: 4.9718\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch     7: reducing learning rate of group 0 to 1.6200e-02.\n",
      "\n",
      "\u001b[1mEpoch 8\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 4.9718\n",
      "Batch 111 Loss: 2.3040\n",
      "Batch 222 Loss: 4.2214\n",
      "Batch 333 Loss: 2.4216\n",
      "Batch 444 Loss: 4.0936\n",
      "\n",
      "EPOCH 8 LOSS: 2.7884\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 9\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 2.7884\n",
      "Batch 111 Loss: 3.8183\n",
      "Batch 222 Loss: 2.8438\n",
      "Batch 333 Loss: 3.8948\n",
      "Batch 444 Loss: 2.6894\n",
      "\n",
      "EPOCH 9 LOSS: 3.6628\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 10\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 3.6628\n",
      "Batch 111 Loss: 2.4193\n",
      "Batch 222 Loss: 3.6744\n",
      "Batch 333 Loss: 2.2945\n",
      "Batch 444 Loss: 3.7624\n",
      "\n",
      "EPOCH 10 LOSS: 2.4349\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    10: reducing learning rate of group 0 to 1.4580e-02.\n",
      "\n",
      "\u001b[1mEpoch 11\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 2.4349\n",
      "Batch 111 Loss: 3.8242\n",
      "Batch 222 Loss: 2.1637\n",
      "Batch 333 Loss: 3.7560\n",
      "Batch 444 Loss: 2.0109\n",
      "\n",
      "EPOCH 11 LOSS: 3.7282\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 12\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 3.7282\n",
      "Batch 111 Loss: 2.3794\n",
      "Batch 222 Loss: 3.6198\n",
      "Batch 333 Loss: 2.5063\n",
      "Batch 444 Loss: 3.6529\n",
      "\n",
      "EPOCH 12 LOSS: 2.2413\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 13\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 2.2413\n",
      "Batch 111 Loss: 3.3242\n",
      "Batch 222 Loss: 2.1224\n",
      "Batch 333 Loss: 3.2999\n",
      "Batch 444 Loss: 2.0813\n",
      "\n",
      "EPOCH 13 LOSS: 3.7998\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    13: reducing learning rate of group 0 to 1.3122e-02.\n",
      "\n",
      "\u001b[1mEpoch 14\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 3.7998\n",
      "Batch 111 Loss: 1.9786\n",
      "Batch 222 Loss: 3.2942\n",
      "Batch 333 Loss: 2.0112\n",
      "Batch 444 Loss: 3.1006\n",
      "\n",
      "EPOCH 14 LOSS: 2.0939\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 15\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 2.0939\n",
      "Batch 111 Loss: 3.0026\n",
      "Batch 222 Loss: 2.1882\n",
      "Batch 333 Loss: 3.1302\n",
      "Batch 444 Loss: 2.0385\n",
      "\n",
      "EPOCH 15 LOSS: 3.1873\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 16\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 3.1873\n",
      "Batch 111 Loss: 2.0088\n",
      "Batch 222 Loss: 3.2040\n",
      "Batch 333 Loss: 1.9091\n",
      "Batch 444 Loss: 3.2363\n",
      "\n",
      "EPOCH 16 LOSS: 2.0368\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    16: reducing learning rate of group 0 to 1.1810e-02.\n",
      "\n",
      "\u001b[1mEpoch 17\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 2.0368\n",
      "Batch 111 Loss: 2.9839\n",
      "Batch 222 Loss: 1.7446\n",
      "Batch 333 Loss: 2.8123\n",
      "Batch 444 Loss: 1.7921\n",
      "\n",
      "EPOCH 17 LOSS: 2.9270\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 18\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 2.9270\n",
      "Batch 111 Loss: 1.8748\n",
      "Batch 222 Loss: 2.9251\n",
      "Batch 333 Loss: 1.8623\n",
      "Batch 444 Loss: 2.9702\n",
      "\n",
      "EPOCH 18 LOSS: 1.8313\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 19\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.8313\n",
      "Batch 111 Loss: 2.8159\n",
      "Batch 222 Loss: 1.8178\n",
      "Batch 333 Loss: 2.7738\n",
      "Batch 444 Loss: 1.8183\n",
      "\n",
      "EPOCH 19 LOSS: 2.9149\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0629e-02.\n",
      "\n",
      "\u001b[1mEpoch 20\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 2.9149\n",
      "Batch 111 Loss: 1.6740\n",
      "Batch 222 Loss: 2.6121\n",
      "Batch 333 Loss: 1.6270\n",
      "Batch 444 Loss: 2.5085\n",
      "\n",
      "EPOCH 20 LOSS: 1.6488\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 21\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.6488\n",
      "Batch 111 Loss: 2.5385\n",
      "Batch 222 Loss: 1.6250\n",
      "Batch 333 Loss: 2.5526\n",
      "Batch 444 Loss: 1.6231\n",
      "\n",
      "EPOCH 21 LOSS: 2.6578\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 22\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 2.6578\n",
      "Batch 111 Loss: 1.6366\n",
      "Batch 222 Loss: 2.6277\n",
      "Batch 333 Loss: 1.6099\n",
      "Batch 444 Loss: 2.6959\n",
      "\n",
      "EPOCH 22 LOSS: 1.6483\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    22: reducing learning rate of group 0 to 9.5659e-03.\n",
      "\n",
      "\u001b[1mEpoch 23\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.6483\n",
      "Batch 111 Loss: 2.3582\n",
      "Batch 222 Loss: 1.4589\n",
      "Batch 333 Loss: 2.3060\n",
      "Batch 444 Loss: 1.4416\n",
      "\n",
      "EPOCH 23 LOSS: 2.3716\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 24\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 2.3716\n",
      "Batch 111 Loss: 1.4675\n",
      "Batch 222 Loss: 2.3559\n",
      "Batch 333 Loss: 1.4256\n",
      "Batch 444 Loss: 2.4422\n",
      "\n",
      "EPOCH 24 LOSS: 1.5540\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 25\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.5540\n",
      "Batch 111 Loss: 2.3787\n",
      "Batch 222 Loss: 1.5095\n",
      "Batch 333 Loss: 2.3195\n",
      "Batch 444 Loss: 1.4908\n",
      "\n",
      "EPOCH 25 LOSS: 2.3174\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    25: reducing learning rate of group 0 to 8.6093e-03.\n",
      "\n",
      "\u001b[1mEpoch 26\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 2.3174\n",
      "Batch 111 Loss: 1.3329\n",
      "Batch 222 Loss: 2.0428\n",
      "Batch 333 Loss: 1.3114\n",
      "Batch 444 Loss: 2.0015\n",
      "\n",
      "EPOCH 26 LOSS: 1.3100\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 27\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.3100\n",
      "Batch 111 Loss: 2.1074\n",
      "Batch 222 Loss: 1.3237\n",
      "Batch 333 Loss: 2.1187\n",
      "Batch 444 Loss: 1.2955\n",
      "\n",
      "EPOCH 27 LOSS: 2.1395\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 28\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 2.1395\n",
      "Batch 111 Loss: 1.3743\n",
      "Batch 222 Loss: 2.1159\n",
      "Batch 333 Loss: 1.3258\n",
      "Batch 444 Loss: 2.2060\n",
      "\n",
      "EPOCH 28 LOSS: 1.3515\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    28: reducing learning rate of group 0 to 7.7484e-03.\n",
      "\n",
      "\u001b[1mEpoch 29\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.3515\n",
      "Batch 111 Loss: 1.8684\n",
      "Batch 222 Loss: 1.1414\n",
      "Batch 333 Loss: 1.8367\n",
      "Batch 444 Loss: 1.1244\n",
      "\n",
      "EPOCH 29 LOSS: 1.9874\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 30\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.9874\n",
      "Batch 111 Loss: 1.1733\n",
      "Batch 222 Loss: 1.9403\n",
      "Batch 333 Loss: 1.1588\n",
      "Batch 444 Loss: 1.9706\n",
      "\n",
      "EPOCH 30 LOSS: 1.2666\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 31\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.2666\n",
      "Batch 111 Loss: 1.9073\n",
      "Batch 222 Loss: 1.2513\n",
      "Batch 333 Loss: 1.9216\n",
      "Batch 444 Loss: 1.2590\n",
      "\n",
      "EPOCH 31 LOSS: 1.8539\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    31: reducing learning rate of group 0 to 6.9736e-03.\n",
      "\n",
      "\u001b[1mEpoch 32\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.8539\n",
      "Batch 111 Loss: 1.0579\n",
      "Batch 222 Loss: 1.6516\n",
      "Batch 333 Loss: 1.0499\n",
      "Batch 444 Loss: 1.6234\n",
      "\n",
      "EPOCH 32 LOSS: 1.0227\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 33\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.0227\n",
      "Batch 111 Loss: 1.7106\n",
      "Batch 222 Loss: 1.0396\n",
      "Batch 333 Loss: 1.7301\n",
      "Batch 444 Loss: 1.0769\n",
      "\n",
      "EPOCH 33 LOSS: 1.7198\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 34\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.7198\n",
      "Batch 111 Loss: 1.1407\n",
      "Batch 222 Loss: 1.7526\n",
      "Batch 333 Loss: 1.0742\n",
      "Batch 444 Loss: 1.8103\n",
      "\n",
      "EPOCH 34 LOSS: 1.0458\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    34: reducing learning rate of group 0 to 6.2762e-03.\n",
      "\n",
      "\u001b[1mEpoch 35\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.0458\n",
      "Batch 111 Loss: 1.5260\n",
      "Batch 222 Loss: 0.9453\n",
      "Batch 333 Loss: 1.4489\n",
      "Batch 444 Loss: 0.9359\n",
      "\n",
      "EPOCH 35 LOSS: 1.6052\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 36\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.6052\n",
      "Batch 111 Loss: 0.9241\n",
      "Batch 222 Loss: 1.5635\n",
      "Batch 333 Loss: 0.9466\n",
      "Batch 444 Loss: 1.6165\n",
      "\n",
      "EPOCH 36 LOSS: 1.0498\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 37\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.0498\n",
      "Batch 111 Loss: 1.5757\n",
      "Batch 222 Loss: 0.9942\n",
      "Batch 333 Loss: 1.5639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 444 Loss: 1.0322\n",
      "\n",
      "EPOCH 37 LOSS: 1.4880\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    37: reducing learning rate of group 0 to 5.6486e-03.\n",
      "\n",
      "\u001b[1mEpoch 38\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.4880\n",
      "Batch 111 Loss: 0.8611\n",
      "Batch 222 Loss: 1.3516\n",
      "Batch 333 Loss: 0.8455\n",
      "Batch 444 Loss: 1.3007\n",
      "\n",
      "EPOCH 38 LOSS: 0.8287\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 39\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8287\n",
      "Batch 111 Loss: 1.3905\n",
      "Batch 222 Loss: 0.8394\n",
      "Batch 333 Loss: 1.4246\n",
      "Batch 444 Loss: 0.8678\n",
      "\n",
      "EPOCH 39 LOSS: 1.4004\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 40\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.4004\n",
      "Batch 111 Loss: 0.9065\n",
      "Batch 222 Loss: 1.4385\n",
      "Batch 333 Loss: 0.8729\n",
      "Batch 444 Loss: 1.4523\n",
      "\n",
      "EPOCH 40 LOSS: 0.8644\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    40: reducing learning rate of group 0 to 5.0837e-03.\n",
      "\n",
      "\u001b[1mEpoch 41\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8644\n",
      "Batch 111 Loss: 1.2067\n",
      "Batch 222 Loss: 0.7708\n",
      "Batch 333 Loss: 1.1845\n",
      "Batch 444 Loss: 0.7687\n",
      "\n",
      "EPOCH 41 LOSS: 1.2847\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 42\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.2847\n",
      "Batch 111 Loss: 0.7622\n",
      "Batch 222 Loss: 1.2773\n",
      "Batch 333 Loss: 0.7643\n",
      "Batch 444 Loss: 1.3225\n",
      "\n",
      "EPOCH 42 LOSS: 0.8282\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 43\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8282\n",
      "Batch 111 Loss: 1.2875\n",
      "Batch 222 Loss: 0.8208\n",
      "Batch 333 Loss: 1.2656\n",
      "Batch 444 Loss: 0.8091\n",
      "\n",
      "EPOCH 43 LOSS: 1.2226\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    43: reducing learning rate of group 0 to 4.5754e-03.\n",
      "\n",
      "\u001b[1mEpoch 44\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.2226\n",
      "Batch 111 Loss: 0.7007\n",
      "Batch 222 Loss: 1.1040\n",
      "Batch 333 Loss: 0.6889\n",
      "Batch 444 Loss: 1.0636\n",
      "\n",
      "EPOCH 44 LOSS: 0.6646\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 45\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6646\n",
      "Batch 111 Loss: 1.1319\n",
      "Batch 222 Loss: 0.6912\n",
      "Batch 333 Loss: 1.1318\n",
      "Batch 444 Loss: 0.6797\n",
      "\n",
      "EPOCH 45 LOSS: 1.1449\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 46\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.1449\n",
      "Batch 111 Loss: 0.7445\n",
      "Batch 222 Loss: 1.1616\n",
      "Batch 333 Loss: 0.7117\n",
      "Batch 444 Loss: 1.1779\n",
      "\n",
      "EPOCH 46 LOSS: 0.6989\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    46: reducing learning rate of group 0 to 4.1178e-03.\n",
      "\n",
      "\u001b[1mEpoch 47\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6989\n",
      "Batch 111 Loss: 0.9990\n",
      "Batch 222 Loss: 0.6284\n",
      "Batch 333 Loss: 0.9541\n",
      "Batch 444 Loss: 0.6270\n",
      "\n",
      "EPOCH 47 LOSS: 1.0350\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 48\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 1.0350\n",
      "Batch 111 Loss: 0.6191\n",
      "Batch 222 Loss: 1.0360\n",
      "Batch 333 Loss: 0.6142\n",
      "Batch 444 Loss: 1.0500\n",
      "\n",
      "EPOCH 48 LOSS: 0.6744\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 49\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6744\n",
      "Batch 111 Loss: 1.0454\n",
      "Batch 222 Loss: 0.6680\n",
      "Batch 333 Loss: 1.0241\n",
      "Batch 444 Loss: 0.6561\n",
      "\n",
      "EPOCH 49 LOSS: 0.9911\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    49: reducing learning rate of group 0 to 3.7060e-03.\n",
      "\n",
      "\u001b[1mEpoch 50\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.9911\n",
      "Batch 111 Loss: 0.5591\n",
      "Batch 222 Loss: 0.9105\n",
      "Batch 333 Loss: 0.5670\n",
      "Batch 444 Loss: 0.8839\n",
      "\n",
      "EPOCH 50 LOSS: 0.5471\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 51\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5471\n",
      "Batch 111 Loss: 0.9240\n",
      "Batch 222 Loss: 0.5586\n",
      "Batch 333 Loss: 0.9139\n",
      "Batch 444 Loss: 0.5673\n",
      "\n",
      "EPOCH 51 LOSS: 0.9253\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 52\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.9253\n",
      "Batch 111 Loss: 0.5999\n",
      "Batch 222 Loss: 0.9393\n",
      "Batch 333 Loss: 0.5732\n",
      "Batch 444 Loss: 0.9556\n",
      "\n",
      "EPOCH 52 LOSS: 0.5571\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    52: reducing learning rate of group 0 to 3.3354e-03.\n",
      "\n",
      "\u001b[1mEpoch 53\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5571\n",
      "Batch 111 Loss: 0.8199\n",
      "Batch 222 Loss: 0.5132\n",
      "Batch 333 Loss: 0.7895\n",
      "Batch 444 Loss: 0.4941\n",
      "\n",
      "EPOCH 53 LOSS: 0.8522\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 54\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8522\n",
      "Batch 111 Loss: 0.5018\n",
      "Batch 222 Loss: 0.8289\n",
      "Batch 333 Loss: 0.5116\n",
      "Batch 444 Loss: 0.8611\n",
      "\n",
      "EPOCH 54 LOSS: 0.5320\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 55\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5320\n",
      "Batch 111 Loss: 0.8449\n",
      "Batch 222 Loss: 0.5252\n",
      "Batch 333 Loss: 0.8386\n",
      "Batch 444 Loss: 0.5146\n",
      "\n",
      "EPOCH 55 LOSS: 0.8217\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    55: reducing learning rate of group 0 to 3.0019e-03.\n",
      "\n",
      "\u001b[1mEpoch 56\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.8217\n",
      "Batch 111 Loss: 0.4509\n",
      "Batch 222 Loss: 0.7489\n",
      "Batch 333 Loss: 0.4529\n",
      "Batch 444 Loss: 0.7107\n",
      "\n",
      "EPOCH 56 LOSS: 0.4460\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 57\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4460\n",
      "Batch 111 Loss: 0.7471\n",
      "Batch 222 Loss: 0.4580\n",
      "Batch 333 Loss: 0.7452\n",
      "Batch 444 Loss: 0.4607\n",
      "\n",
      "EPOCH 57 LOSS: 0.7397\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 58\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.7397\n",
      "Batch 111 Loss: 0.4751\n",
      "Batch 222 Loss: 0.7626\n",
      "Batch 333 Loss: 0.4586\n",
      "Batch 444 Loss: 0.7708\n",
      "\n",
      "EPOCH 58 LOSS: 0.4633\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    58: reducing learning rate of group 0 to 2.7017e-03.\n",
      "\n",
      "\u001b[1mEpoch 59\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4633\n",
      "Batch 111 Loss: 0.6617\n",
      "Batch 222 Loss: 0.4151\n",
      "Batch 333 Loss: 0.6406\n",
      "Batch 444 Loss: 0.4031\n",
      "\n",
      "EPOCH 59 LOSS: 0.6731\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 60\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6731\n",
      "Batch 111 Loss: 0.4131\n",
      "Batch 222 Loss: 0.6783\n",
      "Batch 333 Loss: 0.4073\n",
      "Batch 444 Loss: 0.6971\n",
      "\n",
      "EPOCH 60 LOSS: 0.4284\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 61\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4284\n",
      "Batch 111 Loss: 0.6876\n",
      "Batch 222 Loss: 0.4228\n",
      "Batch 333 Loss: 0.6695\n",
      "Batch 444 Loss: 0.4102\n",
      "\n",
      "EPOCH 61 LOSS: 0.6669\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    61: reducing learning rate of group 0 to 2.4315e-03.\n",
      "\n",
      "\u001b[1mEpoch 62\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6669\n",
      "Batch 111 Loss: 0.3642\n",
      "Batch 222 Loss: 0.5992\n",
      "Batch 333 Loss: 0.3713\n",
      "Batch 444 Loss: 0.5799\n",
      "\n",
      "EPOCH 62 LOSS: 0.3771\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 63\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3771\n",
      "Batch 111 Loss: 0.6042\n",
      "Batch 222 Loss: 0.3813\n",
      "Batch 333 Loss: 0.6018\n",
      "Batch 444 Loss: 0.3737\n",
      "\n",
      "EPOCH 63 LOSS: 0.6018\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 64\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.6018\n",
      "Batch 111 Loss: 0.3872\n",
      "Batch 222 Loss: 0.6070\n",
      "Batch 333 Loss: 0.3665\n",
      "Batch 444 Loss: 0.6172\n",
      "\n",
      "EPOCH 64 LOSS: 0.3713\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    64: reducing learning rate of group 0 to 2.1884e-03.\n",
      "\n",
      "\u001b[1mEpoch 65\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3713\n",
      "Batch 111 Loss: 0.5429\n",
      "Batch 222 Loss: 0.3347\n",
      "Batch 333 Loss: 0.5267\n",
      "Batch 444 Loss: 0.3265\n",
      "\n",
      "EPOCH 65 LOSS: 0.5572\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 66\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5572\n",
      "Batch 111 Loss: 0.3283\n",
      "Batch 222 Loss: 0.5466\n",
      "Batch 333 Loss: 0.3328\n",
      "Batch 444 Loss: 0.5541\n",
      "\n",
      "EPOCH 66 LOSS: 0.3470\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 67\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3470\n",
      "Batch 111 Loss: 0.5533\n",
      "Batch 222 Loss: 0.3494\n",
      "Batch 333 Loss: 0.5428\n",
      "Batch 444 Loss: 0.3352\n",
      "\n",
      "EPOCH 67 LOSS: 0.5439\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    67: reducing learning rate of group 0 to 1.9695e-03.\n",
      "\n",
      "\u001b[1mEpoch 68\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.5439\n",
      "Batch 111 Loss: 0.2941\n",
      "Batch 222 Loss: 0.4920\n",
      "Batch 333 Loss: 0.3002\n",
      "Batch 444 Loss: 0.4700\n",
      "\n",
      "EPOCH 68 LOSS: 0.3043\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 69\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3043\n",
      "Batch 111 Loss: 0.4894\n",
      "Batch 222 Loss: 0.3074\n",
      "Batch 333 Loss: 0.4807\n",
      "Batch 444 Loss: 0.3082\n",
      "\n",
      "EPOCH 69 LOSS: 0.4868\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 70\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4868\n",
      "Batch 111 Loss: 0.3126\n",
      "Batch 222 Loss: 0.4932\n",
      "Batch 333 Loss: 0.2962\n",
      "Batch 444 Loss: 0.4959\n",
      "\n",
      "EPOCH 70 LOSS: 0.2978\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    70: reducing learning rate of group 0 to 1.7726e-03.\n",
      "\n",
      "\u001b[1mEpoch 71\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2978\n",
      "Batch 111 Loss: 0.4389\n",
      "Batch 222 Loss: 0.2733\n",
      "Batch 333 Loss: 0.4311\n",
      "Batch 444 Loss: 0.2592\n",
      "\n",
      "EPOCH 71 LOSS: 0.4553\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 72\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4553\n",
      "Batch 111 Loss: 0.2714\n",
      "Batch 222 Loss: 0.4467\n",
      "Batch 333 Loss: 0.2696\n",
      "Batch 444 Loss: 0.4536\n",
      "\n",
      "EPOCH 72 LOSS: 0.2771\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 73\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2771\n",
      "Batch 111 Loss: 0.4417\n",
      "Batch 222 Loss: 0.2765\n",
      "Batch 333 Loss: 0.4349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 444 Loss: 0.2745\n",
      "\n",
      "EPOCH 73 LOSS: 0.4386\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    73: reducing learning rate of group 0 to 1.5953e-03.\n",
      "\n",
      "\u001b[1mEpoch 74\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.4386\n",
      "Batch 111 Loss: 0.2430\n",
      "Batch 222 Loss: 0.3932\n",
      "Batch 333 Loss: 0.2399\n",
      "Batch 444 Loss: 0.3902\n",
      "\n",
      "EPOCH 74 LOSS: 0.2464\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 75\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2464\n",
      "Batch 111 Loss: 0.3954\n",
      "Batch 222 Loss: 0.2478\n",
      "Batch 333 Loss: 0.3943\n",
      "Batch 444 Loss: 0.2514\n",
      "\n",
      "EPOCH 75 LOSS: 0.3904\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 76\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3904\n",
      "Batch 111 Loss: 0.2487\n",
      "Batch 222 Loss: 0.3936\n",
      "Batch 333 Loss: 0.2431\n",
      "Batch 444 Loss: 0.4021\n",
      "\n",
      "EPOCH 76 LOSS: 0.2406\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    76: reducing learning rate of group 0 to 1.4358e-03.\n",
      "\n",
      "\u001b[1mEpoch 77\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2406\n",
      "Batch 111 Loss: 0.3612\n",
      "Batch 222 Loss: 0.2196\n",
      "Batch 333 Loss: 0.3509\n",
      "Batch 444 Loss: 0.2165\n",
      "\n",
      "EPOCH 77 LOSS: 0.3632\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 78\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3632\n",
      "Batch 111 Loss: 0.2236\n",
      "Batch 222 Loss: 0.3600\n",
      "Batch 333 Loss: 0.2168\n",
      "Batch 444 Loss: 0.3662\n",
      "\n",
      "EPOCH 78 LOSS: 0.2205\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 79\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2205\n",
      "Batch 111 Loss: 0.3562\n",
      "Batch 222 Loss: 0.2262\n",
      "Batch 333 Loss: 0.3481\n",
      "Batch 444 Loss: 0.2170\n",
      "\n",
      "EPOCH 79 LOSS: 0.3588\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    79: reducing learning rate of group 0 to 1.2922e-03.\n",
      "\n",
      "\u001b[1mEpoch 80\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3588\n",
      "Batch 111 Loss: 0.1944\n",
      "Batch 222 Loss: 0.3187\n",
      "Batch 333 Loss: 0.1993\n",
      "Batch 444 Loss: 0.3159\n",
      "\n",
      "EPOCH 80 LOSS: 0.2012\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 81\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2012\n",
      "Batch 111 Loss: 0.3212\n",
      "Batch 222 Loss: 0.2031\n",
      "Batch 333 Loss: 0.3210\n",
      "Batch 444 Loss: 0.2005\n",
      "\n",
      "EPOCH 81 LOSS: 0.3187\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 82\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3187\n",
      "Batch 111 Loss: 0.2061\n",
      "Batch 222 Loss: 0.3200\n",
      "Batch 333 Loss: 0.1954\n",
      "Batch 444 Loss: 0.3237\n",
      "\n",
      "EPOCH 82 LOSS: 0.1944\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    82: reducing learning rate of group 0 to 1.1630e-03.\n",
      "\n",
      "\u001b[1mEpoch 83\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1944\n",
      "Batch 111 Loss: 0.2952\n",
      "Batch 222 Loss: 0.1781\n",
      "Batch 333 Loss: 0.2848\n",
      "Batch 444 Loss: 0.1712\n",
      "\n",
      "EPOCH 83 LOSS: 0.2970\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 84\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2970\n",
      "Batch 111 Loss: 0.1832\n",
      "Batch 222 Loss: 0.2922\n",
      "Batch 333 Loss: 0.1788\n",
      "Batch 444 Loss: 0.2958\n",
      "\n",
      "EPOCH 84 LOSS: 0.1789\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 85\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1789\n",
      "Batch 111 Loss: 0.2869\n",
      "Batch 222 Loss: 0.1850\n",
      "Batch 333 Loss: 0.2830\n",
      "Batch 444 Loss: 0.1803\n",
      "\n",
      "EPOCH 85 LOSS: 0.2917\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0467e-03.\n",
      "\n",
      "\u001b[1mEpoch 86\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2917\n",
      "Batch 111 Loss: 0.1578\n",
      "Batch 222 Loss: 0.2600\n",
      "Batch 333 Loss: 0.1589\n",
      "Batch 444 Loss: 0.2518\n",
      "\n",
      "EPOCH 86 LOSS: 0.1608\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 87\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1608\n",
      "Batch 111 Loss: 0.2625\n",
      "Batch 222 Loss: 0.1634\n",
      "Batch 333 Loss: 0.2591\n",
      "Batch 444 Loss: 0.1650\n",
      "\n",
      "EPOCH 87 LOSS: 0.2564\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 88\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2564\n",
      "Batch 111 Loss: 0.1684\n",
      "Batch 222 Loss: 0.2548\n",
      "Batch 333 Loss: 0.1629\n",
      "Batch 444 Loss: 0.2640\n",
      "\n",
      "EPOCH 88 LOSS: 0.1598\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    88: reducing learning rate of group 0 to 9.4203e-04.\n",
      "\n",
      "\u001b[1mEpoch 89\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1598\n",
      "Batch 111 Loss: 0.2365\n",
      "Batch 222 Loss: 0.1436\n",
      "Batch 333 Loss: 0.2284\n",
      "Batch 444 Loss: 0.1370\n",
      "\n",
      "EPOCH 89 LOSS: 0.2409\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 90\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2409\n",
      "Batch 111 Loss: 0.1459\n",
      "Batch 222 Loss: 0.2382\n",
      "Batch 333 Loss: 0.1483\n",
      "Batch 444 Loss: 0.2429\n",
      "\n",
      "EPOCH 90 LOSS: 0.1508\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 91\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1508\n",
      "Batch 111 Loss: 0.2346\n",
      "Batch 222 Loss: 0.1480\n",
      "Batch 333 Loss: 0.2292\n",
      "Batch 444 Loss: 0.1455\n",
      "\n",
      "EPOCH 91 LOSS: 0.2363\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    91: reducing learning rate of group 0 to 8.4782e-04.\n",
      "\n",
      "\u001b[1mEpoch 92\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2363\n",
      "Batch 111 Loss: 0.1276\n",
      "Batch 222 Loss: 0.2094\n",
      "Batch 333 Loss: 0.1298\n",
      "Batch 444 Loss: 0.2043\n",
      "\n",
      "EPOCH 92 LOSS: 0.1317\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 93\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1317\n",
      "Batch 111 Loss: 0.2094\n",
      "Batch 222 Loss: 0.1365\n",
      "Batch 333 Loss: 0.2075\n",
      "Batch 444 Loss: 0.1310\n",
      "\n",
      "EPOCH 93 LOSS: 0.2099\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 94\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2099\n",
      "Batch 111 Loss: 0.1325\n",
      "Batch 222 Loss: 0.2110\n",
      "Batch 333 Loss: 0.1257\n",
      "Batch 444 Loss: 0.2139\n",
      "\n",
      "EPOCH 94 LOSS: 0.1271\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    94: reducing learning rate of group 0 to 7.6304e-04.\n",
      "\n",
      "\u001b[1mEpoch 95\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1271\n",
      "Batch 111 Loss: 0.1908\n",
      "Batch 222 Loss: 0.1159\n",
      "Batch 333 Loss: 0.1844\n",
      "Batch 444 Loss: 0.1158\n",
      "\n",
      "EPOCH 95 LOSS: 0.1930\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 96\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1930\n",
      "Batch 111 Loss: 0.1208\n",
      "Batch 222 Loss: 0.1898\n",
      "Batch 333 Loss: 0.1181\n",
      "Batch 444 Loss: 0.1962\n",
      "\n",
      "EPOCH 96 LOSS: 0.1222\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 97\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1222\n",
      "Batch 111 Loss: 0.1894\n",
      "Batch 222 Loss: 0.1210\n",
      "Batch 333 Loss: 0.1832\n",
      "Batch 444 Loss: 0.1187\n",
      "\n",
      "EPOCH 97 LOSS: 0.1889\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch    97: reducing learning rate of group 0 to 6.8674e-04.\n",
      "\n",
      "\u001b[1mEpoch 98\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1889\n",
      "Batch 111 Loss: 0.1016\n",
      "Batch 222 Loss: 0.1704\n",
      "Batch 333 Loss: 0.1056\n",
      "Batch 444 Loss: 0.1645\n",
      "\n",
      "EPOCH 98 LOSS: 0.1072\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 99\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1072\n",
      "Batch 111 Loss: 0.1740\n",
      "Batch 222 Loss: 0.1072\n",
      "Batch 333 Loss: 0.1696\n",
      "Batch 444 Loss: 0.1071\n",
      "\n",
      "EPOCH 99 LOSS: 0.1708\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 100\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1708\n",
      "Batch 111 Loss: 0.1071\n",
      "Batch 222 Loss: 0.1711\n",
      "Batch 333 Loss: 0.1054\n",
      "Batch 444 Loss: 0.1724\n",
      "\n",
      "EPOCH 100 LOSS: 0.1042\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   100: reducing learning rate of group 0 to 6.1806e-04.\n",
      "\n",
      "\u001b[1mEpoch 101\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1042\n",
      "Batch 111 Loss: 0.1544\n",
      "Batch 222 Loss: 0.0961\n",
      "Batch 333 Loss: 0.1477\n",
      "Batch 444 Loss: 0.0950\n",
      "\n",
      "EPOCH 101 LOSS: 0.1559\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 102\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1559\n",
      "Batch 111 Loss: 0.0979\n",
      "Batch 222 Loss: 0.1586\n",
      "Batch 333 Loss: 0.0938\n",
      "Batch 444 Loss: 0.1577\n",
      "\n",
      "EPOCH 102 LOSS: 0.0944\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 103\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0944\n",
      "Batch 111 Loss: 0.1538\n",
      "Batch 222 Loss: 0.0992\n",
      "Batch 333 Loss: 0.1479\n",
      "Batch 444 Loss: 0.0958\n",
      "\n",
      "EPOCH 103 LOSS: 0.1540\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   103: reducing learning rate of group 0 to 5.5626e-04.\n",
      "\n",
      "\u001b[1mEpoch 104\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1540\n",
      "Batch 111 Loss: 0.0826\n",
      "Batch 222 Loss: 0.1371\n",
      "Batch 333 Loss: 0.0850\n",
      "Batch 444 Loss: 0.1329\n",
      "\n",
      "EPOCH 104 LOSS: 0.0866\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 105\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0866\n",
      "Batch 111 Loss: 0.1379\n",
      "Batch 222 Loss: 0.0882\n",
      "Batch 333 Loss: 0.1370\n",
      "Batch 444 Loss: 0.0881\n",
      "\n",
      "EPOCH 105 LOSS: 0.1360\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 106\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1360\n",
      "Batch 111 Loss: 0.0893\n",
      "Batch 222 Loss: 0.1386\n",
      "Batch 333 Loss: 0.0838\n",
      "Batch 444 Loss: 0.1408\n",
      "\n",
      "EPOCH 106 LOSS: 0.0846\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   106: reducing learning rate of group 0 to 5.0063e-04.\n",
      "\n",
      "\u001b[1mEpoch 107\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0846\n",
      "Batch 111 Loss: 0.1261\n",
      "Batch 222 Loss: 0.0764\n",
      "Batch 333 Loss: 0.1203\n",
      "Batch 444 Loss: 0.0751\n",
      "\n",
      "EPOCH 107 LOSS: 0.1258\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 108\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1258\n",
      "Batch 111 Loss: 0.0775\n",
      "Batch 222 Loss: 0.1248\n",
      "Batch 333 Loss: 0.0785\n",
      "Batch 444 Loss: 0.1276\n",
      "\n",
      "EPOCH 108 LOSS: 0.0788\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 109\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0788\n",
      "Batch 111 Loss: 0.1253\n",
      "Batch 222 Loss: 0.0797\n",
      "Batch 333 Loss: 0.1227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 444 Loss: 0.0776\n",
      "\n",
      "EPOCH 109 LOSS: 0.1247\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   109: reducing learning rate of group 0 to 4.5057e-04.\n",
      "\n",
      "\u001b[1mEpoch 110\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1247\n",
      "Batch 111 Loss: 0.0680\n",
      "Batch 222 Loss: 0.1108\n",
      "Batch 333 Loss: 0.0696\n",
      "Batch 444 Loss: 0.1080\n",
      "\n",
      "EPOCH 110 LOSS: 0.0698\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 111\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0698\n",
      "Batch 111 Loss: 0.1119\n",
      "Batch 222 Loss: 0.0703\n",
      "Batch 333 Loss: 0.1124\n",
      "Batch 444 Loss: 0.0707\n",
      "\n",
      "EPOCH 111 LOSS: 0.1119\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 112\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1119\n",
      "Batch 111 Loss: 0.0721\n",
      "Batch 222 Loss: 0.1128\n",
      "Batch 333 Loss: 0.0680\n",
      "Batch 444 Loss: 0.1145\n",
      "\n",
      "EPOCH 112 LOSS: 0.0682\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   112: reducing learning rate of group 0 to 4.0551e-04.\n",
      "\n",
      "\u001b[1mEpoch 113\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0682\n",
      "Batch 111 Loss: 0.1017\n",
      "Batch 222 Loss: 0.0637\n",
      "Batch 333 Loss: 0.0971\n",
      "Batch 444 Loss: 0.0617\n",
      "\n",
      "EPOCH 113 LOSS: 0.1013\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 114\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1013\n",
      "Batch 111 Loss: 0.0638\n",
      "Batch 222 Loss: 0.1028\n",
      "Batch 333 Loss: 0.0624\n",
      "Batch 444 Loss: 0.1021\n",
      "\n",
      "EPOCH 114 LOSS: 0.0630\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 115\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0630\n",
      "Batch 111 Loss: 0.1008\n",
      "Batch 222 Loss: 0.0646\n",
      "Batch 333 Loss: 0.0986\n",
      "Batch 444 Loss: 0.0630\n",
      "\n",
      "EPOCH 115 LOSS: 0.1009\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   115: reducing learning rate of group 0 to 3.6496e-04.\n",
      "\n",
      "\u001b[1mEpoch 116\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.1009\n",
      "Batch 111 Loss: 0.0546\n",
      "Batch 222 Loss: 0.0907\n",
      "Batch 333 Loss: 0.0546\n",
      "Batch 444 Loss: 0.0886\n",
      "\n",
      "EPOCH 116 LOSS: 0.0562\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 117\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0562\n",
      "Batch 111 Loss: 0.0914\n",
      "Batch 222 Loss: 0.0584\n",
      "Batch 333 Loss: 0.0905\n",
      "Batch 444 Loss: 0.0575\n",
      "\n",
      "EPOCH 117 LOSS: 0.0892\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 118\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0892\n",
      "Batch 111 Loss: 0.0572\n",
      "Batch 222 Loss: 0.0907\n",
      "Batch 333 Loss: 0.0562\n",
      "Batch 444 Loss: 0.0914\n",
      "\n",
      "EPOCH 118 LOSS: 0.0557\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   118: reducing learning rate of group 0 to 3.2846e-04.\n",
      "\n",
      "\u001b[1mEpoch 119\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0557\n",
      "Batch 111 Loss: 0.0823\n",
      "Batch 222 Loss: 0.0512\n",
      "Batch 333 Loss: 0.0793\n",
      "Batch 444 Loss: 0.0497\n",
      "\n",
      "EPOCH 119 LOSS: 0.0831\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 120\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0831\n",
      "Batch 111 Loss: 0.0518\n",
      "Batch 222 Loss: 0.0831\n",
      "Batch 333 Loss: 0.0509\n",
      "Batch 444 Loss: 0.0837\n",
      "\n",
      "EPOCH 120 LOSS: 0.0511\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 121\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0511\n",
      "Batch 111 Loss: 0.0823\n",
      "Batch 222 Loss: 0.0518\n",
      "Batch 333 Loss: 0.0804\n",
      "Batch 444 Loss: 0.0512\n",
      "\n",
      "EPOCH 121 LOSS: 0.0821\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   121: reducing learning rate of group 0 to 2.9562e-04.\n",
      "\n",
      "\u001b[1mEpoch 122\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0821\n",
      "Batch 111 Loss: 0.0445\n",
      "Batch 222 Loss: 0.0728\n",
      "Batch 333 Loss: 0.0451\n",
      "Batch 444 Loss: 0.0704\n",
      "\n",
      "EPOCH 122 LOSS: 0.0462\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 123\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0462\n",
      "Batch 111 Loss: 0.0737\n",
      "Batch 222 Loss: 0.0474\n",
      "Batch 333 Loss: 0.0738\n",
      "Batch 444 Loss: 0.0462\n",
      "\n",
      "EPOCH 123 LOSS: 0.0735\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 124\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0735\n",
      "Batch 111 Loss: 0.0471\n",
      "Batch 222 Loss: 0.0727\n",
      "Batch 333 Loss: 0.0446\n",
      "Batch 444 Loss: 0.0742\n",
      "\n",
      "EPOCH 124 LOSS: 0.0447\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   124: reducing learning rate of group 0 to 2.6606e-04.\n",
      "\n",
      "\u001b[1mEpoch 125\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0447\n",
      "Batch 111 Loss: 0.0666\n",
      "Batch 222 Loss: 0.0413\n",
      "Batch 333 Loss: 0.0633\n",
      "Batch 444 Loss: 0.0401\n",
      "\n",
      "EPOCH 125 LOSS: 0.0673\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 126\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0673\n",
      "Batch 111 Loss: 0.0420\n",
      "Batch 222 Loss: 0.0676\n",
      "Batch 333 Loss: 0.0406\n",
      "Batch 444 Loss: 0.0687\n",
      "\n",
      "EPOCH 126 LOSS: 0.0405\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 127\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0405\n",
      "Batch 111 Loss: 0.0669\n",
      "Batch 222 Loss: 0.0424\n",
      "Batch 333 Loss: 0.0641\n",
      "Batch 444 Loss: 0.0419\n",
      "\n",
      "EPOCH 127 LOSS: 0.0659\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   127: reducing learning rate of group 0 to 2.3945e-04.\n",
      "\n",
      "\u001b[1mEpoch 128\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0659\n",
      "Batch 111 Loss: 0.0363\n",
      "Batch 222 Loss: 0.0592\n",
      "Batch 333 Loss: 0.0363\n",
      "Batch 444 Loss: 0.0579\n",
      "\n",
      "EPOCH 128 LOSS: 0.0379\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 129\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0379\n",
      "Batch 111 Loss: 0.0595\n",
      "Batch 222 Loss: 0.0382\n",
      "Batch 333 Loss: 0.0597\n",
      "Batch 444 Loss: 0.0377\n",
      "\n",
      "EPOCH 129 LOSS: 0.0590\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 130\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0590\n",
      "Batch 111 Loss: 0.0377\n",
      "Batch 222 Loss: 0.0596\n",
      "Batch 333 Loss: 0.0359\n",
      "Batch 444 Loss: 0.0601\n",
      "\n",
      "EPOCH 130 LOSS: 0.0354\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   130: reducing learning rate of group 0 to 2.1551e-04.\n",
      "\n",
      "\u001b[1mEpoch 131\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0354\n",
      "Batch 111 Loss: 0.0540\n",
      "Batch 222 Loss: 0.0331\n",
      "Batch 333 Loss: 0.0514\n",
      "Batch 444 Loss: 0.0333\n",
      "\n",
      "EPOCH 131 LOSS: 0.0543\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 132\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0543\n",
      "Batch 111 Loss: 0.0344\n",
      "Batch 222 Loss: 0.0547\n",
      "Batch 333 Loss: 0.0341\n",
      "Batch 444 Loss: 0.0548\n",
      "\n",
      "EPOCH 132 LOSS: 0.0341\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 133\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0341\n",
      "Batch 111 Loss: 0.0535\n",
      "Batch 222 Loss: 0.0341\n",
      "Batch 333 Loss: 0.0523\n",
      "Batch 444 Loss: 0.0336\n",
      "\n",
      "EPOCH 133 LOSS: 0.0538\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   133: reducing learning rate of group 0 to 1.9395e-04.\n",
      "\n",
      "\u001b[1mEpoch 134\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0538\n",
      "Batch 111 Loss: 0.0292\n",
      "Batch 222 Loss: 0.0478\n",
      "Batch 333 Loss: 0.0296\n",
      "Batch 444 Loss: 0.0469\n",
      "\n",
      "EPOCH 134 LOSS: 0.0305\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 135\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0305\n",
      "Batch 111 Loss: 0.0480\n",
      "Batch 222 Loss: 0.0310\n",
      "Batch 333 Loss: 0.0482\n",
      "Batch 444 Loss: 0.0301\n",
      "\n",
      "EPOCH 135 LOSS: 0.0484\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 136\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0484\n",
      "Batch 111 Loss: 0.0303\n",
      "Batch 222 Loss: 0.0480\n",
      "Batch 333 Loss: 0.0291\n",
      "Batch 444 Loss: 0.0485\n",
      "\n",
      "EPOCH 136 LOSS: 0.0297\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   136: reducing learning rate of group 0 to 1.7456e-04.\n",
      "\n",
      "\u001b[1mEpoch 137\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0297\n",
      "Batch 111 Loss: 0.0436\n",
      "Batch 222 Loss: 0.0268\n",
      "Batch 333 Loss: 0.0423\n",
      "Batch 444 Loss: 0.0262\n",
      "\n",
      "EPOCH 137 LOSS: 0.0441\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 138\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0441\n",
      "Batch 111 Loss: 0.0275\n",
      "Batch 222 Loss: 0.0444\n",
      "Batch 333 Loss: 0.0275\n",
      "Batch 444 Loss: 0.0448\n",
      "\n",
      "EPOCH 138 LOSS: 0.0278\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 139\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0278\n",
      "Batch 111 Loss: 0.0434\n",
      "Batch 222 Loss: 0.0281\n",
      "Batch 333 Loss: 0.0421\n",
      "Batch 444 Loss: 0.0276\n",
      "\n",
      "EPOCH 139 LOSS: 0.0433\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   139: reducing learning rate of group 0 to 1.5710e-04.\n",
      "\n",
      "\u001b[1mEpoch 140\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0433\n",
      "Batch 111 Loss: 0.0239\n",
      "Batch 222 Loss: 0.0395\n",
      "Batch 333 Loss: 0.0236\n",
      "Batch 444 Loss: 0.0376\n",
      "\n",
      "EPOCH 140 LOSS: 0.0247\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 141\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0247\n",
      "Batch 111 Loss: 0.0388\n",
      "Batch 222 Loss: 0.0249\n",
      "Batch 333 Loss: 0.0392\n",
      "Batch 444 Loss: 0.0248\n",
      "\n",
      "EPOCH 141 LOSS: 0.0390\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 142\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0390\n",
      "Batch 111 Loss: 0.0248\n",
      "Batch 222 Loss: 0.0382\n",
      "Batch 333 Loss: 0.0245\n",
      "Batch 444 Loss: 0.0396\n",
      "\n",
      "EPOCH 142 LOSS: 0.0243\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   142: reducing learning rate of group 0 to 1.4139e-04.\n",
      "\n",
      "\u001b[1mEpoch 143\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0243\n",
      "Batch 111 Loss: 0.0354\n",
      "Batch 222 Loss: 0.0219\n",
      "Batch 333 Loss: 0.0342\n",
      "Batch 444 Loss: 0.0217\n",
      "\n",
      "EPOCH 143 LOSS: 0.0357\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 144\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0357\n",
      "Batch 111 Loss: 0.0221\n",
      "Batch 222 Loss: 0.0357\n",
      "Batch 333 Loss: 0.0222\n",
      "Batch 444 Loss: 0.0361\n",
      "\n",
      "EPOCH 144 LOSS: 0.0228\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 145\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 111 Loss: 0.0347\n",
      "Batch 222 Loss: 0.0228\n",
      "Batch 333 Loss: 0.0341\n",
      "Batch 444 Loss: 0.0218\n",
      "\n",
      "EPOCH 145 LOSS: 0.0354\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   145: reducing learning rate of group 0 to 1.2725e-04.\n",
      "\n",
      "\u001b[1mEpoch 146\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0354\n",
      "Batch 111 Loss: 0.0193\n",
      "Batch 222 Loss: 0.0316\n",
      "Batch 333 Loss: 0.0199\n",
      "Batch 444 Loss: 0.0308\n",
      "\n",
      "EPOCH 146 LOSS: 0.0198\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 147\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0198\n",
      "Batch 111 Loss: 0.0310\n",
      "Batch 222 Loss: 0.0205\n",
      "Batch 333 Loss: 0.0316\n",
      "Batch 444 Loss: 0.0203\n",
      "\n",
      "EPOCH 147 LOSS: 0.0314\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 148\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0314\n",
      "Batch 111 Loss: 0.0205\n",
      "Batch 222 Loss: 0.0315\n",
      "Batch 333 Loss: 0.0193\n",
      "Batch 444 Loss: 0.0324\n",
      "\n",
      "EPOCH 148 LOSS: 0.0199\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   148: reducing learning rate of group 0 to 1.1453e-04.\n",
      "\n",
      "\u001b[1mEpoch 149\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0199\n",
      "Batch 111 Loss: 0.0290\n",
      "Batch 222 Loss: 0.0179\n",
      "Batch 333 Loss: 0.0278\n",
      "Batch 444 Loss: 0.0173\n",
      "\n",
      "EPOCH 149 LOSS: 0.0294\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 150\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.0294\n",
      "Batch 111 Loss: 0.0180\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-97708da475b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                   \u001b[0mvalidation_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_torch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                   y_val=y_val)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-b131393f30ae>\u001b[0m in \u001b[0;36mtrain_autoencoder\u001b[0;34m(model, dataset, loss_func, optimizer, epochs, batch_size, validation_tensor, y_val, lr_rate_scheduler, noise_factor, random_seed, MSE_stopping_threshold)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\033[1mEpoch {}\\033[0m\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnoise_factor\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lmbda=0.25\n",
    "optimizer = torch.optim.SGD(ae4.parameters(), lr=0.02,momentum=0.9,nesterov=True)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.9, patience=2, verbose=True)\n",
    "train_autoencoder(model=ae4,\n",
    "                  dataset=output3,\n",
    "                  loss_func=loss_func,\n",
    "                  optimizer=optimizer,\n",
    "                  batch_size=512,\n",
    "                  epochs=200,\n",
    "                  validation_tensor=val_torch,\n",
    "                  y_val=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "output4 = ae4(output3)\n",
    "train_output4 = ae4(train_output3)\n",
    "val_output4 = ae4(val_output3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder V: Kitchen Sink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae5 = AutoEncoder(n_features,int(n_features//4),dropout=0.5)\n",
    "loss_func = L1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mEpoch 1\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.3079\n",
      "Batch 55 Loss: 0.2757\n",
      "Batch 110 Loss: 0.2761\n",
      "Batch 165 Loss: 0.2779\n",
      "Batch 220 Loss: 0.2804\n",
      "\n",
      "EPOCH 1 LOSS: 0.0281\n",
      "\n",
      "Reconstruction error recall: 0.2079\n",
      "\n",
      "\u001b[1mEpoch 2\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2761\n",
      "Batch 55 Loss: 0.2778\n",
      "Batch 110 Loss: 0.2804\n",
      "Batch 165 Loss: 0.2748\n",
      "Batch 220 Loss: 0.2793\n",
      "\n",
      "EPOCH 2 LOSS: 0.0281\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   163: reducing learning rate of group 0 to 6.7628e-05.\n",
      "\n",
      "\u001b[1mEpoch 3\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2768\n",
      "Batch 55 Loss: 0.2819\n",
      "Batch 110 Loss: 0.2805\n",
      "Batch 165 Loss: 0.2801\n",
      "Batch 220 Loss: 0.2792\n",
      "\n",
      "EPOCH 3 LOSS: 0.0280\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 4\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2782\n",
      "Batch 55 Loss: 0.2770\n",
      "Batch 110 Loss: 0.2773\n",
      "Batch 165 Loss: 0.2768\n",
      "Batch 220 Loss: 0.2766\n",
      "\n",
      "EPOCH 4 LOSS: 0.0280\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 5\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2761\n",
      "Batch 55 Loss: 0.2778\n",
      "Batch 110 Loss: 0.2772\n",
      "Batch 165 Loss: 0.2763\n",
      "Batch 220 Loss: 0.2799\n",
      "\n",
      "EPOCH 5 LOSS: 0.0281\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   166: reducing learning rate of group 0 to 6.0865e-05.\n",
      "\n",
      "\u001b[1mEpoch 6\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2793\n",
      "Batch 55 Loss: 0.2778\n",
      "Batch 110 Loss: 0.2748\n",
      "Batch 165 Loss: 0.2757\n",
      "Batch 220 Loss: 0.2785\n",
      "\n",
      "EPOCH 6 LOSS: 0.0281\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 7\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2754\n",
      "Batch 55 Loss: 0.2830\n",
      "Batch 110 Loss: 0.2760\n",
      "Batch 165 Loss: 0.2776\n",
      "Batch 220 Loss: 0.2782\n",
      "\n",
      "EPOCH 7 LOSS: 0.0281\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "\n",
      "\u001b[1mEpoch 8\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2748\n",
      "Batch 55 Loss: 0.2759\n",
      "Batch 110 Loss: 0.2743\n",
      "Batch 165 Loss: 0.2796\n",
      "Batch 220 Loss: 0.2796\n",
      "\n",
      "EPOCH 8 LOSS: 0.0281\n",
      "\n",
      "Reconstruction error recall 0.2079\n",
      "Change: 0.0000%\n",
      "Epoch   169: reducing learning rate of group 0 to 5.4779e-05.\n",
      "\n",
      "\u001b[1mEpoch 9\u001b[0m\n",
      "\n",
      "Batch 0 Loss: 0.2776\n",
      "Batch 55 Loss: 0.2764\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-376843786839>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m                   \u001b[0mnoise_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                   \u001b[0mvalidation_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_torch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                   y_val=y_val)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-b131393f30ae>\u001b[0m in \u001b[0;36mtrain_autoencoder\u001b[0;34m(model, dataset, loss_func, optimizer, epochs, batch_size, validation_tensor, y_val, lr_rate_scheduler, noise_factor, random_seed, MSE_stopping_threshold)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnoise_factor\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnoise_factor\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.RMSprop(ae5.parameters(), lr=0.02, weight_decay=0.5)\n",
    "train_autoencoder(model=ae5,\n",
    "                  dataset=output4,\n",
    "                  loss_func=loss_func,\n",
    "                  optimizer=optimizer,\n",
    "                  batch_size=1024,\n",
    "                  epochs=200,\n",
    "                  noise_factor=0.5,\n",
    "                  validation_tensor=val_torch,\n",
    "                  y_val=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "output5 = ae5(output4)\n",
    "train_output5 = ae5(train_output4)\n",
    "val_output5 = ae5(val_output4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add reconstruction score to DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_output = train_output5.detach().numpy()\n",
    "final_val_output = val_output5.detach().numpy()\n",
    "train_reconstruction_score = np.power(X_train_sc - final_train_output,2).sum(axis=1)\n",
    "val_reconstruction_score = np.power(X_val_sc - final_val_output,2).sum(axis=1)\n",
    "X_train['recon_score']=train_reconstruction_score\n",
    "X_val['recon_score']= val_reconstruction_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with L2 regularization on SMOTE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(n_jobs=-1)\n",
    "smote_train_X, smote_train_y = smote.fit_resample(X_train,y_train)\n",
    "smote_val_X, smote_val_y = smote.fit_resample(X_val,y_val)\n",
    "sklearn = LogisticRegression()\n",
    "sklearn.fit(smote_train_X,smote_train_y)\n",
    "X_train['smote']=sklearn.predict_proba(X_train)[:,1]\n",
    "X_val['smote']=sklearn.predict_proba(X_val)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class-Weighted MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add time data to columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.join(time_df)\n",
    "X_val = X_val.join(time_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_keras = to_categorical(y_train)\n",
    "y_val_keras = to_categorical(y_val)\n",
    "class_weights = {0:1,1:1/y_train.mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_keras = sc.fit_transform(X_train)\n",
    "X_val_keras = sc.fit_transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set checkpoint and learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = ReduceLROnPlateau(monitor='loss',\n",
    "                                factor=0.8, \n",
    "                                patience=10, \n",
    "                                verbose=1,\n",
    "                                mode='auto', \n",
    "                                min_delta=0.0001, \n",
    "                                cooldown=0, \n",
    "                                min_lr=0)\n",
    "checkpoint = ModelCheckpoint('checkpoint.best.hdf5',  verbose=1, save_best_only=True, mode='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate and compile MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = models.Sequential()\n",
    "nn.add(layers.Dropout(.3))\n",
    "nn.add(layers.Dense(128, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "nn.add(layers.Dense(64,activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "nn.add(layers.Dropout(.3))\n",
    "nn.add(layers.Dense(32,activation='relu'))\n",
    "nn.add(layers.Dense(16,activation='relu'))\n",
    "nn.add(layers.Dropout(.3))\n",
    "nn.add(layers.Dense(8,activation='relu'))\n",
    "nn.add(layers.Dense(4,activation='relu'))\n",
    "nn.add(layers.Dense(2,activation='sigmoid'))\n",
    "nn.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 227845 samples, validate on 56962 samples\n",
      "Epoch 1/1000\n",
      "177664/227845 [======================>.......] - ETA: 1s - loss: 1.2118"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-d06ecc1e7f19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m        \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m        \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_keras\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val_keras\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m        callbacks=[scheduler,checkpoint])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nn.fit(X_train_keras, \n",
    "       y_train_keras, \n",
    "       epochs=1000, \n",
    "       class_weight=class_weights,\n",
    "       batch_size=512,\n",
    "       validation_data=(X_val_keras,y_val_keras),\n",
    "       callbacks=[scheduler,checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get predictions from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nn = models.Sequential()\n",
    "results_nn.add(layers.Dense(128, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "results_nn.add(layers.Dense(64,activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "results_nn.add(layers.Dense(32,activation='relu'))\n",
    "results_nn.add(layers.Dense(16,activation='relu'))\n",
    "results_nn.add(layers.Dense(8,activation='relu'))\n",
    "results_nn.add(layers.Dense(4,activation='relu'))\n",
    "results_nn.add(layers.Dense(2,activation='sigmoid'))\n",
    "results_nn.load_weights('checkpoint.best.hdf5')\n",
    "results_nn.compile(loss='binary_crossentropy',optimizer='adam')\n",
    "\n",
    "val_preds = results_nn.predict(X_val_keras)\n",
    "train_preds = results_nn.predict(X_train_keras)\n",
    "\n",
    "train_preds = pd.DataFrame(train_preds[:,1],index=X_train.index)\n",
    "val_preds = pd.DataFrame(val_preds[:,1],index=X_val.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run MLP results through FLIC to obtain final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "Iter 10 recall:  1.0\n",
      "Iter 20 recall:  0.8\n",
      "Iter 30 recall:  0.75\n",
      "Iter 40 recall:  0.75\n",
      "Iter 50 recall:  0.65\n",
      "Iter 60 recall:  0.65\n",
      "Iter 70 recall:  0.65\n",
      "Iter 80 recall:  0.65\n",
      "Iter 90 recall:  0.65\n",
      "Iter 100 recall:  0.65\n",
      "Iter 110 recall:  0.65\n",
      "Iter 120 recall:  0.65\n",
      "Iter 130 recall:  0.65\n",
      "Iter 140 recall:  0.65\n",
      "Iter 150 recall:  0.65\n",
      "Iter 160 recall:  0.65\n",
      "Iter 170 recall:  0.65\n",
      "Iter 180 recall:  0.65\n",
      "Iter 190 recall:  0.65\n",
      "Iter 200 recall:  0.65\n",
      "Iter 210 recall:  0.65\n",
      "Iter 220 recall:  0.65\n",
      "Iter 230 recall:  0.65\n",
      "Iter 240 recall:  0.65\n",
      "Iter 250 recall:  0.65\n",
      "Epoch:  2\n",
      "Iter 10 recall:  1.0\n",
      "Iter 20 recall:  1.0\n",
      "Iter 30 recall:  1.0\n",
      "Iter 40 recall:  1.0\n",
      "Iter 50 recall:  1.0\n",
      "Iter 60 recall:  1.0\n",
      "Iter 70 recall:  1.0\n",
      "Iter 80 recall:  1.0\n",
      "Iter 90 recall:  1.0\n",
      "Iter 100 recall:  1.0\n",
      "Iter 110 recall:  1.0\n",
      "Iter 120 recall:  1.0\n",
      "Iter 130 recall:  1.0\n",
      "Iter 140 recall:  1.0\n",
      "Iter 150 recall:  1.0\n",
      "Iter 160 recall:  1.0\n",
      "Iter 170 recall:  1.0\n",
      "Iter 180 recall:  1.0\n",
      "Iter 190 recall:  1.0\n",
      "Iter 200 recall:  1.0\n",
      "Iter 210 recall:  1.0\n",
      "Iter 220 recall:  1.0\n",
      "Iter 230 recall:  1.0\n",
      "Iter 240 recall:  1.0\n",
      "Iter 250 recall:  1.0\n",
      "Epoch:  3\n",
      "Iter 10 recall:  1.0\n",
      "Iter 20 recall:  1.0\n",
      "Iter 30 recall:  1.0\n",
      "Iter 40 recall:  1.0\n",
      "Iter 50 recall:  1.0\n",
      "Iter 60 recall:  1.0\n",
      "Iter 70 recall:  1.0\n",
      "Iter 80 recall:  1.0\n",
      "Iter 90 recall:  1.0\n",
      "Iter 100 recall:  1.0\n",
      "Iter 110 recall:  1.0\n",
      "Iter 120 recall:  1.0\n",
      "Iter 130 recall:  1.0\n",
      "Iter 140 recall:  1.0\n",
      "Iter 150 recall:  1.0\n",
      "Iter 160 recall:  1.0\n",
      "Iter 170 recall:  1.0\n",
      "Iter 180 recall:  1.0\n",
      "Iter 190 recall:  1.0\n",
      "Iter 200 recall:  1.0\n",
      "Iter 210 recall:  1.0\n",
      "Iter 220 recall:  1.0\n",
      "Iter 230 recall:  1.0\n",
      "Iter 240 recall:  1.0\n",
      "Iter 250 recall:  1.0\n",
      "Epoch:  4\n",
      "Iter 10 recall:  1.0\n",
      "Iter 20 recall:  1.0\n",
      "Iter 30 recall:  1.0\n",
      "Iter 40 recall:  1.0\n",
      "Iter 50 recall:  1.0\n",
      "Iter 60 recall:  1.0\n",
      "Iter 70 recall:  1.0\n",
      "Iter 80 recall:  1.0\n",
      "Iter 90 recall:  1.0\n",
      "Iter 100 recall:  1.0\n",
      "Iter 110 recall:  1.0\n",
      "Iter 120 recall:  1.0\n",
      "Iter 130 recall:  1.0\n",
      "Iter 140 recall:  1.0\n",
      "Iter 150 recall:  1.0\n",
      "Iter 160 recall:  1.0\n",
      "Iter 170 recall:  1.0\n",
      "Iter 180 recall:  1.0\n",
      "Iter 190 recall:  1.0\n",
      "Iter 200 recall:  1.0\n",
      "Iter 210 recall:  1.0\n",
      "Iter 220 recall:  1.0\n",
      "Iter 230 recall:  1.0\n",
      "Iter 240 recall:  1.0\n",
      "Iter 250 recall:  1.0\n",
      "Epoch:  5\n",
      "Iter 10 recall:  1.0\n",
      "Iter 20 recall:  1.0\n",
      "Iter 30 recall:  1.0\n",
      "Iter 40 recall:  1.0\n",
      "Iter 50 recall:  1.0\n",
      "Iter 60 recall:  1.0\n",
      "Iter 70 recall:  1.0\n",
      "Iter 80 recall:  1.0\n",
      "Iter 90 recall:  1.0\n",
      "Iter 100 recall:  1.0\n",
      "Iter 110 recall:  1.0\n",
      "Iter 120 recall:  1.0\n",
      "Iter 130 recall:  1.0\n",
      "Iter 140 recall:  1.0\n",
      "Iter 150 recall:  1.0\n",
      "Iter 160 recall:  1.0\n",
      "Iter 170 recall:  1.0\n",
      "Iter 180 recall:  1.0\n",
      "Iter 190 recall:  1.0\n",
      "Iter 200 recall:  1.0\n",
      "Iter 210 recall:  1.0\n",
      "Iter 220 recall:  1.0\n",
      "Iter 230 recall:  1.0\n",
      "Iter 240 recall:  1.0\n",
      "Iter 250 recall:  1.0\n",
      "Epoch:  6\n",
      "Iter 10 recall:  1.0\n",
      "Iter 20 recall:  1.0\n",
      "Iter 30 recall:  1.0\n",
      "Iter 40 recall:  1.0\n",
      "Iter 50 recall:  1.0\n",
      "Iter 60 recall:  1.0\n",
      "Iter 70 recall:  1.0\n",
      "Iter 80 recall:  1.0\n",
      "Iter 90 recall:  1.0\n",
      "Iter 100 recall:  1.0\n",
      "Iter 110 recall:  1.0\n",
      "Iter 120 recall:  1.0\n",
      "Iter 130 recall:  1.0\n",
      "Iter 140 recall:  1.0\n",
      "Iter 150 recall:  1.0\n",
      "Iter 160 recall:  1.0\n",
      "Iter 170 recall:  1.0\n",
      "Iter 180 recall:  1.0\n",
      "Iter 190 recall:  1.0\n",
      "Iter 200 recall:  1.0\n",
      "Iter 210 recall:  1.0\n",
      "Iter 220 recall:  1.0\n",
      "Iter 230 recall:  1.0\n",
      "Iter 240 recall:  1.0\n",
      "Iter 250 recall:  1.0\n",
      "Epoch:  7\n",
      "Iter 10 recall:  1.0\n",
      "Iter 20 recall:  1.0\n",
      "Iter 30 recall:  1.0\n",
      "Iter 40 recall:  1.0\n",
      "Iter 50 recall:  1.0\n",
      "Iter 60 recall:  1.0\n",
      "Iter 70 recall:  1.0\n",
      "Iter 80 recall:  1.0\n",
      "Iter 90 recall:  1.0\n",
      "Iter 100 recall:  1.0\n",
      "Iter 110 recall:  1.0\n",
      "Iter 120 recall:  1.0\n",
      "Iter 130 recall:  1.0\n",
      "Iter 140 recall:  1.0\n",
      "Iter 150 recall:  1.0\n",
      "Iter 160 recall:  1.0\n",
      "Iter 170 recall:  1.0\n",
      "Iter 180 recall:  1.0\n",
      "Iter 190 recall:  1.0\n",
      "Iter 200 recall:  1.0\n",
      "Iter 210 recall:  1.0\n",
      "Iter 220 recall:  1.0\n",
      "Iter 230 recall:  1.0\n",
      "Iter 240 recall:  1.0\n",
      "Iter 250 recall:  1.0\n",
      "Epoch:  8\n",
      "Iter 10 recall:  1.0\n",
      "Iter 20 recall:  1.0\n",
      "Iter 30 recall:  1.0\n",
      "Iter 40 recall:  1.0\n",
      "Iter 50 recall:  1.0\n",
      "Iter 60 recall:  1.0\n",
      "Iter 70 recall:  1.0\n",
      "Iter 80 recall:  1.0\n",
      "Iter 90 recall:  1.0\n",
      "Iter 100 recall:  1.0\n",
      "Iter 110 recall:  1.0\n",
      "Iter 120 recall:  1.0\n",
      "Iter 130 recall:  1.0\n",
      "Iter 140 recall:  1.0\n",
      "Iter 150 recall:  1.0\n",
      "Iter 160 recall:  1.0\n",
      "Iter 170 recall:  1.0\n",
      "Iter 180 recall:  1.0\n",
      "Iter 190 recall:  1.0\n",
      "Iter 200 recall:  1.0\n",
      "Iter 210 recall:  1.0\n",
      "Iter 220 recall:  1.0\n",
      "Iter 230 recall:  1.0\n",
      "Iter 240 recall:  1.0\n",
      "Iter 250 recall:  1.0\n",
      "Epoch:  9\n",
      "Iter 10 recall:  1.0\n",
      "Iter 20 recall:  1.0\n",
      "Iter 30 recall:  1.0\n",
      "Iter 40 recall:  1.0\n",
      "Iter 50 recall:  1.0\n",
      "Iter 60 recall:  1.0\n",
      "Iter 70 recall:  1.0\n",
      "Iter 80 recall:  1.0\n",
      "Iter 90 recall:  1.0\n",
      "Iter 100 recall:  1.0\n",
      "Iter 110 recall:  1.0\n",
      "Iter 120 recall:  1.0\n",
      "Iter 130 recall:  1.0\n",
      "Iter 140 recall:  1.0\n",
      "Iter 150 recall:  1.0\n",
      "Iter 160 recall:  1.0\n",
      "Iter 170 recall:  1.0\n",
      "Iter 180 recall:  1.0\n",
      "Iter 190 recall:  1.0\n",
      "Iter 200 recall:  1.0\n",
      "Iter 210 recall:  1.0\n",
      "Iter 220 recall:  1.0\n",
      "Iter 230 recall:  1.0\n",
      "Iter 240 recall:  1.0\n",
      "Iter 250 recall:  1.0\n",
      "Epoch:  10\n",
      "Iter 10 recall:  1.0\n",
      "Iter 20 recall:  1.0\n",
      "Iter 30 recall:  1.0\n",
      "Iter 40 recall:  1.0\n",
      "Iter 50 recall:  1.0\n",
      "Iter 60 recall:  1.0\n",
      "Iter 70 recall:  1.0\n",
      "Iter 80 recall:  1.0\n",
      "Iter 90 recall:  1.0\n",
      "Iter 100 recall:  1.0\n",
      "Iter 110 recall:  1.0\n",
      "Iter 120 recall:  1.0\n",
      "Iter 130 recall:  1.0\n",
      "Iter 140 recall:  1.0\n",
      "Iter 150 recall:  1.0\n",
      "Iter 160 recall:  1.0\n",
      "Iter 170 recall:  1.0\n",
      "Iter 180 recall:  1.0\n",
      "Iter 190 recall:  1.0\n",
      "Iter 200 recall:  1.0\n",
      "Iter 210 recall:  1.0\n",
      "Iter 220 recall:  1.0\n",
      "Iter 230 recall:  1.0\n",
      "Iter 240 recall:  1.0\n",
      "Iter 250 recall:  1.0\n",
      "Epoch:  11\n",
      "Iter 10 recall:  1.0\n",
      "Iter 20 recall:  1.0\n",
      "Iter 30 recall:  1.0\n",
      "Iter 40 recall:  1.0\n",
      "Iter 50 recall:  1.0\n",
      "Iter 60 recall:  1.0\n",
      "Iter 70 recall:  1.0\n",
      "Iter 80 recall:  1.0\n",
      "Iter 90 recall:  1.0\n",
      "Iter 100 recall:  1.0\n",
      "Iter 110 recall:  1.0\n",
      "Iter 120 recall:  1.0\n",
      "Iter 130 recall:  1.0\n",
      "Iter 140 recall:  1.0\n",
      "Iter 150 recall:  1.0\n",
      "Iter 160 recall:  1.0\n",
      "Iter 170 recall:  1.0\n",
      "Iter 180 recall:  1.0\n",
      "Iter 190 recall:  1.0\n",
      "Iter 200 recall:  1.0\n",
      "Iter 210 recall:  1.0\n",
      "Iter 220 recall:  1.0\n",
      "Iter 230 recall:  1.0\n",
      "Iter 240 recall:  1.0\n",
      "Iter 250 recall:  1.0\n",
      "Epoch:  12\n",
      "Iter 10 recall:  1.0\n",
      "Iter 20 recall:  1.0\n",
      "Iter 30 recall:  1.0\n",
      "Iter 40 recall:  1.0\n",
      "Iter 50 recall:  1.0\n",
      "Iter 60 recall:  1.0\n",
      "Iter 70 recall:  1.0\n",
      "Iter 80 recall:  1.0\n",
      "Iter 90 recall:  1.0\n",
      "Iter 100 recall:  1.0\n",
      "Iter 110 recall:  1.0\n",
      "Iter 120 recall:  1.0\n",
      "Iter 130 recall:  1.0\n",
      "Iter 140 recall:  1.0\n",
      "Iter 150 recall:  1.0\n",
      "Iter 160 recall:  1.0\n",
      "Iter 170 recall:  1.0\n",
      "Iter 180 recall:  1.0\n",
      "Iter 190 recall:  1.0\n",
      "Iter 200 recall:  1.0\n",
      "Iter 210 recall:  1.0\n",
      "Iter 220 recall:  1.0\n",
      "Iter 230 recall:  1.0\n",
      "Iter 240 recall:  1.0\n",
      "Iter 250 recall:  1.0\n",
      "Epoch:  13\n",
      "Iter 10 recall:  1.0\n",
      "Iter 20 recall:  1.0\n",
      "Iter 30 recall:  1.0\n",
      "Iter 40 recall:  1.0\n",
      "Iter 50 recall:  1.0\n",
      "Iter 60 recall:  1.0\n",
      "Iter 70 recall:  1.0\n",
      "Iter 80 recall:  1.0\n",
      "Iter 90 recall:  1.0\n",
      "Iter 100 recall:  1.0\n",
      "Iter 110 recall:  1.0\n",
      "Iter 120 recall:  1.0\n",
      "Iter 130 recall:  1.0\n",
      "Iter 140 recall:  1.0\n",
      "Iter 150 recall:  1.0\n",
      "Iter 160 recall:  1.0\n",
      "Iter 170 recall:  1.0\n",
      "Iter 180 recall:  1.0\n",
      "Iter 190 recall:  1.0\n",
      "Iter 200 recall:  1.0\n",
      "Iter 210 recall:  1.0\n",
      "Iter 220 recall:  1.0\n",
      "Iter 230 recall:  1.0\n",
      "Iter 240 recall:  1.0\n",
      "Iter 250 recall:  1.0\n",
      "Epoch:  14\n",
      "Iter 10 recall:  1.0\n",
      "Iter 20 recall:  1.0\n",
      "Iter 30 recall:  1.0\n",
      "Iter 40 recall:  1.0\n",
      "Iter 50 recall:  1.0\n",
      "Iter 60 recall:  1.0\n",
      "Iter 70 recall:  1.0\n",
      "Iter 80 recall:  1.0\n",
      "Iter 90 recall:  1.0\n",
      "Iter 100 recall:  1.0\n",
      "Iter 110 recall:  1.0\n",
      "Iter 120 recall:  1.0\n",
      "Iter 130 recall:  1.0\n",
      "Iter 140 recall:  1.0\n",
      "Iter 150 recall:  1.0\n",
      "Iter 160 recall:  1.0\n",
      "Iter 170 recall:  1.0\n",
      "Iter 180 recall:  1.0\n",
      "Iter 190 recall:  1.0\n",
      "Iter 200 recall:  1.0\n",
      "Iter 210 recall:  1.0\n",
      "Iter 220 recall:  1.0\n",
      "Iter 230 recall:  1.0\n",
      "Iter 240 recall:  1.0\n",
      "Iter 250 recall:  1.0\n",
      "Epoch:  15\n",
      "Iter 10 recall:  1.0\n",
      "Iter 20 recall:  1.0\n",
      "Iter 30 recall:  1.0\n",
      "Iter 40 recall:  1.0\n",
      "Iter 50 recall:  1.0\n",
      "Iter 60 recall:  1.0\n",
      "Iter 70 recall:  1.0\n",
      "Iter 80 recall:  1.0\n",
      "Iter 90 recall:  1.0\n",
      "Iter 100 recall:  1.0\n",
      "Iter 110 recall:  1.0\n",
      "Iter 120 recall:  1.0\n",
      "Iter 130 recall:  1.0\n",
      "Iter 140 recall:  1.0\n",
      "Iter 150 recall:  1.0\n",
      "Iter 160 recall:  1.0\n",
      "Iter 170 recall:  1.0\n",
      "Iter 180 recall:  1.0\n",
      "Iter 190 recall:  1.0\n",
      "Iter 200 recall:  1.0\n",
      "Iter 210 recall:  1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 220 recall:  1.0\n",
      "Iter 230 recall:  1.0\n",
      "Iter 240 recall:  1.0\n",
      "Iter 250 recall:  1.0\n",
      "Epoch:  16\n",
      "Iter 10 recall:  1.0\n",
      "Iter 20 recall:  1.0\n",
      "Iter 30 recall:  1.0\n",
      "Iter 40 recall:  1.0\n",
      "Iter 50 recall:  1.0\n",
      "Iter 60 recall:  1.0\n",
      "Iter 70 recall:  1.0\n",
      "Iter 80 recall:  1.0\n",
      "Iter 90 recall:  1.0\n",
      "Iter 100 recall:  1.0\n",
      "Iter 110 recall:  1.0\n",
      "Iter 120 recall:  1.0\n",
      "Iter 130 recall:  1.0\n",
      "Iter 140 recall:  1.0\n",
      "Iter 150 recall:  1.0\n",
      "Iter 160 recall:  1.0\n",
      "Iter 170 recall:  1.0\n",
      "Iter 180 recall:  1.0\n",
      "Iter 190 recall:  1.0\n",
      "Iter 200 recall:  1.0\n",
      "Iter 210 recall:  1.0\n",
      "Iter 220 recall:  1.0\n",
      "Iter 230 recall:  1.0\n",
      "Iter 240 recall:  1.0\n",
      "Iter 250 recall:  1.0\n",
      "Epoch:  17\n",
      "Iter 10 recall:  1.0\n",
      "Iter 20 recall:  1.0\n",
      "Iter 30 recall:  1.0\n",
      "Iter 40 recall:  1.0\n",
      "Iter 50 recall:  1.0\n",
      "Iter 60 recall:  1.0\n",
      "Iter 70 recall:  1.0\n",
      "Iter 80 recall:  1.0\n",
      "Iter 90 recall:  1.0\n",
      "Iter 100 recall:  1.0\n",
      "Iter 110 recall:  1.0\n",
      "Iter 120 recall:  1.0\n",
      "Iter 130 recall:  1.0\n",
      "Iter 140 recall:  1.0\n",
      "Iter 150 recall:  1.0\n",
      "Iter 160 recall:  1.0\n",
      "Iter 170 recall:  1.0\n",
      "Iter 180 recall:  1.0\n",
      "Iter 190 recall:  1.0\n",
      "Iter 200 recall:  1.0\n",
      "Iter 210 recall:  1.0\n",
      "Iter 220 recall:  1.0\n",
      "Iter 230 recall:  1.0\n",
      "Iter 240 recall:  1.0\n",
      "Iter 250 recall:  1.0\n",
      "Epoch:  18\n",
      "Iter 10 recall:  1.0\n",
      "Iter 20 recall:  1.0\n",
      "Iter 30 recall:  1.0\n",
      "Iter 40 recall:  1.0\n",
      "Iter 50 recall:  1.0\n",
      "Iter 60 recall:  1.0\n",
      "Iter 70 recall:  1.0\n",
      "Iter 80 recall:  1.0\n",
      "Iter 90 recall:  1.0\n",
      "Iter 100 recall:  1.0\n",
      "Iter 110 recall:  1.0\n",
      "Iter 120 recall:  1.0\n",
      "Iter 130 recall:  1.0\n",
      "Iter 140 recall:  1.0\n",
      "Iter 150 recall:  1.0\n",
      "Iter 160 recall:  1.0\n",
      "Iter 170 recall:  1.0\n",
      "Iter 180 recall:  1.0\n",
      "Iter 190 recall:  1.0\n",
      "Iter 200 recall:  1.0\n",
      "Iter 210 recall:  1.0\n",
      "Iter 220 recall:  1.0\n",
      "Iter 230 recall:  1.0\n",
      "Iter 240 recall:  1.0\n",
      "Iter 250 recall:  1.0\n",
      "Epoch:  19\n",
      "Iter 10 recall:  1.0\n",
      "Iter 20 recall:  1.0\n",
      "Iter 30 recall:  1.0\n",
      "Iter 40 recall:  1.0\n",
      "Iter 50 recall:  1.0\n",
      "Iter 60 recall:  1.0\n",
      "Iter 70 recall:  1.0\n",
      "Iter 80 recall:  1.0\n",
      "Iter 90 recall:  1.0\n",
      "Iter 100 recall:  1.0\n",
      "Iter 110 recall:  1.0\n",
      "Iter 120 recall:  1.0\n",
      "Iter 130 recall:  1.0\n",
      "Iter 140 recall:  1.0\n",
      "Iter 150 recall:  1.0\n",
      "Iter 160 recall:  1.0\n",
      "Iter 170 recall:  1.0\n",
      "Iter 180 recall:  1.0\n",
      "Iter 190 recall:  1.0\n",
      "Iter 200 recall:  1.0\n",
      "Iter 210 recall:  1.0\n",
      "Iter 220 recall:  1.0\n",
      "Iter 230 recall:  1.0\n",
      "Iter 240 recall:  1.0\n",
      "Iter 250 recall:  1.0\n",
      "Epoch:  20\n",
      "Iter 10 recall:  1.0\n",
      "Iter 20 recall:  1.0\n",
      "Iter 30 recall:  1.0\n",
      "Iter 40 recall:  1.0\n",
      "Iter 50 recall:  1.0\n",
      "Iter 60 recall:  1.0\n",
      "Iter 70 recall:  1.0\n",
      "Iter 80 recall:  1.0\n",
      "Iter 90 recall:  1.0\n",
      "Iter 100 recall:  1.0\n",
      "Iter 110 recall:  1.0\n",
      "Iter 120 recall:  1.0\n",
      "Iter 130 recall:  1.0\n",
      "Iter 140 recall:  1.0\n",
      "Iter 150 recall:  1.0\n",
      "Iter 160 recall:  1.0\n",
      "Iter 170 recall:  1.0\n",
      "Iter 180 recall:  1.0\n",
      "Iter 190 recall:  1.0\n",
      "Iter 200 recall:  1.0\n",
      "Iter 210 recall:  1.0\n",
      "Iter 220 recall:  1.0\n",
      "Iter 230 recall:  1.0\n",
      "Iter 240 recall:  1.0\n",
      "Iter 250 recall:  1.0\n"
     ]
    }
   ],
   "source": [
    "FLIC = PMLE.PMLE.Firth_Logit(num_iters=250,alpha=0.05,FLIC=True, metric='recall', readout_rate=10)\n",
    "train = np.zeros(X_train.shape[0])\n",
    "val = np.zeros(X_val.shape[0])\n",
    "for i in range(20):\n",
    "    print('Epoch:',i+1)\n",
    "    X = train_preds[y_train==1].sample(frac=0.05).append(train_preds[y_train==0].sample(frac=0.05))\n",
    "    y = y_train.loc[X.index]\n",
    "    FLIC.fit(X,y)\n",
    "    train = ((i)*train + FLIC.predict_proba(train_preds))/(i+1)\n",
    "    val =  ((i)*val + FLIC.predict_proba(val_preds))/(i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final validation set area under the ROC curve score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9884146871274243"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_val,val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
